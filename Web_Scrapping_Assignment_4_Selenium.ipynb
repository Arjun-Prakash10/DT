{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D://chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia: \n",
    "### Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "### You need to find following details:\n",
    "### A) Rank\n",
    "### B) Name\n",
    "### C) Artist\n",
    "### D) Upload date\n",
    "### E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the dictionary\n",
    "d = {\n",
    "    'Rank':[],\n",
    "    'Name':[],\n",
    "    'Artist':[],\n",
    "    'Upload_Date':[],\n",
    "    'Views(billions)':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the total number of rows\n",
    "rows = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rank': ['1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25',\n",
       "  '26',\n",
       "  '27',\n",
       "  '28',\n",
       "  '29',\n",
       "  '30'],\n",
       " 'Name': ['\"Baby Shark Dance\"',\n",
       "  '\"Despacito\"',\n",
       "  '\"Shape of You\"',\n",
       "  '\"Johny Johny Yes Papa\"',\n",
       "  '\"See You Again\"',\n",
       "  '\"Masha and the Bear – Recipe for Disaster\"',\n",
       "  '\"Uptown Funk\"',\n",
       "  '\"Gangnam Style\"',\n",
       "  '\"Learning Colors – Colorful Eggs on a Farm\"',\n",
       "  '\"Bath Song\"',\n",
       "  '\"Phonics Song with Two Words\"',\n",
       "  '\"Sugar\"',\n",
       "  '\"Sorry\"',\n",
       "  '\"Roar\"',\n",
       "  '\"Dame Tu Cosita\"',\n",
       "  '\"Counting Stars\"',\n",
       "  '\"Thinking Out Loud\"',\n",
       "  '\"Dark Horse\"',\n",
       "  '\"Faded\"',\n",
       "  '\"Shake It Off\"',\n",
       "  '\"Lean On\"',\n",
       "  '\"Bailando\"',\n",
       "  '\"Girls Like You\"',\n",
       "  '\"Let Her Go\"',\n",
       "  '\"Mi Gente\"',\n",
       "  '\"Wheels on the Bus\"',\n",
       "  '\"Hello\"',\n",
       "  '\"Perfect\"',\n",
       "  '\"Waka Waka (This Time for Africa)\"',\n",
       "  '\"Axel F\"'],\n",
       " 'Artist': [\"Pinkfong Kids' Songs & Stories\",\n",
       "  'Luis Fonsi',\n",
       "  'Ed Sheeran',\n",
       "  'LooLoo Kids',\n",
       "  'Wiz Khalifa',\n",
       "  'Get Movies',\n",
       "  'Mark Ronson',\n",
       "  'Psy',\n",
       "  'Miroshka TV',\n",
       "  'Cocomelon – Nursery Rhymes',\n",
       "  'ChuChu TV',\n",
       "  'Maroon 5',\n",
       "  'Justin Bieber',\n",
       "  'Katy Perry',\n",
       "  'El Chombo',\n",
       "  'OneRepublic',\n",
       "  'Ed Sheeran',\n",
       "  'Katy Perry',\n",
       "  'Alan Walker',\n",
       "  'Taylor Swift',\n",
       "  'Major Lazer Official',\n",
       "  'Enrique Iglesias',\n",
       "  'Maroon 5',\n",
       "  'Passenger',\n",
       "  'J Balvin',\n",
       "  'Cocomelon – Nursery Rhymes',\n",
       "  'Adele',\n",
       "  'Ed Sheeran',\n",
       "  'Shakira',\n",
       "  'Crazy Frog'],\n",
       " 'Upload_Date': ['June 17, 2016',\n",
       "  'January 12, 2017',\n",
       "  'January 30, 2017',\n",
       "  'October 8, 2016',\n",
       "  'April 6, 2015',\n",
       "  'January 31, 2012',\n",
       "  'November 19, 2014',\n",
       "  'July 15, 2012',\n",
       "  'February 27, 2018',\n",
       "  'May 2, 2018',\n",
       "  'March 6, 2014',\n",
       "  'January 14, 2015',\n",
       "  'October 22, 2015',\n",
       "  'September 5, 2013',\n",
       "  'April 5, 2018',\n",
       "  'May 31, 2013',\n",
       "  'October 7, 2014',\n",
       "  'February 20, 2014',\n",
       "  'December 3, 2015',\n",
       "  'August 18, 2014',\n",
       "  'March 22, 2015',\n",
       "  'April 11, 2014',\n",
       "  'May 31, 2018',\n",
       "  'July 25, 2012',\n",
       "  'June 29, 2017',\n",
       "  'May 24, 2018',\n",
       "  'October 22, 2015',\n",
       "  'November 9, 2017',\n",
       "  'June 4, 2010',\n",
       "  'June 16, 2009'],\n",
       " 'Views(billions)': ['8.44',\n",
       "  '7.32',\n",
       "  '5.29',\n",
       "  '5.24',\n",
       "  '5.08',\n",
       "  '4.43',\n",
       "  '4.16',\n",
       "  '4.05',\n",
       "  '3.97',\n",
       "  '3.95',\n",
       "  '3.78',\n",
       "  '3.45',\n",
       "  '3.43',\n",
       "  '3.34',\n",
       "  '3.28',\n",
       "  '3.27',\n",
       "  '3.24',\n",
       "  '3.05',\n",
       "  '3.05',\n",
       "  '3.05',\n",
       "  '3.02',\n",
       "  '3.01',\n",
       "  '3.01',\n",
       "  '2.97',\n",
       "  '2.90',\n",
       "  '2.89',\n",
       "  '2.83',\n",
       "  '2.82',\n",
       "  '2.80',\n",
       "  '2.77']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the details of the video from each row\n",
    "xpath = \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr[\"\n",
    "for i in range(len(rows)):\n",
    "    xpath_row = xpath+str(i+1)+\"]/td\"\n",
    "    row = driver.find_elements_by_xpath(xpath_row)\n",
    "    d['Rank'].append(row[0].text[:-1])\n",
    "    d['Name'].append(row[1].text[:-4])\n",
    "    d['Artist'].append(row[2].text)\n",
    "    d['Views(billions)'].append(row[3].text)\n",
    "    d['Upload_Date'].append(row[4].text)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views(billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>8.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Shake It Off\"</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Mi Gente\"</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                         Name  \\\n",
       "0     1                           \"Baby Shark Dance\"   \n",
       "1     2                                  \"Despacito\"   \n",
       "2     3                               \"Shape of You\"   \n",
       "3     4                       \"Johny Johny Yes Papa\"   \n",
       "4     5                              \"See You Again\"   \n",
       "5     6   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "6     7                                \"Uptown Funk\"   \n",
       "7     8                              \"Gangnam Style\"   \n",
       "8     9  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "9    10                                  \"Bath Song\"   \n",
       "10   11                \"Phonics Song with Two Words\"   \n",
       "11   12                                      \"Sugar\"   \n",
       "12   13                                      \"Sorry\"   \n",
       "13   14                                       \"Roar\"   \n",
       "14   15                             \"Dame Tu Cosita\"   \n",
       "15   16                             \"Counting Stars\"   \n",
       "16   17                          \"Thinking Out Loud\"   \n",
       "17   18                                 \"Dark Horse\"   \n",
       "18   19                                      \"Faded\"   \n",
       "19   20                               \"Shake It Off\"   \n",
       "20   21                                    \"Lean On\"   \n",
       "21   22                                   \"Bailando\"   \n",
       "22   23                             \"Girls Like You\"   \n",
       "23   24                                 \"Let Her Go\"   \n",
       "24   25                                   \"Mi Gente\"   \n",
       "25   26                          \"Wheels on the Bus\"   \n",
       "26   27                                      \"Hello\"   \n",
       "27   28                                    \"Perfect\"   \n",
       "28   29           \"Waka Waka (This Time for Africa)\"   \n",
       "29   30                                     \"Axel F\"   \n",
       "\n",
       "                            Artist        Upload_Date Views(billions)  \n",
       "0   Pinkfong Kids' Songs & Stories      June 17, 2016            8.44  \n",
       "1                       Luis Fonsi   January 12, 2017            7.32  \n",
       "2                       Ed Sheeran   January 30, 2017            5.29  \n",
       "3                      LooLoo Kids    October 8, 2016            5.24  \n",
       "4                      Wiz Khalifa      April 6, 2015            5.08  \n",
       "5                       Get Movies   January 31, 2012            4.43  \n",
       "6                      Mark Ronson  November 19, 2014            4.16  \n",
       "7                              Psy      July 15, 2012            4.05  \n",
       "8                      Miroshka TV  February 27, 2018            3.97  \n",
       "9       Cocomelon – Nursery Rhymes        May 2, 2018            3.95  \n",
       "10                       ChuChu TV      March 6, 2014            3.78  \n",
       "11                        Maroon 5   January 14, 2015            3.45  \n",
       "12                   Justin Bieber   October 22, 2015            3.43  \n",
       "13                      Katy Perry  September 5, 2013            3.34  \n",
       "14                       El Chombo      April 5, 2018            3.28  \n",
       "15                     OneRepublic       May 31, 2013            3.27  \n",
       "16                      Ed Sheeran    October 7, 2014            3.24  \n",
       "17                      Katy Perry  February 20, 2014            3.05  \n",
       "18                     Alan Walker   December 3, 2015            3.05  \n",
       "19                    Taylor Swift    August 18, 2014            3.05  \n",
       "20            Major Lazer Official     March 22, 2015            3.02  \n",
       "21                Enrique Iglesias     April 11, 2014            3.01  \n",
       "22                        Maroon 5       May 31, 2018            3.01  \n",
       "23                       Passenger      July 25, 2012            2.97  \n",
       "24                        J Balvin      June 29, 2017            2.90  \n",
       "25      Cocomelon – Nursery Rhymes       May 24, 2018            2.89  \n",
       "26                           Adele   October 22, 2015            2.83  \n",
       "27                      Ed Sheeran   November 9, 2017            2.82  \n",
       "28                         Shakira       June 4, 2010            2.80  \n",
       "29                      Crazy Frog      June 16, 2009            2.77  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "### Url = https://www.bcci.tv/.\n",
    "### You need to find following details:\n",
    "### A) Match title (I.e. 1st ODI)\n",
    "### B) Series\n",
    "### C) Place\n",
    "### D) Date\n",
    "### E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to International Fixtures Page\n",
    "page = driver.find_element_by_xpath(\"//div[contains(text(),'International')]/following::div[2]/ul/li/a[contains(text(),'Fixtures')]\").get_attribute('href')\n",
    "driver.get(page)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the dictionary\n",
    "d = {\n",
    "    'Match_Title':[],\n",
    "    'Series':[],\n",
    "    'Place':[],\n",
    "    'Date':[],\n",
    "    'Time':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the total number of matches\n",
    "matches = driver.find_elements_by_xpath(\"//div[@class='js-list']/a\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Match_Title': ['Final',\n",
       "  '1st Test',\n",
       "  '2nd Test',\n",
       "  '3rd Test',\n",
       "  '4th Test',\n",
       "  '5th Test'],\n",
       " 'Series': ['The Ageas Bowl, Southampton',\n",
       "  'Trent Bridge, Nottingham',\n",
       "  \"Lord's, London\",\n",
       "  'Headingley, Leeds',\n",
       "  'The Oval, London',\n",
       "  'Old Trafford, Manchester'],\n",
       " 'Place': ['TEST - ICC WORLD TEST CHAMPIONSHIP FINAL',\n",
       "  'TEST - ENGLAND V INDIA 2021',\n",
       "  'TEST - ENGLAND V INDIA 2021',\n",
       "  'TEST - ENGLAND V INDIA 2021',\n",
       "  'TEST - ENGLAND V INDIA 2021',\n",
       "  'TEST - ENGLAND V INDIA 2021'],\n",
       " 'Date': ['18 JUNE',\n",
       "  '04 AUGUST',\n",
       "  '12 AUGUST',\n",
       "  '25 AUGUST',\n",
       "  '02 SEPTEMBER',\n",
       "  '10 SEPTEMBER'],\n",
       " 'Time': ['15:30 IST',\n",
       "  '15:30 IST',\n",
       "  '15:30 IST',\n",
       "  '15:30 IST',\n",
       "  '15:30 IST',\n",
       "  '15:30 IST']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching 'Match_Title', 'Series', 'Place', 'Date', 'Time'\n",
    "for i in range(len(matches)):\n",
    "    tmp_1 = driver.find_element_by_xpath(\"//div[@class='js-list']/a[\"+str(i+1)+\"]//p[@class='fixture__additional-info']\").text.split('\\n')\n",
    "    tmp_2 = driver.find_element_by_xpath(\"//div[@class='js-list']/a[\"+str(i+1)+\"]//div[@class='fixture__format-strip']\").text.split('\\n')\n",
    "    tmp_3 = driver.find_element_by_xpath(\"//div[@class='js-list']/a[\"+str(i+1)+\"]//div[@class='fixture__full-date']\").text.split('\\n')\n",
    "    d['Match_Title'].append(tmp_1[0])\n",
    "    d['Series'].append(tmp_1[1])\n",
    "    d['Place'].append(' - '.join(tmp_2))\n",
    "    d['Date'].append(tmp_3[0]+\" \"+tmp_3[1])\n",
    "    d['Time'].append(tmp_3[2])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "      <td>TEST - ICC WORLD TEST CHAMPIONSHIP FINAL</td>\n",
       "      <td>18 JUNE</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>TEST - ENGLAND V INDIA 2021</td>\n",
       "      <td>04 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>TEST - ENGLAND V INDIA 2021</td>\n",
       "      <td>12 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>TEST - ENGLAND V INDIA 2021</td>\n",
       "      <td>25 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>TEST - ENGLAND V INDIA 2021</td>\n",
       "      <td>02 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>TEST - ENGLAND V INDIA 2021</td>\n",
       "      <td>10 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Title                       Series  \\\n",
       "0       Final  The Ageas Bowl, Southampton   \n",
       "1    1st Test     Trent Bridge, Nottingham   \n",
       "2    2nd Test               Lord's, London   \n",
       "3    3rd Test            Headingley, Leeds   \n",
       "4    4th Test             The Oval, London   \n",
       "5    5th Test     Old Trafford, Manchester   \n",
       "\n",
       "                                      Place          Date       Time  \n",
       "0  TEST - ICC WORLD TEST CHAMPIONSHIP FINAL       18 JUNE  15:30 IST  \n",
       "1               TEST - ENGLAND V INDIA 2021     04 AUGUST  15:30 IST  \n",
       "2               TEST - ENGLAND V INDIA 2021     12 AUGUST  15:30 IST  \n",
       "3               TEST - ENGLAND V INDIA 2021     25 AUGUST  15:30 IST  \n",
       "4               TEST - ENGLAND V INDIA 2021  02 SEPTEMBER  15:30 IST  \n",
       "5               TEST - ENGLAND V INDIA 2021  10 SEPTEMBER  15:30 IST  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of selenium exception from guru99.com.\n",
    "### Url = https://www.guru99.com/\n",
    "### You need to find following details:\n",
    "### A) Name\n",
    "### B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to Selenium Page\n",
    "selenium_page = driver.find_element_by_xpath(\"//li/a[contains(text(),'Selenium')]\")\n",
    "selenium_page.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to Exceptions Page\n",
    "exceptions_page = driver.find_element_by_xpath(\"//td[contains(text(),'Exception')]/preceding::td[1]\")\n",
    "exceptions_page.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the dictionary\n",
    "d = {\n",
    "    'Exception_Name':[],\n",
    "    'Description':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching total number of rows\n",
    "rows = driver.find_elements_by_xpath(\"//table[@class='table table-striped']//tr\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Exception_Name': ['ElementNotVisibleException',\n",
       "  'ElementNotSelectableException',\n",
       "  'NoSuchElementException',\n",
       "  'NoSuchFrameException',\n",
       "  'NoAlertPresentException',\n",
       "  'NoSuchWindowException',\n",
       "  'StaleElementReferenceException',\n",
       "  'SessionNotFoundException',\n",
       "  'TimeoutException',\n",
       "  'WebDriverException',\n",
       "  'ConnectionClosedException',\n",
       "  'ElementClickInterceptedException',\n",
       "  'ElementNotInteractableException',\n",
       "  'ErrorInResponseException',\n",
       "  'ErrorHandler.UnknownServerException',\n",
       "  'ImeActivationFailedException',\n",
       "  'ImeNotAvailableException',\n",
       "  'InsecureCertificateException',\n",
       "  'InvalidArgumentException',\n",
       "  'InvalidCookieDomainException',\n",
       "  'InvalidCoordinatesException',\n",
       "  'InvalidElementStateExceptio',\n",
       "  'InvalidSessionIdException',\n",
       "  'InvalidSwitchToTargetException',\n",
       "  'JavascriptException',\n",
       "  'JsonException',\n",
       "  'NoSuchAttributeException',\n",
       "  'MoveTargetOutOfBoundsException',\n",
       "  'NoSuchContextException',\n",
       "  'NoSuchCookieException',\n",
       "  'NotFoundException',\n",
       "  'RemoteDriverServerException',\n",
       "  'ScreenshotException',\n",
       "  'SessionNotCreatedException',\n",
       "  'UnableToSetCookieException',\n",
       "  'UnexpectedTagNameException',\n",
       "  'UnhandledAlertException',\n",
       "  'UnexpectedAlertPresentException',\n",
       "  'UnknownMethodException',\n",
       "  'UnreachableBrowserException',\n",
       "  'UnsupportedCommandException'],\n",
       " 'Description': ['This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.',\n",
       "  'This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.',\n",
       "  'This Exception occurs if an element could not be found.',\n",
       "  'This Exception occurs if the frame target to be switched to does not exist.',\n",
       "  'This Exception occurs when you switch to no presented alert.',\n",
       "  'This Exception occurs if the window target to be switch does not exist.',\n",
       "  'This Selenium exception occurs happens when the web element is detached from the current DOM.',\n",
       "  'The WebDriver is acting after you quit the browser.',\n",
       "  \"Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn't found in the specified time.\",\n",
       "  'This Exception takes place when the WebDriver is acting right after you close the browser.',\n",
       "  'This type of Exception takes place when there is a disconnection in the driver.',\n",
       "  'The command may not be completed as the element receiving the events is concealing the element which was requested clicked.',\n",
       "  'This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.',\n",
       "  'This happens while interacting with the Firefox extension or the remote driver server.',\n",
       "  'Exception is used as a placeholder in case if the server returns an error without a stack trace.',\n",
       "  'This expectation will occur when IME engine activation has failed.',\n",
       "  'It takes place when IME support is unavailable.',\n",
       "  'Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.',\n",
       "  'It occurs when an argument does not belong to the expected type.',\n",
       "  'This happens when you try to add a cookie under a different domain instead of current URL.',\n",
       "  'This type of Exception matches an interacting operation that is not valid.',\n",
       "  \"It occurs when command can't be finished when the element is invalid.\",\n",
       "  'This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.',\n",
       "  'This occurs when the frame or window target to be switched does not exist.',\n",
       "  'This issue occurs while executing JavaScript given by the user.',\n",
       "  'It occurs when you afford to get the session when the session is not created.',\n",
       "  'This kind of Exception occurs when the attribute of an element could not be found.',\n",
       "  'It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.',\n",
       "  'ContextAware does mobile device testing.',\n",
       "  'This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.',\n",
       "  'This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.',\n",
       "  'This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.',\n",
       "  'It is not possible to capture a screen.',\n",
       "  'It happens when a new session could not be successfully created.',\n",
       "  'This occurs if a driver is unable to set a cookie.',\n",
       "  'Happens if a support class did not get a web element as expected.',\n",
       "  'This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.',\n",
       "  'It occurs when there is the appearance of an unexpected alert.',\n",
       "  'This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.',\n",
       "  'This Exception occurs only when the browser is not able to be opened or crashed because of some reason.',\n",
       "  \"This occurs when remote WebDriver does n't send valid commands as expected.\"]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching 'Exception_Name' and 'Description'\n",
    "for i in range(2,len(rows)+1):\n",
    "    tmp = driver.find_elements_by_xpath(\"//table[@class='table table-striped']//tr[\"+str(i)+\"]/td\")\n",
    "    d['Exception_Name'].append(tmp[0].text)\n",
    "    d['Description'].append(tmp[1].text)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception_Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception_Name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can't be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "### Url = http://statisticstimes.com/\n",
    "### You have to find following details:\n",
    "### A) Rank\n",
    "### B) State\n",
    "### C) GSDP(18-19)\n",
    "### D) GSDP(17-18)\n",
    "### E) Share(2017)\n",
    "### F) GDP ($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to Economy India-Statistics Page\n",
    "ind_stats_page = driver.find_element_by_xpath(\"//button[contains(text(),'Economy')]/following::div[@class='dropdown-content'][1]/a[contains(text(),'India')]\").get_attribute('href')\n",
    "driver.get(ind_stats_page)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to Indian-States GDP Page\n",
    "gdp_states = driver.find_element_by_xpath(\"//a[contains(text(),'» GDP of Indian states')]\").get_attribute('href')\n",
    "driver.get(gdp_states)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the dictionary\n",
    "d = {\n",
    "    'Rank':[],\n",
    "    'State':[],\n",
    "    'GSDP(19-20)':[],\n",
    "    'GSDP(18-19)':[],\n",
    "    'Share(18-19)':[],\n",
    "    'GDP(2019)':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching total number of rows\n",
    "rows = driver.find_elements_by_xpath(\"//table[@id='table_id']/tbody/tr\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rank': ['1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25',\n",
       "  '26',\n",
       "  '27',\n",
       "  '28',\n",
       "  '29',\n",
       "  '30',\n",
       "  '31',\n",
       "  '32',\n",
       "  '33'],\n",
       " 'State': ['Maharashtra',\n",
       "  'Tamil Nadu',\n",
       "  'Uttar Pradesh',\n",
       "  'Gujarat',\n",
       "  'Karnataka',\n",
       "  'West Bengal',\n",
       "  'Rajasthan',\n",
       "  'Andhra Pradesh',\n",
       "  'Telangana',\n",
       "  'Madhya Pradesh',\n",
       "  'Kerala',\n",
       "  'Delhi',\n",
       "  'Haryana',\n",
       "  'Bihar',\n",
       "  'Punjab',\n",
       "  'Odisha',\n",
       "  'Assam',\n",
       "  'Chhattisgarh',\n",
       "  'Jharkhand',\n",
       "  'Uttarakhand',\n",
       "  'Jammu & Kashmir',\n",
       "  'Himachal Pradesh',\n",
       "  'Goa',\n",
       "  'Tripura',\n",
       "  'Chandigarh',\n",
       "  'Puducherry',\n",
       "  'Meghalaya',\n",
       "  'Sikkim',\n",
       "  'Manipur',\n",
       "  'Nagaland',\n",
       "  'Arunachal Pradesh',\n",
       "  'Mizoram',\n",
       "  'Andaman & Nicobar Islands'],\n",
       " 'GSDP(19-20)': ['-',\n",
       "  '1,845,853',\n",
       "  '1,687,818',\n",
       "  '-',\n",
       "  '1,631,977',\n",
       "  '1,253,832',\n",
       "  '1,020,989',\n",
       "  '972,782',\n",
       "  '969,604',\n",
       "  '906,672',\n",
       "  '-',\n",
       "  '856,112',\n",
       "  '831,610',\n",
       "  '611,804',\n",
       "  '574,760',\n",
       "  '521,275',\n",
       "  '-',\n",
       "  '329,180',\n",
       "  '328,598',\n",
       "  '-',\n",
       "  '-',\n",
       "  '165,472',\n",
       "  '80,449',\n",
       "  '55,984',\n",
       "  '-',\n",
       "  '38,253',\n",
       "  '36,572',\n",
       "  '32,496',\n",
       "  '31,790',\n",
       "  '-',\n",
       "  '-',\n",
       "  '26,503',\n",
       "  '-'],\n",
       " 'GSDP(18-19)': ['2,632,792',\n",
       "  '1,630,208',\n",
       "  '1,584,764',\n",
       "  '1,502,899',\n",
       "  '1,493,127',\n",
       "  '1,089,898',\n",
       "  '942,586',\n",
       "  '862,957',\n",
       "  '861,031',\n",
       "  '809,592',\n",
       "  '781,653',\n",
       "  '774,870',\n",
       "  '734,163',\n",
       "  '530,363',\n",
       "  '526,376',\n",
       "  '487,805',\n",
       "  '315,881',\n",
       "  '304,063',\n",
       "  '297,204',\n",
       "  '245,895',\n",
       "  '155,956',\n",
       "  '153,845',\n",
       "  '73,170',\n",
       "  '49,845',\n",
       "  '42,114',\n",
       "  '34,433',\n",
       "  '33,481',\n",
       "  '28,723',\n",
       "  '27,870',\n",
       "  '27,283',\n",
       "  '24,603',\n",
       "  '22,287',\n",
       "  '-'],\n",
       " 'Share(18-19)': ['13.88%',\n",
       "  '8.59%',\n",
       "  '8.35%',\n",
       "  '7.92%',\n",
       "  '7.87%',\n",
       "  '5.75%',\n",
       "  '4.97%',\n",
       "  '4.55%',\n",
       "  '4.54%',\n",
       "  '4.27%',\n",
       "  '4.12%',\n",
       "  '4.08%',\n",
       "  '3.87%',\n",
       "  '2.80%',\n",
       "  '2.77%',\n",
       "  '2.57%',\n",
       "  '1.67%',\n",
       "  '1.60%',\n",
       "  '1.57%',\n",
       "  '1.30%',\n",
       "  '0.82%',\n",
       "  '0.81%',\n",
       "  '0.39%',\n",
       "  '0.26%',\n",
       "  '0.22%',\n",
       "  '0.18%',\n",
       "  '0.18%',\n",
       "  '0.15%',\n",
       "  '0.15%',\n",
       "  '0.14%',\n",
       "  '0.13%',\n",
       "  '0.12%',\n",
       "  '-'],\n",
       " 'GDP(2019)': ['398.145',\n",
       "  '246.529',\n",
       "  '239.656',\n",
       "  '227.276',\n",
       "  '225.798',\n",
       "  '164.820',\n",
       "  '142.543',\n",
       "  '130.501',\n",
       "  '130.210',\n",
       "  '122.431',\n",
       "  '118.206',\n",
       "  '117.180',\n",
       "  '111.024',\n",
       "  '80.204',\n",
       "  '79.601',\n",
       "  '73.768',\n",
       "  '47.769',\n",
       "  '45.982',\n",
       "  '44.945',\n",
       "  '37.186',\n",
       "  '23.584',\n",
       "  '23.265',\n",
       "  '11.065',\n",
       "  '7.538',\n",
       "  '6.369',\n",
       "  '5.207',\n",
       "  '5.063',\n",
       "  '4.344',\n",
       "  '4.215',\n",
       "  '4.126',\n",
       "  '3.721',\n",
       "  '3.370',\n",
       "  '-']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the 'Rank', 'State', 'GSDP(19-20)', 'GSDP(18-19)', 'Share(18-19)', 'GDP(2019)' details\n",
    "str_ = \"//table[@id='table_id']/tbody/tr[\"\n",
    "keys = list(d.keys())\n",
    "for i in range(len(rows)):\n",
    "    path = str_+str(i+1)+\"]/td\"\n",
    "    l = driver.find_elements_by_xpath(path)\n",
    "    for j in range(6):\n",
    "        d[keys[j]].append(l[j].text)\n",
    "d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP(2019)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.88%</td>\n",
       "      <td>398.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.59%</td>\n",
       "      <td>246.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.35%</td>\n",
       "      <td>239.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.92%</td>\n",
       "      <td>227.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.87%</td>\n",
       "      <td>225.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.75%</td>\n",
       "      <td>164.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.97%</td>\n",
       "      <td>142.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.55%</td>\n",
       "      <td>130.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.54%</td>\n",
       "      <td>130.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.27%</td>\n",
       "      <td>122.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.12%</td>\n",
       "      <td>118.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.08%</td>\n",
       "      <td>117.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.87%</td>\n",
       "      <td>111.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.80%</td>\n",
       "      <td>80.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>79.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.57%</td>\n",
       "      <td>73.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.60%</td>\n",
       "      <td>45.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>44.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>23.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20) GSDP(18-19) Share(18-19)  \\\n",
       "0     1                Maharashtra           -   2,632,792       13.88%   \n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208        8.59%   \n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764        8.35%   \n",
       "3     4                    Gujarat           -   1,502,899        7.92%   \n",
       "4     5                  Karnataka   1,631,977   1,493,127        7.87%   \n",
       "5     6                West Bengal   1,253,832   1,089,898        5.75%   \n",
       "6     7                  Rajasthan   1,020,989     942,586        4.97%   \n",
       "7     8             Andhra Pradesh     972,782     862,957        4.55%   \n",
       "8     9                  Telangana     969,604     861,031        4.54%   \n",
       "9    10             Madhya Pradesh     906,672     809,592        4.27%   \n",
       "10   11                     Kerala           -     781,653        4.12%   \n",
       "11   12                      Delhi     856,112     774,870        4.08%   \n",
       "12   13                    Haryana     831,610     734,163        3.87%   \n",
       "13   14                      Bihar     611,804     530,363        2.80%   \n",
       "14   15                     Punjab     574,760     526,376        2.77%   \n",
       "15   16                     Odisha     521,275     487,805        2.57%   \n",
       "16   17                      Assam           -     315,881        1.67%   \n",
       "17   18               Chhattisgarh     329,180     304,063        1.60%   \n",
       "18   19                  Jharkhand     328,598     297,204        1.57%   \n",
       "19   20                Uttarakhand           -     245,895        1.30%   \n",
       "20   21            Jammu & Kashmir           -     155,956        0.82%   \n",
       "21   22           Himachal Pradesh     165,472     153,845        0.81%   \n",
       "22   23                        Goa      80,449      73,170        0.39%   \n",
       "23   24                    Tripura      55,984      49,845        0.26%   \n",
       "24   25                 Chandigarh           -      42,114        0.22%   \n",
       "25   26                 Puducherry      38,253      34,433        0.18%   \n",
       "26   27                  Meghalaya      36,572      33,481        0.18%   \n",
       "27   28                     Sikkim      32,496      28,723        0.15%   \n",
       "28   29                    Manipur      31,790      27,870        0.15%   \n",
       "29   30                   Nagaland           -      27,283        0.14%   \n",
       "30   31          Arunachal Pradesh           -      24,603        0.13%   \n",
       "31   32                    Mizoram      26,503      22,287        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP(2019)  \n",
       "0    398.145  \n",
       "1    246.529  \n",
       "2    239.656  \n",
       "3    227.276  \n",
       "4    225.798  \n",
       "5    164.820  \n",
       "6    142.543  \n",
       "7    130.501  \n",
       "8    130.210  \n",
       "9    122.431  \n",
       "10   118.206  \n",
       "11   117.180  \n",
       "12   111.024  \n",
       "13    80.204  \n",
       "14    79.601  \n",
       "15    73.768  \n",
       "16    47.769  \n",
       "17    45.982  \n",
       "18    44.945  \n",
       "19    37.186  \n",
       "20    23.584  \n",
       "21    23.265  \n",
       "22    11.065  \n",
       "23     7.538  \n",
       "24     6.369  \n",
       "25     5.207  \n",
       "26     5.063  \n",
       "27     4.344  \n",
       "28     4.215  \n",
       "29     4.126  \n",
       "30     3.721  \n",
       "31     3.370  \n",
       "32         -  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of trending repositories on Github.com.\n",
    "### Url = https://github.com/\n",
    "### You have to find the following details:\n",
    "### A) Repository title\n",
    "### B) Repository description\n",
    "### C) Contributors count\n",
    "### D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"http://github.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to trending repositories\n",
    "tending_git = driver.find_element_by_xpath(\"//a[contains(text(),'Trending')]\").get_attribute('href')\n",
    "driver.get(tending_git)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting trending repositories\n",
    "repos = driver.find_elements_by_xpath(\"//article/h1/a\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting trending repositories links\n",
    "repo_links = []\n",
    "for i in repos:\n",
    "    repo_links.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the dictionary\n",
    "d = {\n",
    "    'Repository_title':[],\n",
    "    'Repository_desc':[],\n",
    "    'Contributors_count':[],\n",
    "    'Languages_used':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Repository_title': ['VaccineNotifier',\n",
       "  'Kubernetes The Hard Way',\n",
       "  'OnlyFans DataScraper (Python 3.9.X)',\n",
       "  'Self-Supervised Vision Transformers with DINO',\n",
       "  'docs',\n",
       "  'CoWIN vaccination slot availability using Python',\n",
       "  'flashlight',\n",
       "  'wave',\n",
       "  'tldr',\n",
       "  'whatfreewords',\n",
       "  'The Algorithms - JavaScript',\n",
       "  'Dogecoin Core [DOGE, Ð]',\n",
       "  'The Fuck',\n",
       "  'Table of Contents',\n",
       "  'COVID-19 Vaccine Tracker',\n",
       "  'vfat-tools',\n",
       "  'Fork Explorer',\n",
       "  'The Art of Command Line',\n",
       "  'linux',\n",
       "  'tips',\n",
       "  'Chroma — A general purpose syntax highlighter in pure Go',\n",
       "  'AWS Amplify CLI',\n",
       "  'The Solidity Contract-Oriented Programming Language',\n",
       "  'Interactsh',\n",
       "  'Ionic Framework'],\n",
       " 'Repository_desc': [\"VaccineNotifier\\nVaccineNotifier checks the cowin portal periodically to find vaccination slots available in your pin code and for your age. If found, it will send you emails every minute until the slots are available.\\nSteps to run the script:\\nStep 1) Enable application access on your gmail with steps given here: https://support.google.com/accounts/answer/185833?p=InvalidSecondFactor&visit_id=637554658548216477-2576856839&rd=1\\n\\nStep 2) Enter the details in the file .env, present in the same folder\\n\\nStep 3) On your terminal run: npm i && pm2 start vaccineNotifier.js\\n\\nTo close the app run: pm2 stop vaccineNotifier.js && pm2 delete vaccineNotifier.js\\nHere's a sample of the resultant emails:\",\n",
       "  \"Kubernetes The Hard Way\\nThis tutorial walks you through setting up Kubernetes the hard way. This guide is not for people looking for a fully automated command to bring up a Kubernetes cluster. If that's you then check out Google Kubernetes Engine, or the Getting Started Guides.\\nKubernetes The Hard Way is optimized for learning, which means taking the long route to ensure you understand each task required to bootstrap a Kubernetes cluster.\\nThe results of this tutorial should not be viewed as production ready, and may receive limited support from the community, but don't let that stop you from learning!\\nCopyright\\n\\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\\nTarget Audience\\nThe target audience for this tutorial is someone planning to support a production Kubernetes cluster and wants to understand how everything fits together.\\nCluster Details\\nKubernetes The Hard Way guides you through bootstrapping a highly available Kubernetes cluster with end-to-end encryption between components and RBAC authentication.\\nkubernetes v1.21.0\\ncontainerd v1.4.4\\ncoredns v1.8.3\\ncni v0.9.1\\netcd v3.4.15\\nLabs\\nThis tutorial assumes you have access to the Google Cloud Platform. While GCP is used for basic infrastructure requirements the lessons learned in this tutorial can be applied to other platforms.\\nPrerequisites\\nInstalling the Client Tools\\nProvisioning Compute Resources\\nProvisioning the CA and Generating TLS Certificates\\nGenerating Kubernetes Configuration Files for Authentication\\nGenerating the Data Encryption Config and Key\\nBootstrapping the etcd Cluster\\nBootstrapping the Kubernetes Control Plane\\nBootstrapping the Kubernetes Worker Nodes\\nConfiguring kubectl for Remote Access\\nProvisioning Pod Network Routes\\nDeploying the DNS Cluster Add-on\\nSmoke Test\\nCleaning Up\",\n",
       "  'OnlyFans DataScraper (Python 3.9.X)\\nMandatory Tutorial\\nRead the #FAQ at the bottom of this page before submitting a issue.\\nRunning the app via docker\\nBuild and run the image, mounting the appropriate directories:\\ndocker build -t only-fans . && docker run -it --rm --name onlyfans -v ${PWD}/.settings:/usr/src/app/.settings -v ${PWD}/.profiles:/usr/src/app/.profiles -v ${PWD}/.sites:/usr/src/app/.sites only-fans\\nRunning on Linux\\nhttps://github.com/DIGITALCRIMINAL/OnlyFans/discussions/889\\nRunning the app locally\\nFrom the project folder open CMD/Terminal and run the command below:\\npip install -r requirements.txt\\nStart:\\npython start_ofd.py or double click start_ofd.py\\nOpen and edit:\\n.profiles/default/auth.json\\n[auth]\\nFill in the following:\\n{\"auth_id\":\"your_auth_id\"}\\n{\"sess\":\"your_sess_token\"}\\n{\"user-agent\":\"your_user-agent\"}\\nIf you\\'re using 2FA or have these cookies:\\n{\"auth_hash\":\"your_auth_hash\"}\\n{\"auth_uniq_\":\"your_auth_uniq_\"}\\nOptional change:\\n{\"app-token\":\"your_token\"}\\nOnly enter in cookies that reflect your OnlyFans account otherwise, you\\'ll get auth errors.\\nGo to www.onlyfans.com and login, open the network debugger, then check the image below on how to get said above cookies\\n(Instead of typing \"?app\", type \"api2\")\\nYour auth config should look similar to this\\nIf you want to auth via browser, add your email and password.\\nIf you get auth attempt errors, only YOU can fix it unless you\\'re willing to let me into your account so I can see if it\\'s working or not. All issues about auth errors will be closed automatically. It\\'s spam at this point, there\\'s like 1000s of them and I don\\'t care for anyone who can\\'t use the search function lmao.\\nNote: If active is set to False, the script will ignore the profile.\\nUSAGE\\npython start_ofd.py or double click start_ofd.py\\nEnter in inputs as prompted by console.\\nOPTIONAL\\nOpen:\\nconfig.json (Open with a texteditor)\\n[settings]\\nprofile_directories:\\nWhere your account information is stored (auth.json).\\nDefault = [\".profiles\"]\\n\\nIf you\\'re going to fill, please remember to use forward (\"/\") slashes only.\\ndownload_directories:\\nWhere downloaded content is stored.\\nDefault = [\".sites\"]\\n\\nIf you\\'re going to fill, please remember to use forward (\"/\") slashes only.\\n\\nYou can add multiple directories and the script will automatically rollover to the next directory if the current is full.\\nmetadata_directories:\\nWhere metadata content is stored.\\nDefault = [\".sites\"]\\n\\nIf you\\'re going to fill, please remember to use forward (\"/\") slashes only.\\n\\nAutomatic rollover not supported yet.\\npath_formatting:\\nOverview for file_directory_format, filename_format and metadata_directory_format\\n{site_name} = The site you\\'re scraping.\\n\\n{first_letter} = First letter of the model you\\'re scraping.\\n\\n{post_id} = The posts\\' ID.\\n\\n{media_id} = The media\\'s ID.\\n\\n{username} = The account\\'s username.\\n\\n{api_type} = Posts, Messages, etc.\\n\\n{media_type} = Images, Videos, etc.\\n\\n{filename} = The media\\'s filename.\\n\\n{value} = Value of the content. Paid or Free.\\n\\n{text} = The media\\'s text.\\n\\n{date} = The post\\'s creation date.\\n\\n{ext} = The media\\'s file extension.\\n\\nDon\\'t use the text variable. If you do, enjoy emojis in your filepaths and errors lmao.\\nfile_directory_format:\\nThis puts each media file into a folder.\\nThe list below are unique identifiers that you must include.\\nYou can choose one or more.\\nDefault = \"{site_name}/{username}/{api_type}/{value}/{media_type}\"\\nDefault Translated = \"OnlyFans/belledelphine/Posts/Free/Images\"\\n\\n{username} = belledelphine\\nfilename_format:\\nUsage: Format for a filename\\nThe list below are unique identifiers that you must include.\\nYou must choose one or more.\\nDefault = \"{filename}.{ext}\"\\nDefault Translated = \"5fb5a5e4b4ce6c47ce2b4_source.mp4\"\\n\\n{filename} = 5fb5a5e4b4ce6c47ce2b4_source\\n{media_id} = 133742069\\nmetadata_directory_format:\\nUsage: Filepath for metadata. It\\'s tied with download_directories so ignore metadata_directories in the config.\\nThe list below are unique identifiers that you must include.\\nYou must choose one or more.\\nDefault = \"{site_name}/{username}/Metadata\"\\nDefault Translated = \"OnlyFans/belledelphine/Metadata\"\\n\\n{username} = belledelphine\\ntext_length:\\nUsage: When you use {text} in filename_format, a limit of how many characters can be set by inputting a number.\\nDefault = \"\"\\nIdeal = \"50\"\\nMax = \"255\"\\n\\nThe ideal is actually 0.\\nvideo_quality:\\nUsage: Select the resolution of the video.\\nDefault = \"source\"\\n720p = \"720\" | \"720p\"\\n240p = \"240\" | \"240p\"\\nauto_site_choice:\\nUsage: You can automatically choose which site you want to scrape.\\nDefault = \"\"\\n\\nOnlyFans = \"onlyfans\"\\nauto_choice:\\nUsage: You can automatically choose which media type you want to scrape. Default = \"\"\\nEverything = \"a\"\\nImages = \"b\"\\nVideos = \"c\"\\nAudios = \"d\"\\n\\nYou can automatically choose which type of media you want to scrape.\\nauto_scrape_names:\\nDefault = false\\n\\nIf set to true, the script will scrape all the names.\\nauto_scrape_apis:\\nDefault = true\\n\\nIf set to false, you\\'ll be given the option to scrape individual apis.\\njobs:\\n\"scrape_names\" - This will scrape your standard content\\n\"scrape_paid_content\" - This will scrape paid content\\n\\nIf set to false, it won\\'t do the job.\\nexport_type:\\nDefault = \"json\"\\n\\nJSON = \"json\"\\n\\nYou can export an archive to different formats (not anymore lol).\\noverwrite_files:\\nDefault = false\\n\\nIf set to true, any file with the same name will be redownloaded.\\ndate_format:\\nDefault = \"%d-%m-%Y\"\\n\\nIf you live in the USA and you want to use the incorrect format, use the following:\\n\\n\"%m-%d-%Y\"\\nmax_threads:\\nDefault = -1\\n\\nWhen number is set below 1, it will use all threads.\\nSet a number higher than 0 to limit threads.\\nmin_drive_space:\\nDefault = 0\\nType: Float\\n\\nSpace is calculated in GBs.\\n0.5 is 500mb, 1 is 1gb,etc.\\nWhen a drive goes below minimum drive space, it will move onto the next drive or go into an infinite loop until drive is above the minimum space.\\nwebhooks:\\nDefault = []\\n\\nSupported webhooks:\\nDiscord\\n\\nData is sent whenever you\\'ve completely downloaded a model.\\nYou can also put in your own custom url and parse the data.\\nNeed another webhook? Open an issue.\\nexit_on_completion:\\nDefault = false\\n\\nIf set to true the scraper run once and exit upon completion, otherwise the scraper will give the option to run again. This is useful if the scraper is being executed by a cron job or another script.\\ninfinite_loop:\\nDefault = true\\n\\nIf set to false, the script will run once and ask you to input anything to continue.\\nloop_timeout:\\nDefault = 0\\n\\nWhen infinite_loop is set to true this will set the time in seconds to pause the loop in between runs.\\nboards:\\nDefault = []\\nExample = [\"s\", \"gif\"]\\n\\nInput boards names that you want to automatically scrape.\\nignored_keywords:\\nDefault = []\\nExample = [\"ignore\", \"me\"]\\n\\nAny words you input, the script will ignore any content that contains these words.\\nignore_type:\\nDefault = \"\"\\na = \"paid\"\\nb = \"free\"\\n\\nThis setting will not include any paid or free accounts in your subscription list.\\n\\nExample: \"ignore_type\": \"paid\"\\n\\nThis choice will not include any accounts that you\\'ve paid for.\\nexport_metadata:\\nDefault = true\\n\\nSet to false if you don\\'t want to save metadata.\\nblacklist_name:\\nDefault = \"\"\\n\\nThis setting will not include any blacklisted usernames when you choose the \"scrape all\" option.\\n\\nGo to https://onlyfans.com/my/lists and create a new list; you can name it whatever you want but I called mine \"Blacklisted\".\\n\\nAdd the list\\'s name to the config.\\n\\nExample: \"blacklist_name\": \"Blacklisted\"\\n\\nYou can create as many lists as you want.\\nFAQ\\nBefore troubleshooting, make sure you\\'re using Python 3.9 and the latest commit of the script.\\nError: Access Denied / Auth Loop\\nMake sure your cookies and user-agent are correct. Use this tool Cookie Helper\\nAttributeError: type object \\'datetime.datetime\\' has no attribute \\'fromisoformat\\'\\nOnly works with Python 3.7 and above.\\nI can\\'t see \".settings\" folder\\'\\nMake sure you can see hidden files\\nWindows Tutorial\\nMac Tutorial\\nLinux\\nI\\'m getting authed into the wrong account\\nEnjoy the free content. | This has been patched lol.\\nI\\'m using Linux OS and something isn\\'t working.\\nScript was built on Windows 10. If you\\'re using Linux you can still submit an issue and I\\'ll try my best to fix it.\\nAm I able to bypass paywalls with this script?\\nHell yeah! My open source script can bypass paywalls for free. Tutorial\\nDo OnlyFans or OnlyFans models know I\\'m using this script?\\nOnlyFans may know that you\\'re using this script, but I try to keep it as anon as possible.\\nGenerally, models will not know unless OnlyFans tells them but there is identifiable information in the metadata folder which contains your IP address, so don\\'t share it unless you\\'re using a proxy/vpn or just don\\'t care.\\nDo you collect session information?\\nNo. The code is on Github which allows you to audit the codebase yourself. You can use wireshark or any other network analysis program to verify the outgoing connections are respective to the modules you chose.\\nDisclaimer:\\nOnlyFans is a registered trademark of Fenix International Limited.\\nThe contributors of this script isn\\'t in any way affiliated with, sponsored by, or endorsed by Fenix International Limited.\\nThe contributors of this script are not responsible for the end users\\' actions.\\nLMAO',\n",
       "  \"Self-Supervised Vision Transformers with DINO\\nPyTorch implementation and pretrained models for DINO. For details, see Emerging Properties in Self-Supervised Vision Transformers.\\n[blogpost] [arXiv] [Yannic Kilcher's video]\\nPretrained models\\nYou can choose to download only the weights of the pretrained backbone used for downstream tasks, or the full checkpoint which contains backbone and projection head weights for both student and teacher networks. We also provide the training and evaluation logs.\\narch params k-nn linear download\\nDeiT-S/16 21M 74.5% 77.0% backbone only full checkpoint args logs eval logs\\nDeiT-S/8 21M 78.3% 79.7% backbone only full checkpoint args logs eval logs\\nViT-B/16 85M 76.1% 78.2% backbone only full checkpoint args logs eval logs\\nViT-B/8 85M 77.4% 80.1% backbone only full checkpoint args logs eval logs\\nResNet-50 23M 67.5% 75.3% backbone only full checkpoint args logs eval logs\\nThe pretrained models are available on PyTorch Hub.\\nimport torch\\ndeits16 = torch.hub.load('facebookresearch/dino:main', 'dino_deits16')\\ndeits8 = torch.hub.load('facebookresearch/dino:main', 'dino_deits8')\\nvitb16 = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\\nvitb8 = torch.hub.load('facebookresearch/dino:main', 'dino_vitb8')\\nresnet50 = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50')\\nTraining\\nDocumentation\\nPlease install PyTorch and download the ImageNet dataset. This codebase has been developed with python version 3.6, PyTorch version 1.7.1, CUDA 11.0 and torchvision 0.8.2. The exact arguments to reproduce the models presented in our paper can be found in the args column of the pretrained models section. For a glimpse at the full documentation of DINO training please run:\\npython main_dino.py --help\\nVanilla DINO training 🦕\\nRun DINO with DeiT-small network on a single node with 8 GPUs for 100 epochs with the following command. Training time is 1.75 day and the resulting checkpoint should reach 69.3% on k-NN eval and ~73.8% on linear eval. We provide training and linear evaluation logs for this run to help reproducibility.\\npython -m torch.distributed.launch --nproc_per_node=8 main_dino.py --arch deit_small --data_path /path/to/imagenet/train --output_dir /path/to/saving_dir\\nMulti-node training\\nWe use Slurm and submitit (pip install submitit). To train on 2 nodes with 8 GPUs each (total 16 GPUs):\\npython run_with_submitit.py --nodes 2 --ngpus 8 --arch deit_small --data_path /path/to/imagenet/train --output_dir /path/to/saving_dir\\nDINO with ViT-base network.\\nBoosting DINO performance 🦖\\nYou can improve the performance of the vanilla run by:\\ntraining for more epochs: --epochs 300,\\nincreasing the teacher temperature: --teacher_temp 0.07 --warmup_teacher_temp_epochs 30.\\nremoving last layer normalization (only safe with --arch deit_small): --norm_last_layer false,\\nFull command.\\nThe resulting pretrained model should reach 73.3% on k-NN eval and ~76.1% on linear eval. Training time is 2.6 days with 16 GPUs. We provide training and linear evaluation logs for this run to help reproducibility.\\nResNet-50 and other convnets trainings\\nThis code also works for training DINO on convolutional networks, like ResNet-50 for example. We highly recommend to adapt some optimization arguments in this case. For example following is a command to train DINO on ResNet-50 on a single node with 8 GPUs for 100 epochs. We provide training logs for this run.\\npython -m torch.distributed.launch --nproc_per_node=8 main_dino.py --arch resnet50 --optimizer sgd --weight_decay 1e-4 --weight_decay_end 1e-4 --global_crops_scale 0.14 1 --local_crops_scale 0.05 0.14 --data_path /path/to/imagenet/train --output_dir /path/to/saving_dir\\nSelf-attention visualization\\nYou can look at the self-attention of the [CLS] token on the different heads of the last layer by running:\\npython visualize_attention.py\\nAlso, check out this colab for video inference.\\nEvaluation: k-NN classification on ImageNet\\nTo evaluate a simple k-NN classifier with a single GPU on a pre-trained model, run:\\npython -m torch.distributed.launch --nproc_per_node=1 eval_knn.py --data_path /path/to/imagenet\\nIf you choose not to specify --pretrained_weights, then DINO reference weights are used by default. If you want instead to evaluate checkpoints from a run of your own, you can run for example:\\npython -m torch.distributed.launch --nproc_per_node=1 eval_knn.py --pretrained_weights /path/to/checkpoint.pth --checkpoint_key teacher --data_path /path/to/imagenet \\nEvaluation: Linear classification on ImageNet\\nTo train a supervised linear classifier on frozen weights on a single node with 8 gpus, run:\\npython -m torch.distributed.launch --nproc_per_node=8 eval_linear.py --data_path /path/to/imagenet\\nLicense\\nSee the LICENSE file for more details.\\nCitation\\nIf you find this repository useful, please consider giving a star ⭐ and citation 🦖:\\n@article{caron2021emerging,\\n  title={Emerging Properties in Self-Supervised Vision Transformers},\\n  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J\\\\'egou, Herv\\\\'e  and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},\\n  journal={arXiv preprint arXiv:2104.14294},\\n  year={2021}\\n}\",\n",
       "  \"GitHub Docs\\nThis repository contains the documentation website code and Markdown source files for docs.github.com.\\nGitHub's Docs team works on pre-production content in a private repo that regularly syncs with this public repo.\\nIn this article:\\nContributing\\nREADMEs\\nLicense\\nContributing\\nStart contributing right now:\\nWe accept a lot of different contributions, including some that don't require you to write a single line of code.\\nClick make a contribution from docs\\nAs you're using GitHub Docs, you may find something in an article that you'd like to add to, update, or change. Click on make a contribution to navigate directly to that article in the codebase, so that you can begin making your contribution.\\nOpen an issue\\nIf you've found a problem, you can open an issue using a template.\\nSolve an issue\\nIf you have a solution to one of the open issues, you will need to fork the repository and submit a pull request using the template that is visible automatically in the pull request body. For more details about this process, please check out Getting Started with Contributing.\\nJoin us in discussions\\nWe use GitHub Discussions to talk about all sorts of topics related to documentation and this site. For example: if you'd like help troubleshooting a PR, have a great new idea, or want to share something amazing you've learned in our docs, join us in discussions.\\nAnd that's it!\\nThat's how you can get started easily as a member of the GitHub Documentation community. ✨\\nIf you want to know more, or you're making a more complex contribution, check out Getting Started with Contributing.\\nThere are a few more things to know when you're getting started with this repo:\\nIf you're having trouble with your GitHub account, contact Support.\\nWe do not accept pull requests for translated content - see CONTRIBUTING.md for more information.\\nREADMEs\\nIn addition to the README you're reading right now, this repo includes other READMEs that describe the purpose of each subdirectory in more detail:\\ncontent/README.md\\ncontent/graphql/README.md\\ncontent/rest/README.md\\ncontributing/README.md\\ndata/README.md\\ndata/reusables/README.md\\ndata/variables/README.md\\nincludes/liquid-tags/README.md\\nincludes/README.md\\njavascripts/README.md\\nlayouts/README.md\\nlib/liquid-tags/README.md\\nmiddleware/README.md\\nscript/README.md\\nstylesheets/README.md\\ntests/README.md\\nLicense\\nThe GitHub product documentation in the assets, content, and data folders are licensed under a CC-BY license.\\nAll other code in this repository is licensed under a MIT license.\\nWhen using the GitHub logos, be sure to follow the GitHub logo guidelines.\",\n",
       "  'CoWIN vaccination slot availability using Python\\nScript to check the available slots for Covid-19 Vaccination Centers from CoWIN API in India\\nLink to the Website\\nLink to the article',\n",
       "  'Quickstart | Installation | Documentation\\nFlashlight is a fast, flexible machine learning library written entirely in C++ from the Facebook AI Research Speech team and the creators of Torch and Deep Speech. Its core features include:\\nJust-in-time kernel compilation with modern C++ with the ArrayFire tensor library.\\nCUDA and CPU backends for GPU and CPU training.\\nAn emphasis on efficiency and scale.\\nNative support in C++ and simple extensibility makes Flashlight a powerful research framework that\\'s hackable to its core and enables fast iteration on new experimental setups and algorithms without sacrificing performance. In a single repository, Flashlight provides apps for research across multiple domains:\\nAutomatic speech recognition (the wav2letter project) — Documentation | Tutorial\\nImage classification\\nObject detection\\nLanguage modeling\\nProject Layout\\nFlashlight is broken down into a few parts:\\nflashlight/lib contains kernels and standalone utilities for sequence losses, beam search decoding, text processing, and more.\\nflashlight/fl is the core neural network library using the ArrayFire tensor library.\\nflashlight/app are applications of the core library to machine learning across domains.\\nflashlight/ext are extensions on top of Flashlight and ArrayFire that are useful across apps.\\nQuickstart\\nFirst, build and install Flashlight and link it to your own project.\\nSequential forms a sequence of Flashlight Modules for chaining computation.\\nImplementing a simple convnet is easy.\\nSee the MNIST example for a full tutorial including a training loop and dataset abstractions.\\nVariable is the base Flashlight tensor that operates on ArrayFire arrays. Tape-based Automatic differentiation in Flashlight is simple and works as you\\'d expect.\\nAutograd Example\\nBuilding and Installing\\nInstall with vcpkg | With Docker | From Source | From Source with vcpkg | Build Your Project with Flashlight\\nRequirements\\nAt minimum, compilation requires:\\nA C++ compiler with good C++17 support (e.g. gcc/g++ >= 7)\\nCMake — version 3.10 or later, and make\\nA Linux-based operating system.\\nSee the full dependency list for more details if building from source.\\nInstructions for building/installing Python bindings can be found here.\\nFlashlight Build Setups\\nFlashlight can be broken down into several components as described above. Each component can be incrementally built by specifying the correct build options.\\nThere are two ways to work with Flashlight:\\nAs an installed library that you link to with your own project. This is best for building standalone applications dependent on Flashlight.\\nWith in-source development where the Flashlight project source is changed and rebuilt. This is best if customizing/hacking the core framework or the Flashlight-provided app binaries.\\nFlashlight can be built in one of two ways:\\nWith vcpkg, a C++ package manager.\\nFrom source by installing dependencies as needed.\\nInstalling Flashlight with vcpkg\\nLibrary Installation with vcpkg\\nFlashlight is most-easily built and installed with vcpkg. Both the CUDA and CPU backends are supported with vcpkg. For either backend, first install Intel MKL. For the CUDA backend, install CUDA >= 9.2, cuDNN, and NCCL. Then, after installing vcpkg, install the libraries and core with:\\n./vcpkg/vcpkg install flashlight-cuda # CUDA backend, OR\\n./vcpkg/vcpkg install flashlight-cpu  # CPU backend\\nTo install Flashlight apps, check the features available for installation by running ./vcpkg search flashlight-cuda or ./vcpkg search flashlight-cpu. Each app is a \"feature\": for example, ./vcpkg install flashlight-cuda[asr] installs the ASR app with the CUDA backend.\\nBelow is the currently-supported list of features (for each of flashlight-cuda and flashlight-cpu):\\nflashlight-{cuda/cpu}[lib]      # Flashlight libraries\\nflashlight-{cuda/cpu}[nn]       # Flashlight neural net library\\nflashlight-{cuda/cpu}[asr]      # Flashlight speech recognition app\\nflashlight-{cuda/cpu}[lm]       # Flashlight language modeling app\\nflashlight-{cuda/cpu}[imgclass] # Flashlight image classification app\\nFlashlight app binaries are also built for the selected features and are installed into the vcpkg install tree\\'s tools directory.\\nIntegrating Flashlight into your own project with is simple using vcpkg\\'s CMake toolchain integration.\\nFrom-Source Build with vcpkg\\nFirst, install the dependencies for your backend of choice using vcpkg (click to expand the below):\\nInstalling CUDA Backend Dependencies with vcpkg\\nInstalling CPU Backend Dependencies with vcpkg\\nBuild Using the vcpkg Toolchain File\\nTo build Flashlight from source with these dependencies, clone the repository:\\ngit clone https://github.com/flashlight/flashlight.git && cd flashlight\\nmkdir -p build && cd build\\nThen, build from source using vcpkg\\'s CMake toolchain:\\ncmake .. \\\\\\n    -DCMAKE_BUILD_TYPE=Release\\n    -DFL_BACKEND=CUDA\\n    -DCMAKE_TOOLCHAIN_FILE=[path to your vcpkg clone]/scripts/buildsystems/vcpkg.cmake\\nmake -j$(nproc)\\nmake install -j$(nproc) # only if you want to install Flashlight for external use\\nTo build a subset of Flashlight\\'s features, see the build options below.\\nBuilding from Source\\nTo build from source, first install the below dependencies. Most are available with your system\\'s local package manager.\\nSome dependencies marked below are downloaded and installed automatically if not found on the local system. FL_BUILD_STANDALONE determines this behavior — if disabled, dependencies won\\'t be downloaded and built when building Flashlight.\\nOnce all dependencies are installed, clone the repository:\\ngit clone https://github.com/flashlight/flashlight.git && cd flashlight\\nmkdir -p build && cd build\\nThen build all Flashlight components with:\\ncmake .. -DCMAKE_BUILD_TYPE=Release -DFL_BACKEND=[backend] [...build options]\\nmake -j$(nproc)\\nmake install\\nSetting the MKLROOT environment variable (export MKLROOT=/opt/intel/oneapi/mkl/latest or export MKLROOT=/opt/intel/mkl on most Linux-based systems) can help CMake find Intel MKL if not initially found.\\nTo build a smaller subset of Flashlight features/apps, see the build options below for a complete list of options.\\nTo install Flashlight in a custom directory, use CMake\\'s CMAKE_INSTALL_PREFIX argument. Flashlight libraries can be built as shared libraries using CMake\\'s BUILD_SHARED_LIBS argument.\\nFlashlight uses modern CMake and IMPORTED targets for most dependencies. If a dependency isn\\'t found, passing -D<package>_DIR to your cmake command or exporting <package>_DIR as an environment variable equal to the path to <package>Config.cmake can help locate dependencies on your system. See the documentation for more details. If CMake is failing to locate a package, check to see if a corresponding issue has already been created before creating your own.\\nDependencies\\nDependencies marked with * are automatically downloaded and built from source if not found on the system. Setting FL_BUILD_STANDALONE to OFF disables this behavior.\\nDependencies marked with ^ are required if building with distributed training enabled (FL_BUILD_DISTRIBUTED — see the build options below). Distributed training is required for all apps.\\nDependencies marked with † are installable via vcpkg. See the instructions for installing those dependencies above for doing a Flashlight from-source build.\\nComponent Backend Dependencies\\nlibraries CUDA CUDA >= 9.2, CUB*† (if CUDA < 11)\\nCPU A BLAS library (Intel MKL >= 2018, OpenBLAS†, etc)\\ncore Any ArrayFire >= 3.7.3†, an MPI library^(OpenMPI†, etc),  cereal*† >= 1.3.0, stb*†\\nCUDA CUDA >= 9.2, NCCL^, cuDNN\\nCPU oneDNN† >= 2.0, gloo (with MPI)*^†\\napp: all Any Google Glog†, Gflags†\\napp: asr Any libsndfile*† >= 10.0.28, a BLAS library (Intel MKL >= 2018, OpenBLAS†, etc)\\napp: imgclass Any -\\napp: objdet Any -\\napp: lm Any -\\ntests Any Google Test (gtest, with gmock)*† >= 1.10.0\\nBuild Options\\nThe Flashlight CMake build accepts the following build options (prefixed with -D when running CMake from the command line):\\nName Options Default Value Description\\nFL_BACKEND CUDA, CPU, OPENCL CUDA Backend with which to build all components.\\nFL_BUILD_STANDALONE ON, OFF ON Downloads/builds some dependencies if not found.\\nFL_BUILD_LIBRARIES ON, OFF ON Build the Flashlight libraries.\\nFL_BUILD_CORE ON, OFF ON Build the Flashlight neural net library.\\nFL_BUILD_DISTRIBUTED ON, OFF ON Build with distributed training; required for apps.\\nFL_BUILD_CONTRIB ON, OFF ON Build contrib APIs subject to breaking changes.\\nFL_BUILD_ALL_APPS ON, OFF OFF Defines default value for every app (see below).\\nFL_BUILD_APP_ASR ON, OFF FL_BUILD_ALL_APPS Build the automatic speech recognition app.\\nFL_BUILD_APP_IMGCLASS ON, OFF FL_BUILD_ALL_APPS Build the image classification app.\\nFL_BUILD_APP_OBJDET ON, OFF FL_BUILD_ALL_APPS Build automatic speech recognition app tools.\\nFL_BUILD_APP_LM ON, OFF FL_BUILD_ALL_APPS Build the language modeling app.\\nFL_BUILD_APP_ASR_TOOLS ON, OFF FL_BUILD_APP_ASR Build automatic speech recognition app tools.\\nFL_BUILD_TESTS ON, OFF ON Build tests.\\nFL_BUILD_EXAMPLES ON, OFF ON Build examples.\\nFL_BUILD_EXPERIMENTAL ON, OFF OFF Build experimental components.\\nCMAKE_BUILD_TYPE See docs. Debug See the CMake documentation.\\nCMAKE_INSTALL_PREFIX [Directory] See docs. See the CMake documentation.\\nBuilding Your Own Project with Flashlight\\nFlashlight is most-easily linked to using CMake. Flashlight exports the following CMake targets when installed:\\nflashlight::fl-libraries — contains flashlight libraries headers and symbols.\\nflashlight::flashlight — contains flashlight libraries as well as the flashlight core autograd and neural network library.\\nflashlight::flashlight-app-asr — contains the automatic speech recognition app along with the flashlight core and flashlight libraries.\\nflashlight::flashlight-app-imgclass — contains the image classification app along with the flashlight core and flashlight libraries.\\nflashlight::flashlight-app-objdet — contains the object detection app along with the flashlight core and flashlight libraries.\\nflashlight::flashlight-app-lm — contains the language modeling app along with the flashlight core and flashlight libraries.\\nGiven a simple project.cpp file that includes and links to Flashlight:\\n#include <iostream>\\n\\n#include <arrayfire.h>\\n#include <flashlight/fl/flashlight.h>\\n\\nint main() {\\n fl::Variable v(af::constant(1, 1), true);\\n auto result = v + 10;\\n std::cout << \"Hello World!\" << std::endl;\\n af::print(\"Array value is \", result.array()); // 11.000\\n return 0;\\n}\\nThe following CMake configuration links Flashlight and sets include directories:\\ncmake_minimum_required(VERSION 3.10)\\nset(CMAKE_CXX_STANDARD 17)\\nset(CMAKE_CXX_STANDARD_REQUIRED ON)\\n\\nadd_executable(myProject project.cpp)\\n\\nfind_package(flashlight CONFIG REQUIRED)\\ntarget_link_libraries(myProject PRIVATE flashlight::flashlight)\\nWith a vcpkg Flashlight Installation\\nIf you installed Flashlight with vcpkg, the above CMake configuration for myProject can be built by running:\\ncd project && mkdir build && cd build\\ncmake .. \\\\\\n  -DCMAKE_TOOLCHAIN_FILE=[path to vcpkg clone]/scripts/buildsystems/vcpkg.cmake \\\\\\n  -DCMAKE_BUILD_TYPE=Release\\nmake -j$(nproc)\\nWith a From-Source Flashlight Installation\\nIf using a from-source installation of Flashlight, Flashlight will be found automatically by CMake:\\ncd project && mkdir build && cd build\\ncmake .. -DCMAKE_BUILD_TYPE=Release\\nmake -j$(nproc)\\nIf Flashlight is installed in a custom location using a CMAKE_INSTALL_PREFIX, passing -Dflashlight_DIR=[install prefix]/share/flashlight/cmake as an argument to your cmake command can help CMake find Flashlight.\\nBuilding and Running Flashlight with Docker\\nFlashlight and its dependencies can also be built with the provided Dockerfiles — see the accompanying Docker documentation for more information.\\nContributing and Contact\\nContact: vineelkpratap@fb.com, awni@fb.com, jacobkahn@fb.com, qiantong@fb.com, antares@fb.com, padentomasello@fb.com, jcai@fb.com, gab@fb.com, vitaliy888@fb.com, locronan@fb.com\\nFlashlight is being very actively developed. See CONTRIBUTING for more on how to help out.\\nAcknowledgments\\nSome of Flashlight\\'s code is derived from arrayfire-ml.\\nLicense\\nFlashlight is under a BSD license. See LICENSE for more information.',\n",
       "  \"Introduction\\nWave is a Software as a Service Starter Kit that can help you build your next great idea 💰. Wave is built with Laravel, Voyager, TailwindCSS, and a few other awesome technologies. Here are some of the awesome features ✨:\\nAuthentication\\nUser Profiles\\nUser Impersonation\\nSubscriptions\\nSubscription Plans\\nUser Roles\\nNotifications\\nAnnouncements\\nFully Functional Blog\\nOut of the Box API\\nVoyager Admin\\nCustomizable Themes\\nDemo\\nView a live demo here, or deploy your own instance to DigitalOcean, by clicking the button below.\\nInstallation\\nTo install Wave, you'll want to clone or download this repo:\\ngit clone https://github.com/thedevdojo/wave.git project_name\\nNext, we can install Wave with these 4 simple steps:\\n1. Create a New Database\\nDuring the installation we need to use a MySQL database. You will need to create a new database and save the credentials for the next step.\\n2. Copy the .env.example file\\nWe need to specify our Environment variables for our application. You will see a file named .env.example, you will need to duplicate that file and rename it to .env.\\nThen, open up the .env file and update your DB_DATABASE, DB_USERNAME, and DB_PASSWORD in the appropriate fields. You will also want to update the APP_URL to the URL of your application.\\nAPP_URL=http://wave.test\\n\\nDB_CONNECTION=mysql\\nDB_HOST=127.0.0.1\\nDB_PORT=3306\\nDB_DATABASE=wave\\nDB_USERNAME=root\\nDB_PASSWORD=\\n3. Add Composer Dependencies\\nNext, we will need to install all our composer dependencies by running the following command:\\ncomposer install\\n4. Run Migrations and Seeds\\nWe need to migrate our database structure into our database, which we can do by running:\\nphp artisan migrate\\n\\nFinally, we will need to seed our database with the following command:\\nphp artisan db:seed\\n\\n🎉 And that's it! You will now be able to visit your URL and see your Wave application up and running.\\nWatch, Learn, and Build\\nWe've also got a full video series on how you can setup, build, and configure Wave. 🍿 You can watch first few videos for free, and additional videos will require a DevDojo Pro subscription. By subscribing to a DevDojo Pro subscription you will also be supporting the ongoing development of this project. It's a win win! 🙌\\nClick here to watch the Wave Video Series.\\nDocumentation\\nCheckout the official documentation here.\",\n",
       "  'What is tldr-pages?\\nThe tldr-pages project is a collection of community-maintained help pages for command-line tools, that aims to be a simpler, more approachable complement to traditional man pages.\\nMaybe you are new to the command-line world? Or just a little rusty? Or perhaps you can\\'t always remember the arguments to lsof, or tar?\\nIt certainly doesn\\'t help that the first option explained in man tar is:\\n-b blocksize\\n   Specify the block size, in 512-byte records, for tape drive I/O.\\n   As a rule, this argument is only needed when reading from or writing to tape drives,\\n   and usually not even then as the default block size of 20 records (10240 bytes) is very common.\\nThere seems to be room for simpler help pages, focused on practical examples. How about:\\nThis repository is just that: an ever-growing collection of examples for the most common UNIX, Linux, macOS, SunOS and Windows command-line tools.\\nHow do I use it?\\nA popular and convenient way to access these pages on your computer is to install the Node.js client, which is supported by the tldr-pages project maintainers:\\nnpm install -g tldr\\nThat way you can write tldr tar in the terminal to show the tldr page for tar, just like you would write man tar to show its manpage.\\nHowever, if you just want to browse without installing anything, check out the PDF version.\\nThere are also various other clients provided by the community, both for the command line and for other platforms:\\nAlfred Workflow\\ntldr-alfred\\nalfred-tldr\\nAlbert Plugin\\nAndroid clients:\\ntldroid, available on Google Play (outdated)\\ntldr-flutter, available on Google Play or F-Droid\\nBash clients:\\ntldr-sh-client\\ntldr-bash-client\\nC# client\\nC client: brew install tldr\\nChrome Extension available on Chrome Web Store\\nCrystal client: brew install porras/tap/tlcr\\nDart client: pub global activate tldr\\nDash docset: Open Preferences > Downloads > User Contributed and find tldr pages in the list\\nDiscord Bot: Follow the building instructions or use a privately hosted version\\nDocker images:\\ntldr-docker - Run the tldr command via a docker container: alias tldr=\\'docker run --rm -it -v ~/.tldr/:/root/.tldr/ nutellinoit/tldr\\'\\nElixir clients:\\nExTldr.\\nTLDR Elixir Client (binaries not yet available)\\nEmacs client, available on MELPA\\nGo clients:\\ngithub.com/pranavraja/tldr: go get github.com/pranavraja/tldr (or platform binaries)\\nhttps://github.com/leighmcculloch/tldr: go get 4d63.com/tldr or brew install 4d63/tldr/tldr (or platform binaries)\\ngithub.com/elecprog/tldr: go get github.com/elecprog/tldr (or platform binaries)\\ngithub.com/isacikgoz/tldr: go get github.com/isacikgoz/tldr (or platform binaries)\\ngithub.com/HardDie/myTldr: go get github.com/HardDie/myTldr (or platform binaries) (supports custom pages directories)\\niOS clients:\\ntldr-man-page, available on App Store\\ntldr-pages, available on App Store\\nHaskell clients:\\ntldr-hs: stack install tldr or apt-get install tldr on Debian-based distributions\\nfast-tldr\\nJava client\\nKeypirinha Plugin\\nNode.js client: npm install -g tldr\\nOCaml client: opam install tldr\\nOutfieldr: A Zig client\\nPerl5 client: cpanm App::tldr\\nPHP client: composer global require brainmaestro/tldr\\nPython clients:\\ntldr-python-client: pip install tldr or pacman -S tldr on Arch Linux\\ntldr.py: pip install tldr.py or apt-get install tldr-py on Debian-based distributions\\nR client: devtools::install_github(\\'kirillseva/tldrrr\\')\\nRuby client: gem install tldrb\\nRust client: cargo install tealdeer or brew install tealdeer\\nVim Client\\nVisual Studio Code extension available on Visual Studio Code Marketplace\\nWeb clients:\\ntldr.dendron.so: https://tldr.dendron.so\\ntldr.jsx: http://tldr.ostera.io\\ntldr.finzzz.net: https://tldr.finzzz.net\\nDistroWatch\\ntldr.ooops.me: web client with multilingual support\\nTLDR Persian: Web Client in Persian\\nThere is also a comprehensive list of clients in our Wiki.\\nHow do I contribute?\\nYour favourite command isn\\'t covered?\\nYou can think of more examples for an existing command?\\nAll tldr pages are kept as Markdown files right here in this repository, so you can edit them directly and submit your changes as pull requests.\\nAll contributions are welcome! We strive to maintain a welcoming and collaborative community. Have a look at the contributing guidelines, and go ahead!\\nIf you\\'d like to contribute to translations, you can visit https://lukwebsforge.github.io/tldri18n/ to see the current progress of all translations.\\nSimilar projects\\nCheat allows you to create and view interactive cheatsheets on the command-line. It was designed to help remind *nix system administrators of options for commands that they use frequently, but not frequently enough to remember.\\nBro pages are a highly readable supplement to man pages. Bro pages show concise, common-case examples for Unix commands. The examples are submitted by the user base, and can be voted up or down; the best entries are what people see first when they look up a command.\\nkb is a minimalist command line knowledge base manager. kb can be used to organize your notes and cheatsheets in a minimalist and clean way. It supports also non-text files.\\neg provides detailed examples with explanations on the command line. Examples come from the repository, but eg supports displaying custom examples and commands alongside the defaults.\\ndevhints Rico\\'s cheatsheets are not just focused on the command line and include a plethora of other cheatsheets related to programming.\\nWhat does \"tldr\" mean?\\nTL;DR stands for \"Too Long; Didn\\'t Read\". It originates in Internet slang, where it is used to indicate that a long text (or parts of it) has been skipped as too lengthy. Read more in How-To Geek\\'s article.',\n",
       "  'This was a small test to show how one might reversibly map each ~1m^2 element of the globe onto a 3-tuple of words. Check it out here.\\nTo do this we needed three things:\\nA function which maps metre-accurate (latitude, longitude) pairs into three 5-digit integers below 40k.\\nAn ordered list of 40k words which acts as a bijection between integers and words.\\nA scrambling function which can be called in the first function to ensure nearby (latitude,longitude) pairs are mapped to very different integers\\nNote that all of these functions must be invertible for the mapping to be reversible.\\nThe scrambling function implemented here is inspired by format preserving encryption: it maps a sequence of 14 digits to another by passing it through a Feistel network. There is no need for this encryption to be secure, so the implementation has been simplifed. The point is just to map 14-digits to 14-digits, to exhibit sensitive dependence on the input and to be reversible.',\n",
       "  'The Algorithms - JavaScript\\n    All algorithms implemented in JavaScript (for educational purposes only)\\n  These are for demonstration purposes only. There are many implementations of sorts in the JavaScript standard library that are much better for performance reasons.\\nContribution Guidelines\\nRead our Contribution Guidelines before you contribute.\\nList of Algorithms\\nSee our directory.\\nAlgorithm Explanation\\nsee our wiki',\n",
       "  'Dogecoin Core [DOGE, Ð]\\nDogecoin is a cryptocurrency like Bitcoin, although it does not use SHA256 as its proof of work (POW). Taking development cues from Tenebrix and Litecoin, Dogecoin currently employs a simplified variant of scrypt.\\nWebsite: dogecoin.com.\\nLicense – Much license ⚖️\\nDogecoin Core is released under the terms of the MIT license. See COPYING for more information or see opensource.org\\nDevelopment and contributions – omg developers\\nDevelopment is ongoing, and the development team, as well as other volunteers, can freely work in their own trees and submit pull requests when features or bug fixes are ready.\\nVersion strategy\\nVersion numbers are following major.minor.patch semantics.\\nBranches\\nThere are 3 types of branches in this repository:\\nmaster: Stable, contains the latest version of the latest major.minor release.\\nmaintenance: Stable, contains the latest version of previous releases, which are still under active maintenance. Format: <version>-maint\\ndevelopment: Unstable, contains new code for planned releases. Format: <version>-dev\\nMaster and maintenance branches are exclusively mutable by release. Planned releases will always have a development branch and pull requests should be submitted against those. Maintenance branches are there for bug fixes only, please submit new features against the development branch with the highest version.\\nContributions ✍️\\nDevelopers are strongly encouraged to write unit tests for new code, and to submit new unit tests for old code. Unit tests can be compiled and run (assuming they weren\\'t disabled in configure) with: make check. Further details on running and extending unit tests can be found in /src/test/README.md.\\nThere are also regression and integration tests of the RPC interface, written in Python, that are run automatically on the build server. These tests can be run (if the test dependencies are installed) with: qa/pull-tester/rpc-tests.py\\nChanges should be tested by somebody other than the developer who wrote the code. This is especially important for large or high-risk changes. It is useful to add a test plan to the pull request description if testing the changes is not straightforward.\\nVery Much Frequently Asked Questions ❓\\nHow much doge can exist? – So many puppies! 🐕\\nEarly 2015 (approximately a year and a half after release) there will be approximately 100,000,000,000 coins. Each subsequent block will grant 10,000 coins to encourage miners to continue to secure the network and make up for lost wallets on hard drives/phones/lost encryption passwords/etc.\\nSuch mining information ⛏\\nDogecoin uses a simplified variant of the scrypt key derivation function as its proof of work with a target time of one minute per block and difficulty readjustment after every block. The block rewards are fixed and halve every 100,000 blocks. Starting with the 600,000th block, a permanent reward of 10,000 Dogecoin per block will be issued.\\nOriginally, a different payout scheme was envisioned with block rewards being determined by taking the maximum reward as per the block schedule and applying the result of a Mersenne Twister pseudo-random number generator to arrive at a number between 0 and the maximum reward.\\nThis was changed starting with block 145,000, to prevent large pools from gaming the system and mining only high reward blocks. At the same time, the difficulty retargeting was also changed from four hours to once per block (every minute), implementing an algorithm courtesy of the DigiByte Coin development team, to lessen the impact of sudden increases and decreases of network hashing rate.\\nThe current block reward schedule:\\n1–99,999: 0–1,000,000 Dogecoin\\n100,000–144,999: 0–500,000 Dogecoin\\n145,000–199,999: 250,000 Dogecoin\\n200,000–299,999: 125,000 Dogecoin\\n300,000–399,999: 62,500 Dogecoin\\n400,000–499,999: 31,250 Dogecoin\\n500,000–599,999: 15,625 Dogecoin\\n600,000+: 10,000 Dogecoin\\nThe original block reward schedule, with one-minute block targets and four-hour difficulty readjustment:\\n1–99,999: 0–1,000,000 Dogecoin\\n100,000–199,999: 0–500,000 Dogecoin\\n200,000–299,999: 0–250,000 Dogecoin\\n300,000–399,999: 0–125,000 Dogecoin\\n400,000–499,999: 0–62,500 Dogecoin\\n500,000–599,999: 0–31,250 Dogecoin\\n600,000+: 10,000 Dogecoin\\nWow plz make dogecoind/dogecoin-cli/dogecoin-qt\\nThe following are developer notes on how to build Dogecoin on your native platform. They are not complete guides, but include notes on the necessary libraries, compile flags, etc.\\nOSX Build Notes\\nUnix Build Notes\\nWindows Build Notes\\nSuch ports\\nRPC 22555\\nP2P 22556\\nDevelopment tips and tricks\\ncompiling for debugging\\nRun configure with the --enable-debug option, then make. Or run configure with CXXFLAGS=\"-g -ggdb -O0\" or whatever debug flags you need.\\ndebug.log\\nIf the code is behaving strangely, take a look in the debug.log file in the data directory; error and debugging messages are written there.\\nThe -debug=... command-line option controls debugging; running with just -debug will turn on all categories (and give you a very large debug.log file).\\nThe Qt code routes qDebug() output to debug.log under category \"qt\": run with -debug=qt to see it.\\ntestnet and regtest modes\\nRun with the -testnet option to run with \"play dogecoins\" on the test network, if you are testing multi-machine code that needs to operate across the internet.\\nIf you are testing something that can run on one machine, run with the -regtest option. In regression test mode, blocks can be created on-demand; see qa/rpc-tests/ for tests that run in -regtest mode.\\nDEBUG_LOCKORDER\\nDogecoin Core is a multithreaded application, and deadlocks or other multithreading bugs can be very difficult to track down. Compiling with -DDEBUG_LOCKORDER (configure CXXFLAGS=\"-DDEBUG_LOCKORDER -g\") inserts run-time checks to keep track of which locks are held, and adds warnings to the debug.log file if inconsistencies are detected.',\n",
       "  'The Fuck\\nThe Fuck is a magnificent app, inspired by a @liamosaur tweet, that corrects errors in previous console commands.\\nIs The Fuck too slow? Try the experimental instant mode!\\nMore examples:\\n➜ apt-get install vim\\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\\n\\n➜ fuck\\nsudo apt-get install vim [enter/↑/↓/ctrl+c]\\n[sudo] password for nvbn:\\nReading package lists... Done\\n...\\n➜ git push\\nfatal: The current branch master has no upstream branch.\\nTo push the current branch and set the remote as upstream, use\\n\\n    git push --set-upstream origin master\\n\\n\\n➜ fuck\\ngit push --set-upstream origin master [enter/↑/↓/ctrl+c]\\nCounting objects: 9, done.\\n...\\n➜ puthon\\nNo command \\'puthon\\' found, did you mean:\\n Command \\'python\\' from package \\'python-minimal\\' (main)\\n Command \\'python\\' from package \\'python3\\' (main)\\nzsh: command not found: puthon\\n\\n➜ fuck\\npython [enter/↑/↓/ctrl+c]\\nPython 3.4.2 (default, Oct  8 2014, 13:08:17)\\n...\\n➜ git brnch\\ngit: \\'brnch\\' is not a git command. See \\'git --help\\'.\\n\\nDid you mean this?\\n    branch\\n\\n➜ fuck\\ngit branch [enter/↑/↓/ctrl+c]\\n* master\\n➜ lein rpl\\n\\'rpl\\' is not a task. See \\'lein help\\'.\\n\\nDid you mean this?\\n         repl\\n\\n➜ fuck\\nlein repl [enter/↑/↓/ctrl+c]\\nnREPL server started on port 54848 on host 127.0.0.1 - nrepl://127.0.0.1:54848\\nREPL-y 0.3.1\\n...\\nIf you\\'re not afraid of blindly running corrected commands, the require_confirmation settings option can be disabled:\\n➜ apt-get install vim\\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\\n\\n➜ fuck\\nsudo apt-get install vim\\n[sudo] password for nvbn:\\nReading package lists... Done\\n...\\nContents\\nRequirements\\nInstallations\\nUpdating\\nHow it works\\nCreating your own rules\\nSettings\\nThird party packages with rules\\nExperimental instant mode\\nDeveloping\\nLicense\\nRequirements\\npython (3.4+)\\npip\\npython-dev\\nBack to Contents\\nInstallation\\nOn OS X, you can install The Fuck via Homebrew (or via Linuxbrew on Linux):\\nbrew install thefuck\\nOn Ubuntu / Mint, install The Fuck with the following commands:\\nsudo apt update\\nsudo apt install python3-dev python3-pip python3-setuptools\\nsudo pip3 install thefuck\\nOn FreeBSD, install The Fuck with the following commands:\\npkg install thefuck\\nOn ChromeOS, install The Fuck using chromebrew with the following command:\\ncrew install thefuck\\nOn other systems, install The Fuck by using pip:\\npip install thefuck\\nAlternatively, you may use an OS package manager (OS X, Ubuntu, Arch).\\n# It is recommended that you place this command in your .bash_profile, .bashrc, .zshrc or other startup script:\\neval $(thefuck --alias)\\n# You can use whatever you want as an alias, like for Mondays:\\neval $(thefuck --alias FUCK)\\nOr in your shell config (Bash, Zsh, Fish, Powershell, tcsh).\\nChanges are only available in a new shell session. To make changes immediately available, run source ~/.bashrc (or your shell config file like .zshrc).\\nTo run fixed commands without confirmation, use the --yeah option (or just -y for short, or --hard if you\\'re especially frustrated):\\nfuck --yeah\\nTo fix commands recursively until succeeding, use the -r option:\\nfuck -r\\nBack to Contents\\nUpdating\\npip3 install thefuck --upgrade\\nNote: Alias functionality was changed in v1.34 of The Fuck\\nHow it works\\nThe Fuck attempts to match the previous command with a rule. If a match is found, a new command is created using the matched rule and executed. The following rules are enabled by default:\\nadb_unknown_command – fixes misspelled commands like adb logcta;\\nag_literal – adds -Q to ag when suggested;\\naws_cli – fixes misspelled commands like aws dynamdb scan;\\naz_cli – fixes misspelled commands like az providers;\\ncargo – runs cargo build instead of cargo;\\ncargo_no_command – fixes wrongs commands like cargo buid;\\ncat_dir – replaces cat with ls when you try to cat a directory;\\ncd_correction – spellchecks and correct failed cd commands;\\ncd_cs – changes cs to cd;\\ncd_mkdir – creates directories before cd\\'ing into them;\\ncd_parent – changes cd.. to cd ..;\\nchmod_x – add execution bit;\\nchoco_install – append common suffixes for chocolatey packages;\\ncomposer_not_command – fixes composer command name;\\nconda_mistype – fixes conda commands;\\ncp_create_destination – creates a new directory when you attempt to cp or mv to a non existent one\\ncp_omitting_directory – adds -a when you cp directory;\\ncpp11 – adds missing -std=c++11 to g++ or clang++;\\ndirty_untar – fixes tar x command that untarred in the current directory;\\ndirty_unzip – fixes unzip command that unzipped in the current directory;\\ndjango_south_ghost – adds --delete-ghost-migrations to failed because ghosts django south migration;\\ndjango_south_merge – adds --merge to inconsistent django south migration;\\ndocker_login – executes a docker login and repeats the previous command;\\ndocker_not_command – fixes wrong docker commands like docker tags;\\ndocker_image_being_used_by_container ‐ removes the container that is using the image before removing the image;\\ndry – fixes repetitions like git git push;\\nfab_command_not_found – fix misspelled fabric commands;\\nfix_alt_space – replaces Alt+Space with Space character;\\nfix_file – opens a file with an error in your $EDITOR;\\ngem_unknown_command – fixes wrong gem commands;\\ngit_add – fixes \"pathspec \\'foo\\' did not match any file(s) known to git.\";\\ngit_add_force – adds --force to git add <pathspec>... when paths are .gitignore\\'d;\\ngit_bisect_usage – fixes git bisect strt, git bisect goood, git bisect rset, etc. when bisecting;\\ngit_branch_delete – changes git branch -d to git branch -D;\\ngit_branch_delete_checked_out – changes git branch -d to git checkout master && git branch -D when trying to delete a checked out branch;\\ngit_branch_exists – offers git branch -d foo, git branch -D foo or git checkout foo when creating a branch that already exists;\\ngit_branch_list – catches git branch list in place of git branch and removes created branch;\\ngit_checkout – fixes branch name or creates new branch;\\ngit_clone_git_clone – replaces git clone git clone ... with git clone ...\\ngit_commit_amend – offers git commit --amend after previous commit;\\ngit_commit_reset – offers git reset HEAD~ after previous commit;\\ngit_diff_no_index – adds --no-index to previous git diff on untracked files;\\ngit_diff_staged – adds --staged to previous git diff with unexpected output;\\ngit_fix_stash – fixes git stash commands (misspelled subcommand and missing save);\\ngit_flag_after_filename – fixes fatal: bad flag \\'...\\' after filename\\ngit_help_aliased – fixes git help <alias> commands replacing with the aliased command;\\ngit_hook_bypass – adds --no-verify flag previous to git am, git commit, or git push command;\\ngit_lfs_mistype – fixes mistyped git lfs <command> commands;\\ngit_merge – adds remote to branch names;\\ngit_merge_unrelated – adds --allow-unrelated-histories when required\\ngit_not_command – fixes wrong git commands like git brnch;\\ngit_pull – sets upstream before executing previous git pull;\\ngit_pull_clone – clones instead of pulling when the repo does not exist;\\ngit_pull_uncommitted_changes – stashes changes before pulling and pops them afterwards;\\ngit_push – adds --set-upstream origin $branch to previous failed git push;\\ngit_push_different_branch_names – fixes pushes when local brach name does not match remote branch name;\\ngit_push_pull – runs git pull when push was rejected;\\ngit_push_without_commits – Creates an initial commit if you forget and only git add ., when setting up a new project;\\ngit_rebase_no_changes – runs git rebase --skip instead of git rebase --continue when there are no changes;\\ngit_remote_delete – replaces git remote delete remote_name with git remote remove remote_name;\\ngit_rm_local_modifications – adds -f or --cached when you try to rm a locally modified file;\\ngit_rm_recursive – adds -r when you try to rm a directory;\\ngit_rm_staged – adds -f or --cached when you try to rm a file with staged changes\\ngit_rebase_merge_dir – offers git rebase (--continue | --abort | --skip) or removing the .git/rebase-merge dir when a rebase is in progress;\\ngit_remote_seturl_add – runs git remote add when git remote set_url on nonexistent remote;\\ngit_stash – stashes your local modifications before rebasing or switching branch;\\ngit_stash_pop – adds your local modifications before popping stash, then resets;\\ngit_tag_force – adds --force to git tag <tagname> when the tag already exists;\\ngit_two_dashes – adds a missing dash to commands like git commit -amend or git rebase -continue;\\ngo_run – appends .go extension when compiling/running Go programs;\\ngo_unknown_command – fixes wrong go commands, for example go bulid;\\ngradle_no_task – fixes not found or ambiguous gradle task;\\ngradle_wrapper – replaces gradle with ./gradlew;\\ngrep_arguments_order – fixes grep arguments order for situations like grep -lir . test;\\ngrep_recursive – adds -r when you try to grep directory;\\ngrunt_task_not_found – fixes misspelled grunt commands;\\ngulp_not_task – fixes misspelled gulp tasks;\\nhas_exists_script – prepends ./ when script/binary exists;\\nheroku_multiple_apps – add --app <app> to heroku commands like heroku pg;\\nheroku_not_command – fixes wrong heroku commands like heroku log;\\nhistory – tries to replace command with most similar command from history;\\nhostscli – tries to fix hostscli usage;\\nifconfig_device_not_found – fixes wrong device names like wlan0 to wlp2s0;\\njava – removes .java extension when running Java programs;\\njavac – appends missing .java when compiling Java files;\\nlein_not_task – fixes wrong lein tasks like lein rpl;\\nlong_form_help – changes -h to --help when the short form version is not supported\\nln_no_hard_link – catches hard link creation on directories, suggest symbolic link;\\nln_s_order – fixes ln -s arguments order;\\nls_all – adds -A to ls when output is empty;\\nls_lah – adds -lah to ls;\\nman – changes manual section;\\nman_no_space – fixes man commands without spaces, for example mandiff;\\nmercurial – fixes wrong hg commands;\\nmissing_space_before_subcommand – fixes command with missing space like npminstall;\\nmkdir_p – adds -p when you try to create a directory without parent;\\nmvn_no_command – adds clean package to mvn;\\nmvn_unknown_lifecycle_phase – fixes misspelled life cycle phases with mvn;\\nnpm_missing_script – fixes npm custom script name in npm run-script <script>;\\nnpm_run_script – adds missing run-script for custom npm scripts;\\nnpm_wrong_command – fixes wrong npm commands like npm urgrade;\\nno_command – fixes wrong console commands, for example vom/vim;\\nno_such_file – creates missing directories with mv and cp commands;\\nomnienv_no_such_command – fixes wrong commands for goenv, nodenv, pyenv and rbenv (eg.: pyenv isntall or goenv list);\\nopen – either prepends http:// to address passed to open or create a new file or directory and passes it to open;\\npip_install – fixes permission issues with pip install commands by adding --user or prepending sudo if necessary;\\npip_unknown_command – fixes wrong pip commands, for example pip instatl/pip install;\\nphp_s – replaces -s by -S when trying to run a local php server;\\nport_already_in_use – kills process that bound port;\\nprove_recursively – adds -r when called with directory;\\npython_command – prepends python when you try to run non-executable/without ./ python script;\\npython_execute – appends missing .py when executing Python files;\\npython_module_error – fixes ModuleNotFoundError by trying to pip install that module;\\nquotation_marks – fixes uneven usage of \\' and \" when containing args\\';\\npath_from_history – replaces not found path with similar absolute path from history;\\nreact_native_command_unrecognized – fixes unrecognized react-native commands;\\nremove_shell_prompt_literal – remove leading shell prompt symbol $, common when copying commands from documentations;\\nremove_trailing_cedilla – remove trailing cedillas ç, a common typo for european keyboard layouts;\\nrm_dir – adds -rf when you try to remove a directory;\\nscm_correction – corrects wrong scm like hg log to git log;\\nsed_unterminated_s – adds missing \\'/\\' to sed\\'s s commands;\\nsl_ls – changes sl to ls;\\nssh_known_hosts – removes host from known_hosts on warning;\\nsudo – prepends sudo to previous command if it failed because of permissions;\\nsudo_command_from_user_path – runs commands from users $PATH with sudo;\\nswitch_lang – switches command from your local layout to en;\\nsystemctl – correctly orders parameters of confusing systemctl;\\nterraform_init.py – run terraform init before plan or apply;\\ntest.py – runs py.test instead of test.py;\\ntouch – creates missing directories before \"touching\";\\ntsuru_login – runs tsuru login if not authenticated or session expired;\\ntsuru_not_command – fixes wrong tsuru commands like tsuru shell;\\ntmux – fixes tmux commands;\\nunknown_command – fixes hadoop hdfs-style \"unknown command\", for example adds missing \\'-\\' to the command on hdfs dfs ls;\\nunsudo – removes sudo from previous command if a process refuses to run on super user privilege.\\nvagrant_up – starts up the vagrant instance;\\nwhois – fixes whois command;\\nworkon_doesnt_exists – fixes virtualenvwrapper env name os suggests to create new.\\nyarn_alias – fixes aliased yarn commands like yarn ls;\\nyarn_command_not_found – fixes misspelled yarn commands;\\nyarn_command_replaced – fixes replaced yarn commands;\\nyarn_help – makes it easier to open yarn documentation;\\nBack to Contents\\nThe following rules are enabled by default on specific platforms only:\\napt_get – installs app from apt if it not installed (requires python-commandnotfound / python3-commandnotfound);\\napt_get_search – changes trying to search using apt-get with searching using apt-cache;\\napt_invalid_operation – fixes invalid apt and apt-get calls, like apt-get isntall vim;\\napt_list_upgradable – helps you run apt list --upgradable after apt update;\\napt_upgrade – helps you run apt upgrade after apt list --upgradable;\\nbrew_cask_dependency – installs cask dependencies;\\nbrew_install – fixes formula name for brew install;\\nbrew_reinstall – turns brew install <formula> into brew reinstall <formula>;\\nbrew_link – adds --overwrite --dry-run if linking fails;\\nbrew_uninstall – adds --force to brew uninstall if multiple versions were installed;\\nbrew_unknown_command – fixes wrong brew commands, for example brew docto/brew doctor;\\nbrew_update_formula – turns brew update <formula> into brew upgrade <formula>;\\ndnf_no_such_command – fixes mistyped DNF commands;\\nnixos_cmd_not_found – installs apps on NixOS;\\npacman – installs app with pacman if it is not installed (uses yay or yaourt if available);\\npacman_invalid_option – replaces lowercase pacman options with uppercase.\\npacman_not_found – fixes package name with pacman, yay or yaourt.\\nyum_invalid_operation – fixes invalid yum calls, like yum isntall vim;\\nThe following commands are bundled with The Fuck, but are not enabled by default:\\ngit_push_force – adds --force-with-lease to a git push (may conflict with git_push_pull);\\nrm_root – adds --no-preserve-root to rm -rf / command.\\nBack to Contents\\nCreating your own rules\\nTo add your own rule, create a file named your-rule-name.py in ~/.config/thefuck/rules. The rule file must contain two functions:\\nmatch(command: Command) -> bool\\nget_new_command(command: Command) -> str | list[str]\\nAdditionally, rules can contain optional functions:\\nside_effect(old_command: Command, fixed_command: str) -> None\\nRules can also contain the optional variables enabled_by_default, requires_output and priority.\\nCommand has three attributes: script, output and script_parts. Your rule should not change Command.\\nRules api changed in 3.0: To access a rule\\'s settings, import it with from thefuck.conf import settings\\nsettings is a special object assembled from ~/.config/thefuck/settings.py, and values from env (see more below).\\nA simple example rule for running a script with sudo:\\ndef match(command):\\n    return (\\'permission denied\\' in command.output.lower()\\n            or \\'EACCES\\' in command.output)\\n\\n\\ndef get_new_command(command):\\n    return \\'sudo {}\\'.format(command.script)\\n\\n# Optional:\\nenabled_by_default = True\\n\\ndef side_effect(command, fixed_command):\\n    subprocess.call(\\'chmod 777 .\\', shell=True)\\n\\npriority = 1000  # Lower first, default is 1000\\n\\nrequires_output = True\\nMore examples of rules, utility functions for rules, app/os-specific helpers.\\nBack to Contents\\nSettings\\nSeveral The Fuck parameters can be changed in the file $XDG_CONFIG_HOME/thefuck/settings.py ($XDG_CONFIG_HOME defaults to ~/.config):\\nrules – list of enabled rules, by default thefuck.const.DEFAULT_RULES;\\nexclude_rules – list of disabled rules, by default [];\\nrequire_confirmation – requires confirmation before running new command, by default True;\\nwait_command – max amount of time in seconds for getting previous command output;\\nno_colors – disable colored output;\\npriority – dict with rules priorities, rule with lower priority will be matched first;\\ndebug – enables debug output, by default False;\\nhistory_limit – numeric value of how many history commands will be scanned, like 2000;\\nalter_history – push fixed command to history, by default True;\\nwait_slow_command – max amount of time in seconds for getting previous command output if it in slow_commands list;\\nslow_commands – list of slow commands;\\nnum_close_matches – maximum number of close matches to suggest, by default 3.\\nexcluded_search_path_prefixes – path prefixes to ignore when searching for commands, by default [].\\nAn example of settings.py:\\nrules = [\\'sudo\\', \\'no_command\\']\\nexclude_rules = [\\'git_push\\']\\nrequire_confirmation = True\\nwait_command = 10\\nno_colors = False\\npriority = {\\'sudo\\': 100, \\'no_command\\': 9999}\\ndebug = False\\nhistory_limit = 9999\\nwait_slow_command = 20\\nslow_commands = [\\'react-native\\', \\'gradle\\']\\nnum_close_matches = 5\\nOr via environment variables:\\nTHEFUCK_RULES – list of enabled rules, like DEFAULT_RULES:rm_root or sudo:no_command;\\nTHEFUCK_EXCLUDE_RULES – list of disabled rules, like git_pull:git_push;\\nTHEFUCK_REQUIRE_CONFIRMATION – require confirmation before running new command, true/false;\\nTHEFUCK_WAIT_COMMAND – max amount of time in seconds for getting previous command output;\\nTHEFUCK_NO_COLORS – disable colored output, true/false;\\nTHEFUCK_PRIORITY – priority of the rules, like no_command=9999:apt_get=100, rule with lower priority will be matched first;\\nTHEFUCK_DEBUG – enables debug output, true/false;\\nTHEFUCK_HISTORY_LIMIT – how many history commands will be scanned, like 2000;\\nTHEFUCK_ALTER_HISTORY – push fixed command to history true/false;\\nTHEFUCK_WAIT_SLOW_COMMAND – max amount of time in seconds for getting previous command output if it in slow_commands list;\\nTHEFUCK_SLOW_COMMANDS – list of slow commands, like lein:gradle;\\nTHEFUCK_NUM_CLOSE_MATCHES – maximum number of close matches to suggest, like 5.\\nTHEFUCK_EXCLUDED_SEARCH_PATH_PREFIXES – path prefixes to ignore when searching for commands, by default [].\\nFor example:\\nexport THEFUCK_RULES=\\'sudo:no_command\\'\\nexport THEFUCK_EXCLUDE_RULES=\\'git_pull:git_push\\'\\nexport THEFUCK_REQUIRE_CONFIRMATION=\\'true\\'\\nexport THEFUCK_WAIT_COMMAND=10\\nexport THEFUCK_NO_COLORS=\\'false\\'\\nexport THEFUCK_PRIORITY=\\'no_command=9999:apt_get=100\\'\\nexport THEFUCK_HISTORY_LIMIT=\\'2000\\'\\nexport THEFUCK_NUM_CLOSE_MATCHES=\\'5\\'\\nBack to Contents\\nThird-party packages with rules\\nIf you\\'d like to make a specific set of non-public rules, but would still like to share them with others, create a package named thefuck_contrib_* with the following structure:\\nthefuck_contrib_foo\\n  thefuck_contrib_foo\\n    rules\\n      __init__.py\\n      *third-party rules*\\n    __init__.py\\n    *third-party-utils*\\n  setup.py\\nThe Fuck will find rules located in the rules module.\\nBack to Contents\\nExperimental instant mode\\nThe default behavior of The Fuck requires time to re-run previous commands. When in instant mode, The Fuck saves time by logging output with script, then reading the log.\\nCurrently, instant mode only supports Python 3 with bash or zsh. zsh\\'s autocorrect function also needs to be disabled in order for thefuck to work properly.\\nTo enable instant mode, add --enable-experimental-instant-mode to the alias initialization in .bashrc, .bash_profile or .zshrc.\\nFor example:\\neval $(thefuck --alias --enable-experimental-instant-mode)\\nBack to Contents\\nDeveloping\\nSee CONTRIBUTING.md\\nLicense MIT\\nProject License can be found here.\\nBack to Contents',\n",
       "  'Table of Contents\\nWhat is openpilot?\\nIntegration with Stock Features\\nSupported Hardware\\nSupported Cars\\nCommunity Maintained Cars and Features\\nInstallation Instructions\\nLimitations of openpilot ALC and LDW\\nLimitations of openpilot ACC and FCW\\nLimitations of openpilot DM\\nUser Data and comma Account\\nSafety and Testing\\nTesting on PC\\nCommunity and Contributing\\nDirectory Structure\\nLicensing\\nWhat is openpilot?\\nopenpilot is an open source driver assistance system. Currently, openpilot performs the functions of Adaptive Cruise Control (ACC), Automated Lane Centering (ALC), Forward Collision Warning (FCW) and Lane Departure Warning (LDW) for a growing variety of supported car makes, models and model years. In addition, while openpilot is engaged, a camera based Driver Monitoring (DM) feature alerts distracted and asleep drivers.\\nIntegration with Stock Features\\nIn all supported cars:\\nStock Lane Keep Assist (LKA) and stock ALC are replaced by openpilot ALC, which only functions when openpilot is engaged by the user.\\nStock LDW is replaced by openpilot LDW.\\nAdditionally, on specific supported cars (see ACC column in supported cars):\\nStock ACC is replaced by openpilot ACC.\\nopenpilot FCW operates in addition to stock FCW.\\nopenpilot should preserve all other vehicle\\'s stock features, including, but are not limited to: FCW, Automatic Emergency Braking (AEB), auto high-beam, blind spot warning, and side collision warning.\\nSupported Hardware\\nAt the moment, openpilot supports the EON DevKit and the comma two. A car harness is recommended to connect the EON or comma two to the car. For experimental purposes, openpilot can also run on an Ubuntu computer with external webcams.\\nSupported Cars\\nMake Model (US Market Reference) Supported Package ACC No ACC accel below No ALC below\\nAcura ILX 2016-19 AcuraWatch Plus openpilot 25mph1 25mph\\nAcura RDX 2016-18 AcuraWatch Plus openpilot 25mph1 12mph\\nAcura RDX 2019-21 All Stock 0mph 3mph\\nHonda Accord 2018-20 All Stock 0mph 3mph\\nHonda Accord Hybrid 2018-20 All Stock 0mph 3mph\\nHonda Civic Hatchback 2017-21 Honda Sensing Stock 0mph 12mph\\nHonda Civic Sedan/Coupe 2016-18 Honda Sensing openpilot 0mph 12mph\\nHonda Civic Sedan/Coupe 2019-20 All Stock 0mph 2mph2\\nHonda CR-V 2015-16 Touring openpilot 25mph1 12mph\\nHonda CR-V 2017-20 Honda Sensing Stock 0mph 12mph\\nHonda CR-V Hybrid 2017-2019 Honda Sensing Stock 0mph 12mph\\nHonda Fit 2018-19 Honda Sensing openpilot 25mph1 12mph\\nHonda HR-V 2019-20 Honda Sensing openpilot 25mph1 12mph\\nHonda Insight 2019-21 All Stock 0mph 3mph\\nHonda Inspire 2018 All Stock 0mph 3mph\\nHonda Odyssey 2018-20 Honda Sensing openpilot 25mph1 0mph\\nHonda Passport 2019 All openpilot 25mph1 12mph\\nHonda Pilot 2016-19 Honda Sensing openpilot 25mph1 12mph\\nHonda Ridgeline 2017-21 Honda Sensing openpilot 25mph1 12mph\\nHyundai Palisade 2020-21 All Stock 0mph 0mph\\nHyundai Sonata 2020-21 All Stock 0mph 0mph\\nLexus CT Hybrid 2017-18 LSS Stock3 0mph 0mph\\nLexus ES 2019-20 All openpilot 0mph 0mph\\nLexus ES Hybrid 2017-18 LSS Stock3 0mph 0mph\\nLexus ES Hybrid 2019 All openpilot 0mph 0mph\\nLexus IS 2017-2019 All Stock 22mph 0mph\\nLexus NX 2018 All Stock3 0mph 0mph\\nLexus NX 2020 All openpilot 0mph 0mph\\nLexus NX Hybrid 2018 All Stock3 0mph 0mph\\nLexus RX 2016-18 All Stock3 0mph 0mph\\nLexus RX 2020-21 All openpilot 0mph 0mph\\nLexus RX Hybrid 2016-19 All Stock3 0mph 0mph\\nLexus RX Hybrid 2020 All openpilot 0mph 0mph\\nToyota Avalon 2016-21 TSS-P Stock3 20mph1 0mph\\nToyota Camry 2018-20 All Stock 0mph4 0mph\\nToyota Camry 2021 All openpilot 0mph 0mph\\nToyota Camry Hybrid 2018-20 All Stock 0mph4 0mph\\nToyota Camry Hybrid 2021 All openpilot 0mph 0mph\\nToyota C-HR 2017-20 All Stock 0mph 0mph\\nToyota C-HR Hybrid 2017-19 All Stock 0mph 0mph\\nToyota Corolla 2017-19 All Stock3 20mph1 0mph\\nToyota Corolla 2020-21 All openpilot 0mph 0mph\\nToyota Corolla Hatchback 2019-21 All openpilot 0mph 0mph\\nToyota Corolla Hybrid 2020-21 All openpilot 0mph 0mph\\nToyota Highlander 2017-19 All Stock3 0mph 0mph\\nToyota Highlander 2020-21 All openpilot 0mph 0mph\\nToyota Highlander Hybrid 2017-19 All Stock3 0mph 0mph\\nToyota Highlander Hybrid 2020-21 All openpilot 0mph 0mph\\nToyota Mirai 2021 All openpilot 0mph 0mph\\nToyota Prius 2016-20 TSS-P Stock3 0mph 0mph\\nToyota Prius 2021 All openpilot 0mph 0mph\\nToyota Prius Prime 2017-20 All Stock3 0mph 0mph\\nToyota Prius Prime 2021 All openpilot 0mph 0mph\\nToyota Rav4 2016-18 TSS-P Stock3 20mph1 0mph\\nToyota Rav4 2019-21 All openpilot 0mph 0mph\\nToyota Rav4 Hybrid 2016-18 TSS-P Stock3 0mph 0mph\\nToyota Rav4 Hybrid 2019-21 All openpilot 0mph 0mph\\nToyota Sienna 2018-20 All Stock3 0mph 0mph\\n1Comma Pedal is used to provide stop-and-go capability to some of the openpilot-supported cars that don\\'t currently support stop-and-go. NOTE: The Comma Pedal is not officially supported by comma.\\n22019 Honda Civic 1.6L Diesel Sedan does not have ALC below 12mph.\\n3When disconnecting the Driver Support Unit (DSU), openpilot ACC will replace stock ACC. NOTE: disconnecting the DSU disables Automatic Emergency Braking (AEB).\\n428mph for Camry 4CYL L, 4CYL LE and 4CYL SE which don\\'t have Full-Speed Range Dynamic Radar Cruise Control.\\nCommunity Maintained Cars and Features\\nMake Model (US Market Reference) Supported Package ACC No ACC accel below No ALC below\\nAudi A3 2014-17 Prestige Stock 0mph 0mph\\nAudi A3 Sportback e-tron 2017-18 Prestige Stock 0mph 0mph\\nBuick Regal 20181 Adaptive Cruise openpilot 0mph 7mph\\nCadillac ATS 20181 Adaptive Cruise openpilot 0mph 7mph\\nChevrolet Malibu 20171 Adaptive Cruise openpilot 0mph 7mph\\nChevrolet Volt 2017-181 Adaptive Cruise openpilot 0mph 7mph\\nChrysler Pacifica 2017-18 Adaptive Cruise Stock 0mph 9mph\\nChrysler Pacifica 2020 Adaptive Cruise Stock 0mph 39mph\\nChrysler Pacifica Hybrid 2017-18 Adaptive Cruise Stock 0mph 9mph\\nChrysler Pacifica Hybrid 2019-21 Adaptive Cruise Stock 0mph 39mph\\nGenesis G70 2018 All Stock 0mph 0mph\\nGenesis G80 2018 All Stock 0mph 0mph\\nGenesis G90 2018 All Stock 0mph 0mph\\nGMC Acadia 20181 Adaptive Cruise openpilot 0mph 7mph\\nHolden Astra 20171 Adaptive Cruise openpilot 0mph 7mph\\nHyundai Elantra 2017-19 SCC + LKAS Stock 19mph 34mph\\nHyundai Genesis 2015-16 SCC + LKAS Stock 19mph 37mph\\nHyundai Ioniq Electric 2019 SCC + LKAS Stock 0mph 32mph\\nHyundai Ioniq Electric 2020 SCC + LKAS Stock 0mph 0mph\\nHyundai Kona 2020 SCC + LKAS Stock 0mph 0mph\\nHyundai Kona EV 2019 SCC + LKAS Stock 0mph 0mph\\nHyundai Santa Fe 2019-20 All Stock 0mph 0mph\\nHyundai Sonata 2018-2019 SCC + LKAS Stock 0mph 0mph\\nHyundai Veloster 2019 SCC + LKAS Stock 5mph 0mph\\nJeep Grand Cherokee 2016-18 Adaptive Cruise Stock 0mph 9mph\\nJeep Grand Cherokee 2019-20 Adaptive Cruise Stock 0mph 39mph\\nKia Forte 2018-2021 SCC + LKAS Stock 0mph 0mph\\nKia Niro EV 2020 SCC + LKAS Stock 0mph 0mph\\nKia Optima 2017 SCC + LKAS Stock 0mph 32mph\\nKia Optima 2019 SCC + LKAS Stock 0mph 0mph\\nKia Seltos 2021 SCC + LKAS Stock 0mph 0mph\\nKia Sorento 2018-19 SCC + LKAS Stock 0mph 0mph\\nKia Stinger 2018 SCC + LKAS Stock 0mph 0mph\\nKia Ceed 2019 SCC + LKAS Stock 0mph 0mph\\nNissan Altima 2020 ProPILOT Stock 0mph 0mph\\nNissan Leaf 2018-20 ProPILOT Stock 0mph 0mph\\nNissan Rogue 2018-20 ProPILOT Stock 0mph 0mph\\nNissan X-Trail 2017 ProPILOT Stock 0mph 0mph\\nSEAT Ateca 2018 Driver Assistance Stock 0mph 0mph\\nŠkoda Kodiaq 2018 Driver Assistance Stock 0mph 0mph\\nŠkoda Scala 2020 Driver Assistance Stock 0mph 0mph\\nŠkoda Superb 2015-18 Driver Assistance Stock 0mph 0mph\\nSubaru Ascent 2019 EyeSight Stock 0mph 0mph\\nSubaru Crosstrek 2018-19 EyeSight Stock 0mph 0mph\\nSubaru Forester 2019-20 EyeSight Stock 0mph 0mph\\nSubaru Impreza 2017-19 EyeSight Stock 0mph 0mph\\nVolkswagen e-Golf 2014, 2019-20 Driver Assistance Stock 0mph 0mph\\nVolkswagen Golf 2015-19 Driver Assistance Stock 0mph 0mph\\nVolkswagen Golf GTE 2016 Driver Assistance Stock 0mph 0mph\\nVolkswagen Golf GTI 2018-19 Driver Assistance Stock 0mph 0mph\\nVolkswagen Golf R 2016-19 Driver Assistance Stock 0mph 0mph\\nVolkswagen Golf SportsVan 2016 Driver Assistance Stock 0mph 0mph\\nVolkswagen Jetta 2018-20 Driver Assistance Stock 0mph 0mph\\nVolkswagen Jetta GLI 2021 Driver Assistance Stock 0mph 0mph\\nVolkswagen Passat 2016-172 Driver Assistance Stock 0mph 0mph\\nVolkswagen Tiguan 2020 Driver Assistance Stock 0mph 0mph\\n1Requires an OBD-II car harness and community built ASCM harness. NOTE: disconnecting the ASCM disables Automatic Emergency Braking (AEB).\\n2Only includes the MQB Passat sold outside of North America. The NMS Passat made in Chattanooga TN is not yet supported.\\nCommunity Maintained Cars and Features are not verified by comma to meet our safety model. Be extra cautious using them. They are only available after enabling the toggle in Settings->Developer->Enable Community Features.\\nTo promote a car from community maintained, it must meet a few requirements. We must own one from the brand, we must sell the harness for it, has full ISO26262 in both panda and openpilot, there must be a path forward for longitudinal control, it must have AEB still enabled, and it must support fingerprinting 2.0\\nAlthough they\\'re not upstream, the community has openpilot running on other makes and models. See the \\'Community Supported Models\\' section of each make on our wiki.\\nInstallation Instructions\\nInstall openpilot on an EON or comma two by entering https://openpilot.comma.ai during the installer setup.\\nFollow these video instructions to properly mount the device on the windshield. Note: openpilot features an automatic pose calibration routine and openpilot performance should not be affected by small pitch and yaw misalignments caused by imprecise device mounting.\\nBefore placing the device on your windshield, check the state and local laws and ordinances where you drive. Some state laws prohibit or restrict the placement of objects on the windshield of a motor vehicle.\\nYou will be able to engage openpilot after reviewing the onboarding screens and finishing the calibration procedure.\\nLimitations of openpilot ALC and LDW\\nopenpilot ALC and openpilot LDW do not automatically drive the vehicle or reduce the amount of attention that must be paid to operate your vehicle. The driver must always keep control of the steering wheel and be ready to correct the openpilot ALC action at all times.\\nWhile changing lanes, openpilot is not capable of looking next to you or checking your blind spot. Only nudge the wheel to initiate a lane change after you have confirmed it\\'s safe to do so.\\nMany factors can impact the performance of openpilot ALC and openpilot LDW, causing them to be unable to function as intended. These include, but are not limited to:\\nPoor visibility (heavy rain, snow, fog, etc.) or weather conditions that may interfere with sensor operation.\\nThe road facing camera is obstructed, covered or damaged by mud, ice, snow, etc.\\nObstruction caused by applying excessive paint or adhesive products (such as wraps, stickers, rubber coating, etc.) onto the vehicle.\\nThe device is mounted incorrectly.\\nWhen in sharp curves, like on-off ramps, intersections etc...; openpilot is designed to be limited in the amount of steering torque it can produce.\\nIn the presence of restricted lanes or construction zones.\\nWhen driving on highly banked roads or in presence of strong cross-wind.\\nExtremely hot or cold temperatures.\\nBright light (due to oncoming headlights, direct sunlight, etc.).\\nDriving on hills, narrow, or winding roads.\\nThe list above does not represent an exhaustive list of situations that may interfere with proper operation of openpilot components. It is the driver\\'s responsibility to be in control of the vehicle at all times.\\nLimitations of openpilot ACC and FCW\\nopenpilot ACC and openpilot FCW are not systems that allow careless or inattentive driving. It is still necessary for the driver to pay close attention to the vehicle’s surroundings and to be ready to re-take control of the gas and the brake at all times.\\nMany factors can impact the performance of openpilot ACC and openpilot FCW, causing them to be unable to function as intended. These include, but are not limited to:\\nPoor visibility (heavy rain, snow, fog, etc.) or weather conditions that may interfere with sensor operation.\\nThe road facing camera or radar are obstructed, covered, or damaged by mud, ice, snow, etc.\\nObstruction caused by applying excessive paint or adhesive products (such as wraps, stickers, rubber coating, etc.) onto the vehicle.\\nThe device is mounted incorrectly.\\nApproaching a toll booth, a bridge or a large metal plate.\\nWhen driving on roads with pedestrians, cyclists, etc...\\nIn presence of traffic signs or stop lights, which are not detected by openpilot at this time.\\nWhen the posted speed limit is below the user selected set speed. openpilot does not detect speed limits at this time.\\nIn presence of vehicles in the same lane that are not moving.\\nWhen abrupt braking maneuvers are required. openpilot is designed to be limited in the amount of deceleration and acceleration that it can produce.\\nWhen surrounding vehicles perform close cut-ins from neighbor lanes.\\nDriving on hills, narrow, or winding roads.\\nExtremely hot or cold temperatures.\\nBright light (due to oncoming headlights, direct sunlight, etc.).\\nInterference from other equipment that generates radar waves.\\nThe list above does not represent an exhaustive list of situations that may interfere with proper operation of openpilot components. It is the driver\\'s responsibility to be in control of the vehicle at all times.\\nLimitations of openpilot DM\\nopenpilot DM should not be considered an exact measurement of the alertness of the driver.\\nMany factors can impact the performance of openpilot DM, causing it to be unable to function as intended. These include, but are not limited to:\\nLow light conditions, such as driving at night or in dark tunnels.\\nBright light (due to oncoming headlights, direct sunlight, etc.).\\nThe driver\\'s face is partially or completely outside field of view of the driver facing camera.\\nThe driver facing camera is obstructed, covered, or damaged.\\nThe list above does not represent an exhaustive list of situations that may interfere with proper operation of openpilot components. A driver should not rely on openpilot DM to assess their level of attention.\\nUser Data and comma Account\\nBy default, openpilot uploads the driving data to our servers. You can also access your data by pairing with the comma connect app (iOS, Android). We use your data to train better models and improve openpilot for everyone.\\nopenpilot is open source software: the user is free to disable data collection if they wish to do so.\\nopenpilot logs the road facing camera, CAN, GPS, IMU, magnetometer, thermal sensors, crashes, and operating system logs. The driver facing camera is only logged if you explicitly opt-in in settings. The microphone is not recorded.\\nBy using openpilot, you agree to our Privacy Policy. You understand that use of this software or its related services will generate certain types of user data, which may be logged and stored at the sole discretion of comma. By accepting this agreement, you grant an irrevocable, perpetual, worldwide right to comma for the use of this data.\\nSafety and Testing\\nopenpilot observes ISO26262 guidelines, see SAFETY.md for more details.\\nopenpilot has software in the loop tests that run on every commit.\\nThe safety model code lives in panda and is written in C, see code rigor for more details.\\npanda has software in the loop safety tests.\\nInternally, we have a hardware in the loop Jenkins test suite that builds and unit tests the various processes.\\npanda has additional hardware in the loop tests.\\nWe run the latest openpilot in a testing closet containing 10 EONs continuously replaying routes.\\nTesting on PC\\nFor simplified development and experimentation, openpilot can be run in the CARLA driving simulator, which allows you to develop openpilot without a car. The whole setup should only take a few minutes.\\nSteps:\\nStart the CARLA server on first terminal\\nbash -c \"$(curl https://raw.githubusercontent.com/commaai/openpilot/master/tools/sim/start_carla.sh)\"\\nStart openpilot on second terminal\\nbash -c \"$(curl https://raw.githubusercontent.com/commaai/openpilot/master/tools/sim/start_openpilot_docker.sh)\"\\nPress 1 to engage openpilot\\nSee the full README\\nYou should also take a look at the tools directory in master: lots of tools you can use to replay driving data, test, and develop openpilot from your PC.\\nCommunity and Contributing\\nopenpilot is developed by comma and by users like you. We welcome both pull requests and issues on GitHub. Bug fixes and new car ports are encouraged.\\nYou can add support for your car by following guides we have written for Brand and Model ports. Generally, a car with adaptive cruise control and lane keep assist is a good candidate. Join our Discord to discuss car ports: most car makes have a dedicated channel.\\nWant to get paid to work on openpilot? comma is hiring.\\nAnd follow us on Twitter.\\nDirectory Structure\\n.\\n├── cereal              # The messaging spec and libs used for all logs\\n├── common              # Library like functionality we\\'ve developed here\\n├── installer/updater   # Manages auto-updates of NEOS\\n├── opendbc             # Files showing how to interpret data from cars\\n├── panda               # Code used to communicate on CAN\\n├── phonelibs           # Libraries used on NEOS devices\\n├── pyextra             # Libraries used on NEOS devices\\n└── selfdrive           # Code needed to drive the car\\n    ├── assets          # Fonts, images and sounds for UI\\n    ├── athena          # Allows communication with the app\\n    ├── boardd          # Daemon to talk to the board\\n    ├── camerad         # Driver to capture images from the camera sensors\\n    ├── car             # Car specific code to read states and control actuators\\n    ├── common          # Shared C/C++ code for the daemons\\n    ├── controls        # Perception, planning and controls\\n    ├── debug           # Tools to help you debug and do car ports\\n    ├── locationd       # Soon to be home of precise location\\n    ├── logcatd         # Android logcat as a service\\n    ├── loggerd         # Logger and uploader of car data\\n    ├── modeld          # Driving and monitoring model runners\\n    ├── proclogd        # Logs information from proc\\n    ├── sensord         # IMU / GPS interface code\\n    ├── test            # Unit tests, system tests and a car simulator\\n    └── ui              # The UI\\nLicensing\\nopenpilot is released under the MIT license. Some parts of the software are released under other licenses as specified.\\nAny user of this software shall indemnify and hold harmless comma.ai, Inc. and its directors, officers, employees, agents, stockholders, affiliates, subcontractors and customers from and against all allegations, claims, actions, suits, demands, damages, liabilities, obligations, losses, settlements, judgments, costs and expenses (including without limitation attorneys’ fees and costs) which arise out of, relate to or result from any use of this software by user.\\nTHIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT. YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS. NO WARRANTY EXPRESSED OR IMPLIED.',\n",
       "  'COVID-19 Vaccine Tracker\\n🇮🇳 Get email alerts when COVID-19 Vaccines are available in your city.\\n👉🏻 Project Link',\n",
       "  \"yieldfarming.info\\nIt ain't much, but it's honest work\\nApp : https://vfat.tools\\nOriginal work: https://yieldfarming.info\\nHow to run locally\\nFork the repo and clone it to your PC, or just clone the original. Run npm install (once) and npm run dev\\nThis should bring up the interface at localhost:3000 after a minute or two.\\nHow to contribute\\nFork the project\\nClone your forked copy onto your PC\\nCreate a new branch, make the required changes, test it using the above method\\nCommit to your branch and push to your repo\\nGo to your repo's github page and click Submit a pull request\",\n",
       "  \"Fork Explorer\\nFork Explorer let's you see the status of a BIP9-style softfork. It relies on bitcoind and its JSON-RPC server.\\nBuild and run\\nYou need Deno to build and run this project. Deno is a new Javascript environment, similar to Node.\\nFix config file by duplicating config/config.ts_TEMPLATE to config/config.ts and setting bitcoind's JSON-RPC credentials up.\\n./build-frontend.\\n./run-server.\\nDone.\\nLicense\\nMIT\",\n",
       "  '🌍 Čeština ∙ Deutsch ∙ Ελληνικά ∙ English ∙ Español ∙ Français ∙ Indonesia ∙ Italiano ∙ 日本語 ∙ 한국어 ∙ polski ∙ Português ∙ Română ∙ Русский ∙ Slovenščina ∙ Українська ∙ 简体中文 ∙ 繁體中文\\nThe Art of Command Line\\nNote: I\\'m planning to revise this and looking for a new co-author to help with expanding this into a more comprehensive guide. While it\\'s very popular, it could be broader and a bit deeper. If you like to write and are close to being an expert on this material and willing to consider helping, please drop me a note at josh (0x40) holloway.com. –jlevy, Holloway. Thank you!\\nMeta\\nBasics\\nEveryday use\\nProcessing files and data\\nSystem debugging\\nOne-liners\\nObscure but useful\\nmacOS only\\nWindows only\\nMore resources\\nDisclaimer\\nFluency on the command line is a skill often neglected or considered arcane, but it improves your flexibility and productivity as an engineer in both obvious and subtle ways. This is a selection of notes and tips on using the command-line that we\\'ve found useful when working on Linux. Some tips are elementary, and some are fairly specific, sophisticated, or obscure. This page is not long, but if you can use and recall all the items here, you know a lot.\\nThis work is the result of many authors and translators. Some of this originally appeared on Quora, but it has since moved to GitHub, where people more talented than the original author have made numerous improvements. Please submit a question if you have a question related to the command line. Please contribute if you see an error or something that could be better!\\nMeta\\nScope:\\nThis guide is for both beginners and experienced users. The goals are breadth (everything important), specificity (give concrete examples of the most common case), and brevity (avoid things that aren\\'t essential or digressions you can easily look up elsewhere). Every tip is essential in some situation or significantly saves time over alternatives.\\nThis is written for Linux, with the exception of the \"macOS only\" and \"Windows only\" sections. Many of the other items apply or can be installed on other Unices or macOS (or even Cygwin).\\nThe focus is on interactive Bash, though many tips apply to other shells and to general Bash scripting.\\nIt includes both \"standard\" Unix commands as well as ones that require special package installs -- so long as they are important enough to merit inclusion.\\nNotes:\\nTo keep this to one page, content is implicitly included by reference. You\\'re smart enough to look up more detail elsewhere once you know the idea or command to Google. Use apt, yum, dnf, pacman, pip or brew (as appropriate) to install new programs.\\nUse Explainshell to get a helpful breakdown of what commands, options, pipes etc. do.\\nBasics\\nLearn basic Bash. Actually, type man bash and at least skim the whole thing; it\\'s pretty easy to follow and not that long. Alternate shells can be nice, but Bash is powerful and always available (learning only zsh, fish, etc., while tempting on your own laptop, restricts you in many situations, such as using existing servers).\\nLearn at least one text-based editor well. The nano editor is one of the simplest for basic editing (opening, editing, saving, searching). However, for the power user in a text terminal, there is no substitute for Vim (vi), the hard-to-learn but venerable, fast, and full-featured editor. Many people also use the classic Emacs, particularly for larger editing tasks. (Of course, any modern software developer working on an extensive project is unlikely to use only a pure text-based editor and should also be familiar with modern graphical IDEs and tools.)\\nFinding documentation:\\nKnow how to read official documentation with man (for the inquisitive, man man lists the section numbers, e.g. 1 is \"regular\" commands, 5 is files/conventions, and 8 are for administration). Find man pages with apropos.\\nKnow that some commands are not executables, but Bash builtins, and that you can get help on them with help and help -d. You can find out whether a command is an executable, shell builtin or an alias by using type command.\\ncurl cheat.sh/command will give a brief \"cheat sheet\" with common examples of how to use a shell command.\\nLearn about redirection of output and input using > and < and pipes using |. Know > overwrites the output file and >> appends. Learn about stdout and stderr.\\nLearn about file glob expansion with * (and perhaps ? and [...]) and quoting and the difference between double \" and single \\' quotes. (See more on variable expansion below.)\\nBe familiar with Bash job management: &, ctrl-z, ctrl-c, jobs, fg, bg, kill, etc.\\nKnow ssh, and the basics of passwordless authentication, via ssh-agent, ssh-add, etc.\\nBasic file management: ls and ls -l (in particular, learn what every column in ls -l means), less, head, tail and tail -f (or even better, less +F), ln and ln -s (learn the differences and advantages of hard versus soft links), chown, chmod, du (for a quick summary of disk usage: du -hs *). For filesystem management, df, mount, fdisk, mkfs, lsblk. Learn what an inode is (ls -i or df -i).\\nBasic network management: ip or ifconfig, dig, traceroute, route.\\nLearn and use a version control management system, such as git.\\nKnow regular expressions well, and the various flags to grep/egrep. The -i, -o, -v, -A, -B, and -C options are worth knowing.\\nLearn to use apt-get, yum, dnf or pacman (depending on distro) to find and install packages. And make sure you have pip to install Python-based command-line tools (a few below are easiest to install via pip).\\nEveryday use\\nIn Bash, use Tab to complete arguments or list all available commands and ctrl-r to search through command history (after pressing, type to search, press ctrl-r repeatedly to cycle through more matches, press Enter to execute the found command, or hit the right arrow to put the result in the current line to allow editing).\\nIn Bash, use ctrl-w to delete the last word, and ctrl-u to delete the content from current cursor back to the start of the line. Use alt-b and alt-f to move by word, ctrl-a to move cursor to beginning of line, ctrl-e to move cursor to end of line, ctrl-k to kill to the end of the line, ctrl-l to clear the screen. See man readline for all the default keybindings in Bash. There are a lot. For example alt-. cycles through previous arguments, and alt-* expands a glob.\\nAlternatively, if you love vi-style key-bindings, use set -o vi (and set -o emacs to put it back).\\nFor editing long commands, after setting your editor (for example export EDITOR=vim), ctrl-x ctrl-e will open the current command in an editor for multi-line editing. Or in vi style, escape-v.\\nTo see recent commands, use history. Follow with !n (where n is the command number) to execute again. There are also many abbreviations you can use, the most useful probably being !$ for last argument and !! for last command (see \"HISTORY EXPANSION\" in the man page). However, these are often easily replaced with ctrl-r and alt-..\\nGo to your home directory with cd. Access files relative to your home directory with the ~ prefix (e.g. ~/.bashrc). In sh scripts refer to the home directory as $HOME.\\nTo go back to the previous working directory: cd -.\\nIf you are halfway through typing a command but change your mind, hit alt-# to add a # at the beginning and enter it as a comment (or use ctrl-a, #, enter). You can then return to it later via command history.\\nUse xargs (or parallel). It\\'s very powerful. Note you can control how many items execute per line (-L) as well as parallelism (-P). If you\\'re not sure if it\\'ll do the right thing, use xargs echo first. Also, -I{} is handy. Examples:\\n      find . -name \\'*.py\\' | xargs grep some_function\\n      cat hosts | xargs -I{} ssh root@{} hostname\\npstree -p is a helpful display of the process tree.\\nUse pgrep and pkill to find or signal processes by name (-f is helpful).\\nKnow the various signals you can send processes. For example, to suspend a process, use kill -STOP [pid]. For the full list, see man 7 signal\\nUse nohup or disown if you want a background process to keep running forever.\\nCheck what processes are listening via netstat -lntp or ss -plat (for TCP; add -u for UDP) or lsof -iTCP -sTCP:LISTEN -P -n (which also works on macOS).\\nSee also lsof and fuser for open sockets and files.\\nSee uptime or w to know how long the system has been running.\\nUse alias to create shortcuts for commonly used commands. For example, alias ll=\\'ls -latr\\' creates a new alias ll.\\nSave aliases, shell settings, and functions you commonly use in ~/.bashrc, and arrange for login shells to source it. This will make your setup available in all your shell sessions.\\nPut the settings of environment variables as well as commands that should be executed when you login in ~/.bash_profile. Separate configuration will be needed for shells you launch from graphical environment logins and cron jobs.\\nSynchronize your configuration files (e.g. .bashrc and .bash_profile) among various computers with Git.\\nUnderstand that care is needed when variables and filenames include whitespace. Surround your Bash variables with quotes, e.g. \"$FOO\". Prefer the -0 or -print0 options to enable null characters to delimit filenames, e.g. locate -0 pattern | xargs -0 ls -al or find / -print0 -type d | xargs -0 ls -al. To iterate on filenames containing whitespace in a for loop, set your IFS to be a newline only using IFS=$\\'\\\\n\\'.\\nIn Bash scripts, use set -x (or the variant set -v, which logs raw input, including unexpanded variables and comments) for debugging output. Use strict modes unless you have a good reason not to: Use set -e to abort on errors (nonzero exit code). Use set -u to detect unset variable usages. Consider set -o pipefail too, to abort on errors within pipes (though read up on it more if you do, as this topic is a bit subtle). For more involved scripts, also use trap on EXIT or ERR. A useful habit is to start a script like this, which will make it detect and abort on common errors and print a message:\\n      set -euo pipefail\\n      trap \"echo \\'error: Script failed: see failed command above\\'\" ERR\\nIn Bash scripts, subshells (written with parentheses) are convenient ways to group commands. A common example is to temporarily move to a different working directory, e.g.\\n      # do something in current dir\\n      (cd /some/other/dir && other-command)\\n      # continue in original dir\\nIn Bash, note there are lots of kinds of variable expansion. Checking a variable exists: ${name:?error message}. For example, if a Bash script requires a single argument, just write input_file=${1:?usage: $0 input_file}. Using a default value if a variable is empty: ${name:-default}. If you want to have an additional (optional) parameter added to the previous example, you can use something like output_file=${2:-logfile}. If $2 is omitted and thus empty, output_file will be set to logfile. Arithmetic expansion: i=$(( (i + 1) % 5 )). Sequences: {1..10}. Trimming of strings: ${var%suffix} and ${var#prefix}. For example if var=foo.pdf, then echo ${var%.pdf}.txt prints foo.txt.\\nBrace expansion using {...} can reduce having to re-type similar text and automate combinations of items. This is helpful in examples like mv foo.{txt,pdf} some-dir (which moves both files), cp somefile{,.bak} (which expands to cp somefile somefile.bak) or mkdir -p test-{a,b,c}/subtest-{1,2,3} (which expands all possible combinations and creates a directory tree). Brace expansion is performed before any other expansion.\\nThe order of expansions is: brace expansion; tilde expansion, parameter and variable expansion, arithmetic expansion, and command substitution (done in a left-to-right fashion); word splitting; and filename expansion. (For example, a range like {1..20} cannot be expressed with variables using {$a..$b}. Use seq or a for loop instead, e.g., seq $a $b or for((i=a; i<=b; i++)); do ... ; done.)\\nThe output of a command can be treated like a file via <(some command) (known as process substitution). For example, compare local /etc/hosts with a remote one:\\n      diff /etc/hosts <(ssh somehost cat /etc/hosts)\\nWhen writing scripts you may want to put all of your code in curly braces. If the closing brace is missing, your script will be prevented from executing due to a syntax error. This makes sense when your script is going to be downloaded from the web, since it prevents partially downloaded scripts from executing:\\n{\\n      # Your code here\\n}\\nA \"here document\" allows redirection of multiple lines of input as if from a file:\\ncat <<EOF\\ninput\\non multiple lines\\nEOF\\nIn Bash, redirect both standard output and standard error via: some-command >logfile 2>&1 or some-command &>logfile. Often, to ensure a command does not leave an open file handle to standard input, tying it to the terminal you are in, it is also good practice to add </dev/null.\\nUse man ascii for a good ASCII table, with hex and decimal values. For general encoding info, man unicode, man utf-8, and man latin1 are helpful.\\nUse screen or tmux to multiplex the screen, especially useful on remote ssh sessions and to detach and re-attach to a session. byobu can enhance screen or tmux by providing more information and easier management. A more minimal alternative for session persistence only is dtach.\\nIn ssh, knowing how to port tunnel with -L or -D (and occasionally -R) is useful, e.g. to access web sites from a remote server.\\nIt can be useful to make a few optimizations to your ssh configuration; for example, this ~/.ssh/config contains settings to avoid dropped connections in certain network environments, uses compression (which is helpful with scp over low-bandwidth connections), and multiplex channels to the same server with a local control file:\\n      TCPKeepAlive=yes\\n      ServerAliveInterval=15\\n      ServerAliveCountMax=6\\n      Compression=yes\\n      ControlMaster auto\\n      ControlPath /tmp/%r@%h:%p\\n      ControlPersist yes\\nA few other options relevant to ssh are security sensitive and should be enabled with care, e.g. per subnet or host or in trusted networks: StrictHostKeyChecking=no, ForwardAgent=yes\\nConsider mosh an alternative to ssh that uses UDP, avoiding dropped connections and adding convenience on the road (requires server-side setup).\\nTo get the permissions on a file in octal form, which is useful for system configuration but not available in ls and easy to bungle, use something like\\n      stat -c \\'%A %a %n\\' /etc/timezone\\nFor interactive selection of values from the output of another command, use percol or fzf.\\nFor interaction with files based on the output of another command (like git), use fpp (PathPicker).\\nFor a simple web server for all files in the current directory (and subdirs), available to anyone on your network, use: python -m SimpleHTTPServer 7777 (for port 7777 and Python 2) and python -m http.server 7777 (for port 7777 and Python 3).\\nFor running a command as another user, use sudo. Defaults to running as root; use -u to specify another user. Use -i to login as that user (you will be asked for your password).\\nFor switching the shell to another user, use su username or su - username. The latter with \"-\" gets an environment as if another user just logged in. Omitting the username defaults to root. You will be asked for the password of the user you are switching to.\\nKnow about the 128K limit on command lines. This \"Argument list too long\" error is common when wildcard matching large numbers of files. (When this happens alternatives like find and xargs may help.)\\nFor a basic calculator (and of course access to Python in general), use the python interpreter. For example,\\n>>> 2+3\\n5\\nProcessing files and data\\nTo locate a file by name in the current directory, find . -iname \\'*something*\\' (or similar). To find a file anywhere by name, use locate something (but bear in mind updatedb may not have indexed recently created files).\\nFor general searching through source or data files, there are several options more advanced or faster than grep -r, including (in rough order from older to newer) ack, ag (\"the silver searcher\"), and rg (ripgrep).\\nTo convert HTML to text: lynx -dump -stdin\\nFor Markdown, HTML, and all kinds of document conversion, try pandoc. For example, to convert a Markdown document to Word format: pandoc README.md --from markdown --to docx -o temp.docx\\nIf you must handle XML, xmlstarlet is old but good.\\nFor JSON, use jq. For interactive use, also see jid and jiq.\\nFor YAML, use shyaml.\\nFor Excel or CSV files, csvkit provides in2csv, csvcut, csvjoin, csvgrep, etc.\\nFor Amazon S3, s3cmd is convenient and s4cmd is faster. Amazon\\'s aws and the improved saws are essential for other AWS-related tasks.\\nKnow about sort and uniq, including uniq\\'s -u and -d options -- see one-liners below. See also comm.\\nKnow about cut, paste, and join to manipulate text files. Many people use cut but forget about join.\\nKnow about wc to count newlines (-l), characters (-m), words (-w) and bytes (-c).\\nKnow about tee to copy from stdin to a file and also to stdout, as in ls -al | tee file.txt.\\nFor more complex calculations, including grouping, reversing fields, and statistical calculations, consider datamash.\\nKnow that locale affects a lot of command line tools in subtle ways, including sorting order (collation) and performance. Most Linux installations will set LANG or other locale variables to a local setting like US English. But be aware sorting will change if you change locale. And know i18n routines can make sort or other commands run many times slower. In some situations (such as the set operations or uniqueness operations below) you can safely ignore slow i18n routines entirely and use traditional byte-based sort order, using export LC_ALL=C.\\nYou can set a specific command\\'s environment by prefixing its invocation with the environment variable settings, as in TZ=Pacific/Fiji date.\\nKnow basic awk and sed for simple data munging. See One-liners for examples.\\nTo replace all occurrences of a string in place, in one or more files:\\n      perl -pi.bak -e \\'s/old-string/new-string/g\\' my-files-*.txt\\nTo rename multiple files and/or search and replace within files, try repren. (In some cases the rename command also allows multiple renames, but be careful as its functionality is not the same on all Linux distributions.)\\n      # Full rename of filenames, directories, and contents foo -> bar:\\n      repren --full --preserve-case --from foo --to bar .\\n      # Recover backup files whatever.bak -> whatever:\\n      repren --renames --from \\'(.*)\\\\.bak\\' --to \\'\\\\1\\' *.bak\\n      # Same as above, using rename, if available:\\n      rename \\'s/\\\\.bak$//\\' *.bak\\nAs the man page says, rsync really is a fast and extraordinarily versatile file copying tool. It\\'s known for synchronizing between machines but is equally useful locally. When security restrictions allow, using rsync instead of scp allows recovery of a transfer without restarting from scratch. It also is among the fastest ways to delete large numbers of files:\\nmkdir empty && rsync -r --delete empty/ some-dir && rmdir some-dir\\nFor monitoring progress when processing files, use pv, pycp, pmonitor, progress, rsync --progress, or, for block-level copying, dd status=progress.\\nUse shuf to shuffle or select random lines from a file.\\nKnow sort\\'s options. For numbers, use -n, or -h for handling human-readable numbers (e.g. from du -h). Know how keys work (-t and -k). In particular, watch out that you need to write -k1,1 to sort by only the first field; -k1 means sort according to the whole line. Stable sort (sort -s) can be useful. For example, to sort first by field 2, then secondarily by field 1, you can use sort -k1,1 | sort -s -k2,2.\\nIf you ever need to write a tab literal in a command line in Bash (e.g. for the -t argument to sort), press ctrl-v [Tab] or write $\\'\\\\t\\' (the latter is better as you can copy/paste it).\\nThe standard tools for patching source code are diff and patch. See also diffstat for summary statistics of a diff and sdiff for a side-by-side diff. Note diff -r works for entire directories. Use diff -r tree1 tree2 | diffstat for a summary of changes. Use vimdiff to compare and edit files.\\nFor binary files, use hd, hexdump or xxd for simple hex dumps and bvi, hexedit or biew for binary editing.\\nAlso for binary files, strings (plus grep, etc.) lets you find bits of text.\\nFor binary diffs (delta compression), use xdelta3.\\nTo convert text encodings, try iconv. Or uconv for more advanced use; it supports some advanced Unicode things. For example:\\n      # Displays hex codes or actual names of characters (useful for debugging):\\n      uconv -f utf-8 -t utf-8 -x \\'::Any-Hex;\\' < input.txt\\n      uconv -f utf-8 -t utf-8 -x \\'::Any-Name;\\' < input.txt\\n      # Lowercase and removes all accents (by expanding and dropping them):\\n      uconv -f utf-8 -t utf-8 -x \\'::Any-Lower; ::Any-NFD; [:Nonspacing Mark:] >; ::Any-NFC;\\' < input.txt > output.txt\\nTo split files into pieces, see split (to split by size) and csplit (to split by a pattern).\\nDate and time: To get the current date and time in the helpful ISO 8601 format, use date -u +\"%Y-%m-%dT%H:%M:%SZ\" (other options are problematic). To manipulate date and time expressions, use dateadd, datediff, strptime etc. from dateutils.\\nUse zless, zmore, zcat, and zgrep to operate on compressed files.\\nFile attributes are settable via chattr and offer a lower-level alternative to file permissions. For example, to protect against accidental file deletion the immutable flag: sudo chattr +i /critical/directory/or/file\\nUse getfacl and setfacl to save and restore file permissions. For example:\\n   getfacl -R /some/path > permissions.txt\\n   setfacl --restore=permissions.txt\\nTo create empty files quickly, use truncate (creates sparse file), fallocate (ext4, xfs, btrfs and ocfs2 filesystems), xfs_mkfile (almost any filesystems, comes in xfsprogs package), mkfile (for Unix-like systems like Solaris, Mac OS).\\nSystem debugging\\nFor web debugging, curl and curl -I are handy, or their wget equivalents, or the more modern httpie.\\nTo know current cpu/disk status, the classic tools are top (or the better htop), iostat, and iotop. Use iostat -mxz 15 for basic CPU and detailed per-partition disk stats and performance insight.\\nFor network connection details, use netstat and ss.\\nFor a quick overview of what\\'s happening on a system, dstat is especially useful. For broadest overview with details, use glances.\\nTo know memory status, run and understand the output of free and vmstat. In particular, be aware the \"cached\" value is memory held by the Linux kernel as file cache, so effectively counts toward the \"free\" value.\\nJava system debugging is a different kettle of fish, but a simple trick on Oracle\\'s and some other JVMs is that you can run kill -3 <pid> and a full stack trace and heap summary (including generational garbage collection details, which can be highly informative) will be dumped to stderr/logs. The JDK\\'s jps, jstat, jstack, jmap are useful. SJK tools are more advanced.\\nUse mtr as a better traceroute, to identify network issues.\\nFor looking at why a disk is full, ncdu saves time over the usual commands like du -sh *.\\nTo find which socket or process is using bandwidth, try iftop or nethogs.\\nThe ab tool (comes with Apache) is helpful for quick-and-dirty checking of web server performance. For more complex load testing, try siege.\\nFor more serious network debugging, wireshark, tshark, or ngrep.\\nKnow about strace and ltrace. These can be helpful if a program is failing, hanging, or crashing, and you don\\'t know why, or if you want to get a general idea of performance. Note the profiling option (-c), and the ability to attach to a running process (-p). Use trace child option (-f) to avoid missing important calls.\\nKnow about ldd to check shared libraries etc — but never run it on untrusted files.\\nKnow how to connect to a running process with gdb and get its stack traces.\\nUse /proc. It\\'s amazingly helpful sometimes when debugging live problems. Examples: /proc/cpuinfo, /proc/meminfo, /proc/cmdline, /proc/xxx/cwd, /proc/xxx/exe, /proc/xxx/fd/, /proc/xxx/smaps (where xxx is the process id or pid).\\nWhen debugging why something went wrong in the past, sar can be very helpful. It shows historic statistics on CPU, memory, network, etc.\\nFor deeper systems and performance analyses, look at stap (SystemTap), perf, and sysdig.\\nCheck what OS you\\'re on with uname or uname -a (general Unix/kernel info) or lsb_release -a (Linux distro info).\\nUse dmesg whenever something\\'s acting really funny (it could be hardware or driver issues).\\nIf you delete a file and it doesn\\'t free up expected disk space as reported by du, check whether the file is in use by a process: lsof | grep deleted | grep \"filename-of-my-big-file\"\\nOne-liners\\nA few examples of piecing together commands:\\nIt is remarkably helpful sometimes that you can do set intersection, union, and difference of text files via sort/uniq. Suppose a and b are text files that are already uniqued. This is fast, and works on files of arbitrary size, up to many gigabytes. (Sort is not limited by memory, though you may need to use the -T option if /tmp is on a small root partition.) See also the note about LC_ALL above and sort\\'s -u option (left out for clarity below).\\n      sort a b | uniq > c   # c is a union b\\n      sort a b | uniq -d > c   # c is a intersect b\\n      sort a b b | uniq -u > c   # c is set difference a - b\\nPretty-print two JSON files, normalizing their syntax, then coloring and paginating the result:\\n      diff <(jq --sort-keys . < file1.json) <(jq --sort-keys . < file2.json) | colordiff | less -R\\nUse grep . * to quickly examine the contents of all files in a directory (so each line is paired with the filename), or head -100 * (so each file has a heading). This can be useful for directories filled with config settings like those in /sys, /proc, /etc.\\nSumming all numbers in the third column of a text file (this is probably 3X faster and 3X less code than equivalent Python):\\n      awk \\'{ x += $3 } END { print x }\\' myfile\\nTo see sizes/dates on a tree of files, this is like a recursive ls -l but is easier to read than ls -lR:\\n      find . -type f -ls\\nSay you have a text file, like a web server log, and a certain value that appears on some lines, such as an acct_id parameter that is present in the URL. If you want a tally of how many requests for each acct_id:\\n      egrep -o \\'acct_id=[0-9]+\\' access.log | cut -d= -f2 | sort | uniq -c | sort -rn\\nTo continuously monitor changes, use watch, e.g. check changes to files in a directory with watch -d -n 2 \\'ls -rtlh | tail\\' or to network settings while troubleshooting your wifi settings with watch -d -n 2 ifconfig.\\nRun this function to get a random tip from this document (parses Markdown and extracts an item):\\n      function taocl() {\\n        curl -s https://raw.githubusercontent.com/jlevy/the-art-of-command-line/master/README.md |\\n          sed \\'/cowsay[.]png/d\\' |\\n          pandoc -f markdown -t html |\\n          xmlstarlet fo --html --dropdtd |\\n          xmlstarlet sel -t -v \"(html/body/ul/li[count(p)>0])[$RANDOM mod last()+1]\" |\\n          xmlstarlet unesc | fmt -80 | iconv -t US\\n      }\\nObscure but useful\\nexpr: perform arithmetic or boolean operations or evaluate regular expressions\\nm4: simple macro processor\\nyes: print a string a lot\\ncal: nice calendar\\nenv: run a command (useful in scripts)\\nprintenv: print out environment variables (useful in debugging and scripts)\\nlook: find English words (or lines in a file) beginning with a string\\ncut, paste and join: data manipulation\\nfmt: format text paragraphs\\npr: format text into pages/columns\\nfold: wrap lines of text\\ncolumn: format text fields into aligned, fixed-width columns or tables\\nexpand and unexpand: convert between tabs and spaces\\nnl: add line numbers\\nseq: print numbers\\nbc: calculator\\nfactor: factor integers\\ngpg: encrypt and sign files\\ntoe: table of terminfo entries\\nnc: network debugging and data transfer\\nsocat: socket relay and tcp port forwarder (similar to netcat)\\nslurm: network traffic visualization\\ndd: moving data between files or devices\\nfile: identify type of a file\\ntree: display directories and subdirectories as a nesting tree; like ls but recursive\\nstat: file info\\ntime: execute and time a command\\ntimeout: execute a command for specified amount of time and stop the process when the specified amount of time completes.\\nlockfile: create semaphore file that can only be removed by rm -f\\nlogrotate: rotate, compress and mail logs.\\nwatch: run a command repeatedly, showing results and/or highlighting changes\\nwhen-changed: runs any command you specify whenever it sees file changed. See inotifywait and entr as well.\\ntac: print files in reverse\\ncomm: compare sorted files line by line\\nstrings: extract text from binary files\\ntr: character translation or manipulation\\niconv or uconv: conversion for text encodings\\nsplit and csplit: splitting files\\nsponge: read all input before writing it, useful for reading from then writing to the same file, e.g., grep -v something some-file | sponge some-file\\nunits: unit conversions and calculations; converts furlongs per fortnight to twips per blink (see also /usr/share/units/definitions.units)\\napg: generates random passwords\\nxz: high-ratio file compression\\nldd: dynamic library info\\nnm: symbols from object files\\nab or wrk: benchmarking web servers\\nstrace: system call debugging\\nmtr: better traceroute for network debugging\\ncssh: visual concurrent shell\\nrsync: sync files and folders over SSH or in local file system\\nwireshark and tshark: packet capture and network debugging\\nngrep: grep for the network layer\\nhost and dig: DNS lookups\\nlsof: process file descriptor and socket info\\ndstat: useful system stats\\nglances: high level, multi-subsystem overview\\niostat: Disk usage stats\\nmpstat: CPU usage stats\\nvmstat: Memory usage stats\\nhtop: improved version of top\\nlast: login history\\nw: who\\'s logged on\\nid: user/group identity info\\nsar: historic system stats\\niftop or nethogs: network utilization by socket or process\\nss: socket statistics\\ndmesg: boot and system error messages\\nsysctl: view and configure Linux kernel parameters at run time\\nhdparm: SATA/ATA disk manipulation/performance\\nlsblk: list block devices: a tree view of your disks and disk partitions\\nlshw, lscpu, lspci, lsusb, dmidecode: hardware information, including CPU, BIOS, RAID, graphics, devices, etc.\\nlsmod and modinfo: List and show details of kernel modules.\\nfortune, ddate, and sl: um, well, it depends on whether you consider steam locomotives and Zippy quotations \"useful\"\\nmacOS only\\nThese are items relevant only on macOS.\\nPackage management with brew (Homebrew) and/or port (MacPorts). These can be used to install on macOS many of the above commands.\\nCopy output of any command to a desktop app with pbcopy and paste input from one with pbpaste.\\nTo enable the Option key in macOS Terminal as an alt key (such as used in the commands above like alt-b, alt-f, etc.), open Preferences -> Profiles -> Keyboard and select \"Use Option as Meta key\".\\nTo open a file with a desktop app, use open or open -a /Applications/Whatever.app.\\nSpotlight: Search files with mdfind and list metadata (such as photo EXIF info) with mdls.\\nBe aware macOS is based on BSD Unix, and many commands (for example ps, ls, tail, awk, sed) have many subtle variations from Linux, which is largely influenced by System V-style Unix and GNU tools. You can often tell the difference by noting a man page has the heading \"BSD General Commands Manual.\" In some cases GNU versions can be installed, too (such as gawk and gsed for GNU awk and sed). If writing cross-platform Bash scripts, avoid such commands (for example, consider Python or perl) or test carefully.\\nTo get macOS release information, use sw_vers.\\nWindows only\\nThese items are relevant only on Windows.\\nWays to obtain Unix tools under Windows\\nAccess the power of the Unix shell under Microsoft Windows by installing Cygwin. Most of the things described in this document will work out of the box.\\nOn Windows 10, you can use Windows Subsystem for Linux (WSL), which provides a familiar Bash environment with Unix command line utilities.\\nIf you mainly want to use GNU developer tools (such as GCC) on Windows, consider MinGW and its MSYS package, which provides utilities such as bash, gawk, make and grep. MSYS doesn\\'t have all the features compared to Cygwin. MinGW is particularly useful for creating native Windows ports of Unix tools.\\nAnother option to get Unix look and feel under Windows is Cash. Note that only very few Unix commands and command-line options are available in this environment.\\nUseful Windows command-line tools\\nYou can perform and script most Windows system administration tasks from the command line by learning and using wmic.\\nNative command-line Windows networking tools you may find useful include ping, ipconfig, tracert, and netstat.\\nYou can perform many useful Windows tasks by invoking the Rundll32 command.\\nCygwin tips and tricks\\nInstall additional Unix programs with the Cygwin\\'s package manager.\\nUse mintty as your command-line window.\\nAccess the Windows clipboard through /dev/clipboard.\\nRun cygstart to open an arbitrary file through its registered application.\\nAccess the Windows registry with regtool.\\nNote that a C:\\\\ Windows drive path becomes /cygdrive/c under Cygwin, and that Cygwin\\'s / appears under C:\\\\cygwin on Windows. Convert between Cygwin and Windows-style file paths with cygpath. This is most useful in scripts that invoke Windows programs.\\nMore resources\\nawesome-shell: A curated list of shell tools and resources.\\nawesome-osx-command-line: A more in-depth guide for the macOS command line.\\nStrict mode for writing better shell scripts.\\nshellcheck: A shell script static analysis tool. Essentially, lint for bash/sh/zsh.\\nFilenames and Pathnames in Shell: The sadly complex minutiae on how to handle filenames correctly in shell scripts.\\nData Science at the Command Line: More commands and tools helpful for doing data science, from the book of the same name\\nDisclaimer\\nWith the exception of very small tasks, code is written so others can read it. With power comes responsibility. The fact you can do something in Bash doesn\\'t necessarily mean you should! ;)\\nLicense\\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.',\n",
       "  '-',\n",
       "  'git-tips\\nCollection of git-tips, want to add your tips? Checkout contributing.md\\nEnglish | 中文 | Русский | 한국어 | Tiếng Việt | 日本語 | नेपाली | Polski\\nTools:\\ngit-tip - A handy CLI to make optimum use of these tips. (Here in Docker container)\\nP.S: All these commands are tested on git version 2.7.4 (Apple Git-66).\\nEveryday Git in twenty commands or so\\nShow helpful guides that come with Git\\nSearch change by content\\nShow changes over time for specific file\\nRemove sensitive data from history, after a push\\nSync with remote, overwrite local changes\\nList of all files till a commit\\nGit reset first commit\\nReset: preserve uncommitted local changes\\nList all the conflicted files\\nList of all files changed in a commit\\nUnstaged changes since last commit\\nChanges staged for commit\\nShow both staged and unstaged changes\\nList all branches that are already merged into master\\nQuickly switch to the previous branch\\nRemove branches that have already been merged with master\\nList all branches and their upstreams, as well as last commit on branch\\nTrack upstream branch\\nDelete local branch\\nDelete remote branch\\nDelete local tag\\nDelete remote tag\\nUndo local changes with the last content in head\\nRevert: Undo a commit by creating a new commit\\nReset: Discard commits, advised for private branch\\nReword the previous commit message\\nSee commit history for just the current branch\\nAmend author.\\nReset author, after author has been changed in the global config.\\nChanging a remote\\'s URL\\nGet list of all remote references\\nGet list of all local and remote branches\\nGet only remote branches\\nStage parts of a changed file, instead of the entire file\\nGet git bash completion\\nWhat changed since two weeks?\\nSee all commits made since forking from master\\nPick commits across branches using cherry-pick\\nFind out branches containing commit-hash\\nGit Aliases\\nSaving current state of tracked files without commiting\\nSaving current state of unstaged changes to tracked files\\nSaving current state including untracked files\\nSaving current state with message\\nSaving current state of all files (ignored, untracked, and tracked)\\nShow list of all saved stashes\\nApply any stash without deleting from the stashed list\\nApply last stashed state and delete it from stashed list\\nDelete all stored stashes\\nGrab a single file from a stash\\nShow all tracked files\\nShow all untracked files\\nShow all ignored files\\nCreate new working tree from a repository (git 2.5)\\nCreate new working tree from HEAD state\\nUntrack files without deleting\\nBefore deleting untracked files/directory, do a dry run to get the list of these files/directories\\nForcefully remove untracked files\\nForcefully remove untracked directory\\nUpdate all the submodules\\nShow all commits in the current branch yet to be merged to master\\nRename a branch\\nRebases \\'feature\\' to \\'master\\' and merges it in to master\\nArchive the master branch\\nModify previous commit without modifying the commit message\\nPrunes references to remove branches that have been deleted in the remote.\\nDelete local branches that has been squash and merged in the remote.\\nRetrieve the commit hash of the initial revision.\\nVisualize the version tree.\\nVisualize the tree including commits that are only referenced from reflogs\\nDeploying git tracked subfolder to gh-pages\\nAdding a project to repo using subtree\\nGet latest changes in your repo for a linked project using subtree\\nExport a branch with history to a file.\\nImport from a bundle\\nGet the name of current branch.\\nIgnore one file on commit (e.g. Changelog).\\nStash changes before rebasing\\nFetch pull request by ID to a local branch\\nShow the most recent tag on the current branch.\\nShow inline word diff.\\nShow changes using common diff tools.\\nDon’t consider changes for tracked file.\\nUndo assume-unchanged.\\nClean the files from .gitignore.\\nRestore deleted file.\\nRestore file to a specific commit-hash\\nAlways rebase instead of merge on pull.\\nList all the alias and configs.\\nMake git case sensitive.\\nAdd custom editors.\\nAuto correct typos.\\nCheck if the change was a part of a release.\\nDry run. (any command that supports dry-run flag should do.)\\nMarks your commit as a fix of a previous commit.\\nSquash fixup commits normal commits.\\nSkip staging area during commit.\\nInteractive staging.\\nList ignored files.\\nStatus of ignored files.\\nCommits in Branch1 that are not in Branch2\\nList n last commits\\nReuse recorded resolution, record and reuse previous conflicts resolutions.\\nOpen all conflicted files in an editor.\\nCount unpacked number of objects and their disk consumption.\\nPrune all unreachable objects from the object database.\\nInstantly browse your working repository in gitweb.\\nView the GPG signatures in the commit log\\nRemove entry in the global config.\\nCheckout a new branch without any history\\nExtract file from another branch.\\nList only the root and merge commits.\\nChange previous two commits with an interactive rebase.\\nList all branch is WIP\\nFind guilty with binary search\\nBypass pre-commit and commit-msg githooks\\nList commits and changes to a specific file (even through renaming)\\nClone a single branch\\nCreate and switch new branch\\nIgnore file mode changes on commits\\nTurn off git colored terminal output\\nSpecific color settings\\nShow all local branches ordered by recent commits\\nFind lines matching the pattern (regex or string) in tracked files\\nClone a shallow copy of a repository\\nSearch Commit log across all branches for given text\\nGet first commit in a branch (from master)\\nUnstaging Staged file\\nForce push to Remote Repository\\nAdding Remote name\\nList all currently configured remotes\\nShow the author, time and last revision made to each line of a given file\\nGroup commits by authors and title\\nForced push but still ensure you don\\'t overwrite other\\'s work\\nShow how many lines does an author contribute\\nRevert: Reverting an entire merge\\nNumber of commits in a branch\\nAlias: git undo\\nAdd object notes\\nShow all the git-notes\\nApply commit from another repository\\nSpecific fetch reference\\nFind common ancestor of two branches\\nList unpushed git commits\\nAdd everything, but whitespace changes\\nEdit [local/global] git config\\nblame on certain range\\nShow a Git logical variable.\\nPreformatted patch file.\\nGet the repo name.\\nlogs between date range\\nExclude author from logs\\nGenerates a summary of pending changes\\nList references in a remote repository\\nBackup untracked files.\\nList all git aliases\\nShow git status short\\nCheckout a commit prior to a day ago\\nPush a new local branch to remote repository and track\\nChange a branch base\\nUse SSH instead of HTTPs for remotes\\nUpdate a submodule to the latest commit\\nPrevent auto replacing LF with CRLF\\nEveryday Git in twenty commands or so\\ngit help everyday\\nShow helpful guides that come with Git\\ngit help -g\\nSearch change by content\\ngit log -S\\'<a term in the source>\\'\\nShow changes over time for specific file\\ngit log -p <file_name>\\nRemove sensitive data from history, after a push\\ngit filter-branch --force --index-filter \\'git rm --cached --ignore-unmatch <path-to-your-file>\\' --prune-empty --tag-name-filter cat -- --all && git push origin --force --all\\nSync with remote, overwrite local changes\\ngit fetch origin && git reset --hard origin/master && git clean -f -d\\nList of all files till a commit\\ngit ls-tree --name-only -r <commit-ish>\\nGit reset first commit\\ngit update-ref -d HEAD\\nReset: preserve uncommitted local changes\\ngit reset --keep <commit>\\nList all the conflicted files\\ngit diff --name-only --diff-filter=U\\nList of all files changed in a commit\\ngit diff-tree --no-commit-id --name-only -r <commit-ish>\\nUnstaged changes since last commit\\ngit diff\\nChanges staged for commit\\ngit diff --cached\\nAlternatives:\\ngit diff --staged\\nShow both staged and unstaged changes\\ngit diff HEAD\\nList all branches that are already merged into master\\ngit branch --merged master\\nQuickly switch to the previous branch\\ngit checkout -\\nAlternatives:\\ngit checkout @{-1}\\nRemove branches that have already been merged with master\\ngit branch --merged master | grep -v \\'^\\\\*\\' | xargs -n 1 git branch -d\\nAlternatives:\\ngit branch --merged master | grep -v \\'^\\\\*\\\\|  master\\' | xargs -n 1 git branch -d # will not delete master if master is not checked out\\nList all branches and their upstreams, as well as last commit on branch\\ngit branch -vv\\nTrack upstream branch\\ngit branch -u origin/mybranch\\nDelete local branch\\ngit branch -d <local_branchname>\\nDelete remote branch\\ngit push origin --delete <remote_branchname>\\nAlternatives:\\ngit push origin :<remote_branchname>\\ngit branch -dr <remote/branch>\\nDelete local tag\\ngit tag -d <tag-name>\\nDelete remote tag\\ngit push origin :refs/tags/<tag-name>\\nUndo local changes with the last content in head\\ngit checkout -- <file_name>\\nRevert: Undo a commit by creating a new commit\\ngit revert <commit-ish>\\nReset: Discard commits, advised for private branch\\ngit reset <commit-ish>\\nReword the previous commit message\\ngit commit -v --amend\\nSee commit history for just the current branch\\ngit cherry -v master\\nAmend author.\\ngit commit --amend --author=\\'Author Name <email@address.com>\\'\\nReset author, after author has been changed in the global config.\\ngit commit --amend --reset-author --no-edit\\nChanging a remote\\'s URL\\ngit remote set-url origin <URL>\\nGet list of all remote references\\ngit remote\\nAlternatives:\\ngit remote show\\nGet list of all local and remote branches\\ngit branch -a\\nGet only remote branches\\ngit branch -r\\nStage parts of a changed file, instead of the entire file\\ngit add -p\\nGet git bash completion\\ncurl -L http://git.io/vfhol > ~/.git-completion.bash && echo \\'[ -f ~/.git-completion.bash ] && . ~/.git-completion.bash\\' >> ~/.bashrc\\nWhat changed since two weeks?\\ngit log --no-merges --raw --since=\\'2 weeks ago\\'\\nAlternatives:\\ngit whatchanged --since=\\'2 weeks ago\\'\\nSee all commits made since forking from master\\ngit log --no-merges --stat --reverse master..\\nPick commits across branches using cherry-pick\\ngit checkout <branch-name> && git cherry-pick <commit-ish>\\nFind out branches containing commit-hash\\ngit branch -a --contains <commit-ish>\\nAlternatives:\\ngit branch --contains <commit-ish>\\nGit Aliases\\ngit config --global alias.<handle> <command> \\ngit config --global alias.st status\\nSaving current state of tracked files without commiting\\ngit stash\\nAlternatives:\\ngit stash push\\nSaving current state of unstaged changes to tracked files\\ngit stash -k\\nAlternatives:\\ngit stash --keep-index\\ngit stash push --keep-index\\nSaving current state including untracked files\\ngit stash -u\\nAlternatives:\\ngit stash push -u\\ngit stash push --include-untracked\\nSaving current state with message\\ngit stash push -m <message>\\nAlternatives:\\ngit stash push --message <message>\\nSaving current state of all files (ignored, untracked, and tracked)\\ngit stash -a\\nAlternatives:\\ngit stash --all\\ngit stash push --all\\nShow list of all saved stashes\\ngit stash list\\nApply any stash without deleting from the stashed list\\ngit stash apply <stash@{n}>\\nApply last stashed state and delete it from stashed list\\ngit stash pop\\nAlternatives:\\ngit stash apply stash@{0} && git stash drop stash@{0}\\nDelete all stored stashes\\ngit stash clear\\nAlternatives:\\ngit stash drop <stash@{n}>\\nGrab a single file from a stash\\ngit checkout <stash@{n}> -- <file_path>\\nAlternatives:\\ngit checkout stash@{0} -- <file_path>\\nShow all tracked files\\ngit ls-files -t\\nShow all untracked files\\ngit ls-files --others\\nShow all ignored files\\ngit ls-files --others -i --exclude-standard\\nCreate new working tree from a repository (git 2.5)\\ngit worktree add -b <branch-name> <path> <start-point>\\nCreate new working tree from HEAD state\\ngit worktree add --detach <path> HEAD\\nUntrack files without deleting\\ngit rm --cached <file_path>\\nAlternatives:\\ngit rm --cached -r <directory_path>\\nBefore deleting untracked files/directory, do a dry run to get the list of these files/directories\\ngit clean -n\\nForcefully remove untracked files\\ngit clean -f\\nForcefully remove untracked directory\\ngit clean -f -d\\nUpdate all the submodules\\ngit submodule foreach git pull\\nAlternatives:\\ngit submodule update --init --recursive\\ngit submodule update --remote\\nShow all commits in the current branch yet to be merged to master\\ngit cherry -v master\\nAlternatives:\\ngit cherry -v master <branch-to-be-merged>\\nRename a branch\\ngit branch -m <new-branch-name>\\nAlternatives:\\ngit branch -m [<old-branch-name>] <new-branch-name>\\nRebases \\'feature\\' to \\'master\\' and merges it in to master\\ngit rebase master feature && git checkout master && git merge -\\nArchive the master branch\\ngit archive master --format=zip --output=master.zip\\nModify previous commit without modifying the commit message\\ngit add --all && git commit --amend --no-edit\\nPrunes references to remove branches that have been deleted in the remote.\\ngit fetch -p\\nAlternatives:\\ngit remote prune origin\\nDelete local branches that has been squash and merged in the remote.\\ngit branch -vv | grep \\': gone]\\' | awk \\'{print <!-- @doxie.inject start -->}\\' | xargs git branch -D\\nRetrieve the commit hash of the initial revision.\\n git rev-list --reverse HEAD | head -1\\nAlternatives:\\ngit rev-list --max-parents=0 HEAD\\ngit log --pretty=oneline | tail -1 | cut -c 1-40\\ngit log --pretty=oneline --reverse | head -1 | cut -c 1-40\\nVisualize the version tree.\\ngit log --pretty=oneline --graph --decorate --all\\nAlternatives:\\ngitk --all\\ngit log --graph --pretty=format:\\'%C(auto) %h | %s | %an | %ar%d\\'\\nVisualize the tree including commits that are only referenced from reflogs\\ngit log --graph --decorate --oneline $(git rev-list --walk-reflogs --all)\\nDeploying git tracked subfolder to gh-pages\\ngit subtree push --prefix subfolder_name origin gh-pages\\nAdding a project to repo using subtree\\ngit subtree add --prefix=<directory_name>/<project_name> --squash git@github.com:<username>/<project_name>.git master\\nGet latest changes in your repo for a linked project using subtree\\ngit subtree pull --prefix=<directory_name>/<project_name> --squash git@github.com:<username>/<project_name>.git master\\nExport a branch with history to a file.\\ngit bundle create <file> <branch-name>\\nImport from a bundle\\ngit clone repo.bundle <repo-dir> -b <branch-name>\\nGet the name of current branch.\\ngit rev-parse --abbrev-ref HEAD\\nIgnore one file on commit (e.g. Changelog).\\ngit update-index --assume-unchanged Changelog; git commit -a; git update-index --no-assume-unchanged Changelog\\nStash changes before rebasing\\ngit rebase --autostash\\nFetch pull request by ID to a local branch\\ngit fetch origin pull/<id>/head:<branch-name>\\nAlternatives:\\ngit pull origin pull/<id>/head:<branch-name>\\nShow the most recent tag on the current branch.\\ngit describe --tags --abbrev=0\\nShow inline word diff.\\ngit diff --word-diff\\nShow changes using common diff tools.\\ngit difftool [-t <tool>] <commit1> <commit2> <path>\\nDon’t consider changes for tracked file.\\ngit update-index --assume-unchanged <file_name>\\nUndo assume-unchanged.\\ngit update-index --no-assume-unchanged <file_name>\\nClean the files from .gitignore.\\ngit clean -X -f\\nRestore deleted file.\\ngit checkout <deleting_commit> -- <file_path>\\nRestore file to a specific commit-hash\\ngit checkout <commit-ish> -- <file_path>\\nAlways rebase instead of merge on pull.\\ngit config --global pull.rebase true\\nAlternatives:\\n#git < 1.7.9\\ngit config --global branch.autosetuprebase always\\nList all the alias and configs.\\ngit config --list\\nMake git case sensitive.\\ngit config --global core.ignorecase false\\nAdd custom editors.\\ngit config --global core.editor \\'$EDITOR\\'\\nAuto correct typos.\\ngit config --global help.autocorrect 1\\nCheck if the change was a part of a release.\\ngit name-rev --name-only <SHA-1>\\nDry run. (any command that supports dry-run flag should do.)\\ngit clean -fd --dry-run\\nMarks your commit as a fix of a previous commit.\\ngit commit --fixup <SHA-1>\\nSquash fixup commits normal commits.\\ngit rebase -i --autosquash\\nSkip staging area during commit.\\ngit commit --only <file_path>\\nInteractive staging.\\ngit add -i\\nList ignored files.\\ngit check-ignore *\\nStatus of ignored files.\\ngit status --ignored\\nCommits in Branch1 that are not in Branch2\\ngit log Branch1 ^Branch2\\nList n last commits\\ngit log -<n>\\nAlternatives:\\ngit log -n <n>\\nReuse recorded resolution, record and reuse previous conflicts resolutions.\\ngit config --global rerere.enabled 1\\nOpen all conflicted files in an editor.\\ngit diff --name-only | uniq | xargs $EDITOR\\nCount unpacked number of objects and their disk consumption.\\ngit count-objects --human-readable\\nPrune all unreachable objects from the object database.\\ngit gc --prune=now --aggressive\\nInstantly browse your working repository in gitweb.\\ngit instaweb [--local] [--httpd=<httpd>] [--port=<port>] [--browser=<browser>]\\nView the GPG signatures in the commit log\\ngit log --show-signature\\nRemove entry in the global config.\\ngit config --global --unset <entry-name>\\nCheckout a new branch without any history\\ngit checkout --orphan <branch_name>\\nExtract file from another branch.\\ngit show <branch_name>:<file_name>\\nList only the root and merge commits.\\ngit log --first-parent\\nChange previous two commits with an interactive rebase.\\ngit rebase --interactive HEAD~2\\nList all branch is WIP\\ngit checkout master && git branch --no-merged\\nFind guilty with binary search\\ngit bisect start                    # Search start \\ngit bisect bad                      # Set point to bad commit \\ngit bisect good v2.6.13-rc2         # Set point to good commit|tag \\ngit bisect bad                      # Say current state is bad \\ngit bisect good                     # Say current state is good \\ngit bisect reset                    # Finish search \\nBypass pre-commit and commit-msg githooks\\ngit commit --no-verify\\nList commits and changes to a specific file (even through renaming)\\ngit log --follow -p -- <file_path>\\nClone a single branch\\ngit clone -b <branch-name> --single-branch https://github.com/user/repo.git\\nCreate and switch new branch\\ngit checkout -b <branch-name>\\nAlternatives:\\ngit branch <branch-name> && git checkout <branch-name>\\nIgnore file mode changes on commits\\ngit config core.fileMode false\\nTurn off git colored terminal output\\ngit config --global color.ui false\\nSpecific color settings\\ngit config --global <specific command e.g branch, diff> <true, false or always>\\nShow all local branches ordered by recent commits\\ngit for-each-ref --sort=-committerdate --format=\\'%(refname:short)\\' refs/heads/\\nFind lines matching the pattern (regex or string) in tracked files\\ngit grep --heading --line-number \\'foo bar\\'\\nClone a shallow copy of a repository\\ngit clone https://github.com/user/repo.git --depth 1\\nSearch Commit log across all branches for given text\\ngit log --all --grep=\\'<given-text>\\'\\nGet first commit in a branch (from master)\\ngit log --oneline master..<branch-name> | tail -1\\nAlternatives:\\ngit log --reverse master..<branch-name> | head -6\\nUnstaging Staged file\\ngit reset HEAD <file-name>\\nForce push to Remote Repository\\ngit push -f <remote-name> <branch-name>\\nAdding Remote name\\ngit remote add <remote-nickname> <remote-url>\\nList all currently configured remotes\\ngit remote -v\\nShow the author, time and last revision made to each line of a given file\\ngit blame <file-name>\\nGroup commits by authors and title\\ngit shortlog\\nForced push but still ensure you don\\'t overwrite other\\'s work\\ngit push --force-with-lease <remote-name> <branch-name>\\nShow how many lines does an author contribute\\ngit log --author=\\'_Your_Name_Here_\\' --pretty=tformat: --numstat | gawk \\'{ add += <!-- @doxie.inject start -->; subs += <!-- @doxie.inject end -->; loc += <!-- @doxie.inject start --> - <!-- @doxie.inject end --> } END { printf \"added lines: %s removed lines: %s total lines: %s\\n\", add, subs, loc }\\' -\\nAlternatives:\\ngit log --author=\\'_Your_Name_Here_\\' --pretty=tformat: --numstat | awk \\'{ add += <!-- @doxie.inject start -->; subs += <!-- @doxie.inject end -->; loc += <!-- @doxie.inject start --> - <!-- @doxie.inject end --> } END { printf \"added lines: %s, removed lines: %s, total lines: %s\\n\", add, subs, loc }\\' - # on Mac OSX\\nRevert: Reverting an entire merge\\ngit revert -m 1 <commit-ish>\\nNumber of commits in a branch\\ngit rev-list --count <branch-name>\\nAlias: git undo\\ngit config --global alias.undo \\'!f() { git reset --hard $(git rev-parse --abbrev-ref HEAD)@{${1-1}}; }; f\\'\\nAdd object notes\\ngit notes add -m \\'Note on the previous commit....\\'\\nShow all the git-notes\\ngit log --show-notes=\\'*\\'\\nApply commit from another repository\\ngit --git-dir=<source-dir>/.git format-patch -k -1 --stdout <SHA1> | git am -3 -k\\nSpecific fetch reference\\ngit fetch origin master:refs/remotes/origin/mymaster\\nFind common ancestor of two branches\\ngit merge-base <branch-name> <other-branch-name>\\nList unpushed git commits\\ngit log --branches --not --remotes\\nAlternatives:\\ngit log @{u}..\\ngit cherry -v\\nAdd everything, but whitespace changes\\ngit diff --ignore-all-space | git apply --cached\\nEdit [local/global] git config\\ngit config [--global] --edit\\nblame on certain range\\ngit blame -L <start>,<end>\\nShow a Git logical variable.\\ngit var -l | <variable>\\nPreformatted patch file.\\ngit format-patch -M upstream..topic\\nGet the repo name.\\ngit rev-parse --show-toplevel\\nlogs between date range\\ngit log --since=\\'FEB 1 2017\\' --until=\\'FEB 14 2017\\'\\nExclude author from logs\\ngit log --perl-regexp --author=\\'^((?!excluded-author-regex).*)\\nGenerates a summary of pending changes\\ngit request-pull v1.0 https://git.ko.xz/project master:for-linus\\nList references in a remote repository\\ngit ls-remote git://git.kernel.org/pub/scm/git/git.git\\nBackup untracked files.\\ngit ls-files --others -i --exclude-standard | xargs zip untracked.zip\\nList all git aliases\\ngit config -l | grep alias | sed \\'s/^alias\\\\.//g\\'\\nAlternatives:\\ngit config -l | grep alias | cut -d \\'.\\' -f 2\\nShow git status short\\ngit status --short --branch\\nCheckout a commit prior to a day ago\\ngit checkout master@{yesterday}\\nPush a new local branch to remote repository and track\\ngit push -u origin <branch_name>\\nChange a branch base\\ngit rebase --onto <new_base> <old_base>\\nUse SSH instead of HTTPs for remotes\\ngit config --global url.\\'git@github.com:\\'.insteadOf \\'https://github.com/\\'\\nUpdate a submodule to the latest commit\\ncd <path-to-submodule>\\ngit pull origin <branch>\\ncd <root-of-your-main-project>\\ngit add <path-to-submodule>\\ngit commit -m \"submodule updated\"\\nPrevent auto replacing LF with CRLF\\ngit config --global core.autocrlf false',\n",
       "  'Chroma — A general purpose syntax highlighter in pure Go\\nNOTE: As Chroma has just been released, its API is still in flux. That said, the high-level interface should not change significantly.\\nChroma takes source code and other structured text and converts it into syntax highlighted HTML, ANSI-coloured text, etc.\\nChroma is based heavily on Pygments, and includes translators for Pygments lexers and styles.\\nTable of Contents\\nTable of Contents\\nSupported languages\\nTry it\\nUsing the library\\nQuick start\\nIdentifying the language\\nFormatting the output\\nThe HTML formatter\\nMore detail\\nLexers\\nFormatters\\nStyles\\nCommand-line interface\\nWhat\\'s missing compared to Pygments?\\nSupported languages\\nPrefix Language\\nA ABAP, ABNF, ActionScript, ActionScript 3, Ada, Angular2, ANTLR, ApacheConf, APL, AppleScript, Arduino, Awk\\nB Ballerina, Base Makefile, Bash, Batchfile, BibTeX, BlitzBasic, BNF, Brainfuck\\nC C, C#, C++, Caddyfile, Caddyfile Directives, Cap\\'n Proto, Cassandra CQL, Ceylon, CFEngine3, cfstatement, ChaiScript, Cheetah, Clojure, CMake, COBOL, CoffeeScript, Common Lisp, Coq, Crystal, CSS, Cython\\nD D, Dart, Diff, Django/Jinja, Docker, DTD, Dylan\\nE EBNF, Elixir, Elm, EmacsLisp, Erlang\\nF Factor, Fish, Forth, Fortran, FSharp\\nG GAS, GDScript, Genshi, Genshi HTML, Genshi Text, Gherkin, GLSL, Gnuplot, Go, Go HTML Template, Go Text Template, GraphQL, Groovy\\nH Handlebars, Haskell, Haxe, HCL, Hexdump, HLB, HTML, HTTP, Hy\\nI Idris, Igor, INI, Io\\nJ J, Java, JavaScript, JSON, Julia, Jungle\\nK Kotlin\\nL Lighttpd configuration file, LLVM, Lua\\nM Mako, markdown, Mason, Mathematica, Matlab, MiniZinc, MLIR, Modula-2, MonkeyC, MorrowindScript, Myghty, MySQL\\nN NASM, Newspeak, Nginx configuration file, Nim, Nix\\nO Objective-C, OCaml, Octave, OpenSCAD, Org Mode\\nP PacmanConf, Perl, PHP, PHTML, Pig, PkgConfig, PL/pgSQL, plaintext, Pony, PostgreSQL SQL dialect, PostScript, POVRay, PowerShell, Prolog, PromQL, Protocol Buffer, Puppet, Python, Python 3\\nQ QBasic\\nR R, Racket, Ragel, Raku, react, ReasonML, reg, reStructuredText, Rexx, Ruby, Rust\\nS SAS, Sass, Scala, Scheme, Scilab, SCSS, Smalltalk, Smarty, Snobol, Solidity, SPARQL, SQL, SquidConf, Standard ML, Stylus, Svelte, Swift, SYSTEMD, systemverilog\\nT TableGen, TASM, Tcl, Tcsh, Termcap, Terminfo, Terraform, TeX, Thrift, TOML, TradingView, Transact-SQL, Turing, Turtle, Twig, TypeScript, TypoScript, TypoScriptCssData, TypoScriptHtmlData\\nV VB.net, verilog, VHDL, VimL, vue\\nW WDTE\\nX XML, Xorg\\nY YAML, YANG\\nZ Zig\\nI will attempt to keep this section up to date, but an authoritative list can be displayed with chroma --list.\\nTry it\\nTry out various languages and styles on the Chroma Playground.\\nUsing the library\\nChroma, like Pygments, has the concepts of lexers, formatters and styles.\\nLexers convert source text into a stream of tokens, styles specify how token types are mapped to colours, and formatters convert tokens and styles into formatted output.\\nA package exists for each of these, containing a global Registry variable with all of the registered implementations. There are also helper functions for using the registry in each package, such as looking up lexers by name or matching filenames, etc.\\nIn all cases, if a lexer, formatter or style can not be determined, nil will be returned. In this situation you may want to default to the Fallback value in each respective package, which provides sane defaults.\\nQuick start\\nA convenience function exists that can be used to simply format some source text, without any effort:\\nerr := quick.Highlight(os.Stdout, someSourceCode, \"go\", \"html\", \"monokai\")\\nIdentifying the language\\nTo highlight code, you\\'ll first have to identify what language the code is written in. There are three primary ways to do that:\\nDetect the language from its filename.\\nlexer := lexers.Match(\"foo.go\")\\nExplicitly specify the language by its Chroma syntax ID (a full list is available from lexers.Names()).\\nlexer := lexers.Get(\"go\")\\nDetect the language from its content.\\nlexer := lexers.Analyse(\"package main\\\\n\\\\nfunc main()\\\\n{\\\\n}\\\\n\")\\nIn all cases, nil will be returned if the language can not be identified.\\nif lexer == nil {\\n  lexer = lexers.Fallback\\n}\\nAt this point, it should be noted that some lexers can be extremely chatty. To mitigate this, you can use the coalescing lexer to coalesce runs of identical token types into a single token:\\nlexer = chroma.Coalesce(lexer)\\nFormatting the output\\nOnce a language is identified you will need to pick a formatter and a style (theme).\\nstyle := styles.Get(\"swapoff\")\\nif style == nil {\\n  style = styles.Fallback\\n}\\nformatter := formatters.Get(\"html\")\\nif formatter == nil {\\n  formatter = formatters.Fallback\\n}\\nThen obtain an iterator over the tokens:\\ncontents, err := ioutil.ReadAll(r)\\niterator, err := lexer.Tokenise(nil, string(contents))\\nAnd finally, format the tokens from the iterator:\\nerr := formatter.Format(w, style, iterator)\\nThe HTML formatter\\nBy default the html registered formatter generates standalone HTML with embedded CSS. More flexibility is available through the formatters/html package.\\nFirstly, the output generated by the formatter can be customised with the following constructor options:\\nStandalone() - generate standalone HTML with embedded CSS.\\nWithClasses() - use classes rather than inlined style attributes.\\nClassPrefix(prefix) - prefix each generated CSS class.\\nTabWidth(width) - Set the rendered tab width, in characters.\\nWithLineNumbers() - Render line numbers (style with LineNumbers).\\nLinkableLineNumbers() - Make the line numbers linkable and be a link to themselves.\\nHighlightLines(ranges) - Highlight lines in these ranges (style with LineHighlight).\\nLineNumbersInTable() - Use a table for formatting line numbers and code, rather than spans.\\nIf WithClasses() is used, the corresponding CSS can be obtained from the formatter with:\\nformatter := html.New(html.WithClasses())\\nerr := formatter.WriteCSS(w, style)\\nMore detail\\nLexers\\nSee the Pygments documentation for details on implementing lexers. Most concepts apply directly to Chroma, but see existing lexer implementations for real examples.\\nIn many cases lexers can be automatically converted directly from Pygments by using the included Python 3 script pygments2chroma.py. I use something like the following:\\npython3 ~/Projects/chroma/_tools/pygments2chroma.py \\\\\\n  pygments.lexers.jvm.KotlinLexer \\\\\\n  > ~/Projects/chroma/lexers/kotlin.go \\\\\\n  && gofmt -s -w ~/Projects/chroma/lexers/*.go\\nSee notes in pygments-lexers.txt for a list of lexers, and notes on some of the issues importing them.\\nFormatters\\nChroma supports HTML output, as well as terminal output in 8 colour, 256 colour, and true-colour.\\nA noop formatter is included that outputs the token text only, and a tokens formatter outputs raw tokens. The latter is useful for debugging lexers.\\nStyles\\nChroma styles use the same syntax as Pygments.\\nAll Pygments styles have been converted to Chroma using the _tools/style.py script.\\nWhen you work with one of Chroma\\'s styles, know that the chroma.Background token type provides the default style for tokens. It does so by defining a foreground color and background color.\\nFor example, this gives each token name not defined in the style a default color of #f8f8f8 and uses #000000 for the highlighted code block\\'s background:\\nchroma.Background: \"#f8f8f2 bg:#000000\",\\nAlso, token types in a style file are hierarchical. For instance, when CommentSpecial is not defined, Chroma uses the token style from Comment. So when several comment tokens use the same color, you\\'ll only need to define Comment and override the one that has a different color.\\nFor a quick overview of the available styles and how they look, check out the Chroma Style Gallery.\\nCommand-line interface\\nA command-line interface to Chroma is included. It can be installed with:\\ngo get -u github.com/alecthomas/chroma/cmd/chroma\\nWhat\\'s missing compared to Pygments?\\nQuite a few lexers, for various reasons (pull-requests welcome):\\nPygments lexers for complex languages often include custom code to handle certain aspects, such as Raku\\'s ability to nest code inside regular expressions. These require time and effort to convert.\\nI mostly only converted languages I had heard of, to reduce the porting cost.\\nSome more esoteric features of Pygments are omitted for simplicity.\\nThough the Chroma API supports content detection, very few languages support them. I have plans to implement a statistical analyser at some point, but not enough time.',\n",
       "  \"Reporting Bugs/Feature Requests\\nAWS Amplify CLI\\nThe AWS Amplify CLI is a toolchain which includes a robust feature set for simplifying mobile and web application development. The CLI uses AWS CloudFormation and nested stacks to allow you to add or modify configurations locally before you push them for execution in your account.\\nInstall the CLI\\nCommands Summary\\nTutorials\\nContributing\\nStart building your app\\nChangelog\\nInstall the CLI\\nRequires Node.js® version 10 or later\\nInstall and configure the Amplify CLI as follows:\\n$ npm install -g @aws-amplify/cli\\n$ amplify configure\\nNote: If you're having permission issues on your system installing the CLI, please try the following command:\\n$ sudo npm install -g @aws-amplify/cli --unsafe-perm=true\\n$ amplify configure\\nCommands Summary\\nThe Amplify CLI supports the commands shown in the following table.\\nCommand Description\\namplify configure Configures the AWS access credentials, AWS Region and sets up a new AWS User Profile\\namplify init Initializes a new project, sets up deployment resources in the cloud and prepares your project for Amplify.\\namplify configure project Updates configuration settings used to setup the project during the init step.\\namplify add <category> Adds cloud features to your app.\\namplify update <category> Updates existing cloud features in your app.\\namplify push [--no-gql-override] Provisions cloud resources with the latest local developments. The 'no-gql-override' flag does not automatically compile your annotated GraphQL schema and will override your local AppSync resolvers and templates.\\namplify pull Fetch upstream backend environment definition changes from the cloud and updates the local environment to match that definition.\\namplify publish Runs amplify push, publishes a static assets to Amazon S3 and Amazon CloudFront (*hosting category is required).\\namplify status Displays the state of local resources that haven't been pushed to the cloud (Create/Update/Delete).\\namplify serve Runs amplify push, and then executes the project's start command to test run the client-side application.\\namplify delete Deletes resources tied to the project.\\namplify help | amplify <category> help Displays help for the core CLI.\\namplify codegen add | generate Performs generation of strongly typed objects using a GraphQL schema.\\namplify env add | list | remove | get | pull | import | checkout See the multienv docs.\\nCategory specific commands:\\nauth (Amazon Cognito)\\nstorage (Amazon S3 & Amazon DynamoDB)\\nfunction (AWS Lambda)\\napi (AWS AppSync & Amazon API Gateway)\\nanalytics (Amazon Pinpoint)\\nhosting (Amazon S3 and Amazon CloudFront distribution)\\nnotifications (Amazon Pinpoint)\\ninteractions (Amazon Lex)\\npredictions (Amazon Rekognition, Amazon Textract, Amazon Translate, Amazon Polly, Amazon Transcribe, Amazon Comprehend, and Amazon SageMaker)\\nTutorials\\nGetting Started guide\\nGraphQL transform tutorial\\nNative development with Amplify CLI and AWS AppSync\\nDeveloping\\nTo set up your local development environment, go to Local Environment Setup.\\nTo test your category, do the following:\\ncd <your-test-front-end-project>\\namplify-dev init\\namplify-dev <your-category> <subcommand>\\nBefore pushing code or sending a pull request, do the following:\\nAt the command line, run yarn lint at the top-level directory. This invokes eslint to check for lint errors in all of our packages.\\nYou can use yarn lint to find some of the lint errors. To attempt fix them, go to the package that has errors and run yarn lint-fix\\nIf there are any remaining lint errors, resolve them manually. Linting your code is a best practice that ensures good code quality so it's important that you don't skip this step.\\nContributing\\nWe are thankful for any contributions from the community. Look at our Contribution Guidelines.\",\n",
       "  'The Solidity Contract-Oriented Programming Language\\nYou can talk to us on Gitter and Matrix, tweet at us on Twitter or create a new topic in the Solidity forum. Questions, feedback, and suggestions are welcome!\\nSolidity is a statically typed, contract-oriented, high-level language for implementing smart contracts on the Ethereum platform.\\nFor a good overview and starting point, please check out the official Solidity Language Portal.\\nTable of Contents\\nBackground\\nBuild and Install\\nExample\\nDocumentation\\nDevelopment\\nMaintainers\\nLicense\\nSecurity\\nBackground\\nSolidity is a statically-typed curly-braces programming language designed for developing smart contracts that run on the Ethereum Virtual Machine. Smart contracts are programs that are executed inside a peer-to-peer network where nobody has special authority over the execution, and thus they allow to implement tokens of value, ownership, voting, and other kinds of logic.\\nWhen deploying contracts, you should use the latest released version of Solidity. This is because breaking changes, as well as new features and bug fixes are introduced regularly. We currently use a 0.x version number to indicate this fast pace of change.\\nBuild and Install\\nInstructions about how to build and install the Solidity compiler can be found in the Solidity documentation.\\nExample\\nA \"Hello World\" program in Solidity is of even less use than in other languages, but still:\\n// SPDX-License-Identifier: MIT\\npragma solidity >=0.6.0 <0.9.0;\\n\\ncontract HelloWorld {\\n    function helloWorld() external pure returns (string memory) {\\n        return \"Hello, World!\";\\n    }\\n}\\nTo get started with Solidity, you can use Remix, which is a browser-based IDE. Here are some example contracts:\\nVoting\\nBlind Auction\\nSafe remote purchase\\nMicropayment Channel\\nDocumentation\\nThe Solidity documentation is hosted at Read the docs.\\nDevelopment\\nSolidity is still under development. Contributions are always welcome! Please follow the Developers Guide if you want to help.\\nYou can find our current feature and bug priorities for forthcoming releases in the projects section.\\nMaintainers\\n@axic\\n@chriseth\\nLicense\\nSolidity is licensed under GNU General Public License v3.0.\\nSome third-party code has its own licensing terms.\\nSecurity\\nThe security policy may be found here.',\n",
       "  'Interactsh\\nAn OOB interaction gathering server and client library\\nFeatures • Installation • Usage • Run Interactsh • Self-Hosting • Join Discord\\nInteractsh is an Open-Source Solution for Out of band Data Extraction, A tool designed to detect bugs that cause external interactions, For example - Blind SQLi, Blind CMDi, SSRF, etc.\\nFeatures\\nDNS/HTTP/SMTP Interaction support\\nCLI Client / Web Dashboard support\\nAES encryption with zero logging\\nAutomatic ACME based Wildcard TLS w/ Auto Renewal\\nSELF Hosting version support\\nA hosted instance of the service with WEB UI is available at https://interact.projectdiscovery.io\\nInstalling Interactsh Client\\nInteractsh Client requires go1.15+ to install successfully. Run the following command to get the repo -\\n▶ GO111MODULE=on go get -v github.com/projectdiscovery/interactsh/cmd/interactsh-client\\nUsage\\ninteractsh-client -h\\nThis will display help for the tool. Here are all the switches it supports.\\nFlag Description Example\\nn Number of interactable URLs to generate (default 1) interactsh-client -n 2\\npersistent Enables persistent interactsh sessions interactsh-client persistent\\npoll-interval Number of seconds between each poll request (default 5) interactsh-client -poll-interval 1\\nurl URL of the interactsh server (default \"hxxps://interact.sh\") interactsh-client -url hxxps://example.com\\njson Show JSON output interactsh-client -json\\no Store interaction logs to file interactsh-client -o logs.txt\\nv Show verbose interaction interactsh-client -v\\nRunning Interactsh Client\\nThis will generate single URL that can be used for interaction.\\n▶ interactsh-client\\n\\n    _       __                       __       __  \\n   (_)___  / /____  _________ ______/ /______/ /_ \\n  / / __ \\\\/ __/ _ \\\\/ ___/ __ \\'/ ___/ __/ ___/ __ \\\\\\n / / / / / /_/  __/ /  / /_/ / /__/ /_(__  ) / / /\\n/_/_/ /_/\\\\__/\\\\___/_/   \\\\__,_/\\\\___/\\\\__/____/_/ /_/ v0.0.1\\n\\n  projectdiscovery.io\\n\\n[INF] Listing 1 URL for OOB Testing\\n[INF] c23b2la0kl1krjcrdj10cndmnioyyyyyn.interact.sh\\n\\n[c23b2la0kl1krjcrdj10cndmnioyyyyyn] Recieved DNS interaction (A) from 172.253.226.100 at 2021-26-26 12:26\\n[c23b2la0kl1krjcrdj10cndmnioyyyyyn] Recieved DNS interaction (AAAA) from 32.3.34.129 at 2021-26-26 12:26\\n[c23b2la0kl1krjcrdj10cndmnioyyyyyn] Recieved HTTP interaction from 43.22.22.50 at 2021-26-26 12:26\\n[c23b2la0kl1krjcrdj10cndmnioyyyyyn] Recieved DNS interaction (MX) from 43.3.192.3 at 2021-26-26 12:26\\n[c23b2la0kl1krjcrdj10cndmnioyyyyyn] Recieved DNS interaction (TXT) from 74.32.183.135 at 2021-26-26 12:26\\n[c23b2la0kl1krjcrdj10cndmnioyyyyyn] Recieved SMTP interaction from 32.85.166.50 at 2021-26-26 12:26\\nSending Interaction to Discord,Slack,Telegram with Notify\\n▶ interactsh-client | notify\\nSetting up self-hosted instance\\nClick here for details\\n\\nAcknowledgement\\nInteractsh is inspired from Burp Collaborator.\\nLicense\\nInteractsh is distributed under MIT License and made with 🖤 by the projectdiscovery team.',\n",
       "  'Ionic Framework\\nIonic Framework is the open-source mobile app development framework that makes it easy to build top quality native and progressive web apps with web technologies.\\nIonic Framework is based on Web Components and comes with many significant performance, usability, and feature improvements over the past versions.\\nPackages\\nProject Package Version Links\\nCore @ionic/core README.md\\nAngular @ionic/angular README.md\\nVue @ionic/vue README.md\\nReact @ionic/react README.md\\nLooking for the ionic-angular package? Ionic 3 has been moved to the ionic-v3 repo. See Earlier Versions.\\nGetting Started\\nStart a new project by following our quick Getting Started guide. We would love to hear from you! If you have any feedback or run into issues using our framework, please file an issue on this repository.\\nContributing\\nThanks for your interest in contributing! Read up on our guidelines for contributing and then look through our issues with a help wanted label.\\nPlease note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms.\\nExamples\\nThe Ionic Conference App is a full featured Ionic app. It is the perfect starting point for learning and building your own app.\\nFuture Goals\\nAs Ionic Framework components migrate to the web component standard, a goal of ours is to have Ionic Framework easily work within all of the popular frameworks.\\nEarlier Versions\\nThe source code for earlier versions of the Ionic Framework may exist in other repositories. Please open issues and pull requests in their respective repositories.\\nIonic 2/3: Moved to ionic-team/ionic-v3\\nIonic 1: Moved to ionic-team/ionic-v1'],\n",
       " 'Contributors_count': ['2',\n",
       "  '52',\n",
       "  '21',\n",
       "  '2',\n",
       "  '586',\n",
       "  '5',\n",
       "  '45',\n",
       "  '2',\n",
       "  '1,341',\n",
       "  '1',\n",
       "  '128',\n",
       "  '201',\n",
       "  '156',\n",
       "  '174',\n",
       "  '1',\n",
       "  '47',\n",
       "  '6',\n",
       "  '162',\n",
       "  '5,000+',\n",
       "  '74',\n",
       "  '123',\n",
       "  '185',\n",
       "  '388',\n",
       "  '3',\n",
       "  '407'],\n",
       " 'Languages_used': ['JavaScript, Shell',\n",
       "  '-',\n",
       "  'Python',\n",
       "  'Python',\n",
       "  'JavaScript, HTML, SCSS',\n",
       "  'Jupyter Notebook, Python, Shell',\n",
       "  'C++, Jupyter Notebook, CMake, Python, Cuda, C, Shell',\n",
       "  'PHP, Blade, Shell',\n",
       "  'Markdown',\n",
       "  'HTML',\n",
       "  'JavaScript',\n",
       "  'C++, Python, C, M4, Makefile, HTML',\n",
       "  'Python',\n",
       "  'C++, C, Python, Shell, Perl, Makefile',\n",
       "  'HTML, CSS, JavaScript',\n",
       "  'JavaScript, EJS, SCSS',\n",
       "  'TypeScript, CSS',\n",
       "  '-',\n",
       "  'C, Assembly, C++, Shell, Makefile, Perl',\n",
       "  'JavaScript',\n",
       "  'Go',\n",
       "  'TypeScript, JavaScript, EJS, Python, Shell, Yacc',\n",
       "  'C++, Solidity, Shell, Python, CMake, C',\n",
       "  'Go',\n",
       "  'TypeScript, HTML, SCSS, JavaScript, Vue, CSS']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the 'Repository_title', 'Repository_desc', 'Contributors_count', 'Languages_used' details\n",
    "for i in repo_links:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        d['Repository_title'].append(driver.find_element_by_xpath(\"//article/h1\").text)\n",
    "    except NoSuchElementException:\n",
    "        d['Repository_title'].append(driver.find_element_by_xpath(\"//strong\").text)\n",
    "    \n",
    "    try:    \n",
    "        d['Repository_desc'].append(driver.find_element_by_xpath(\"//article\").text)\n",
    "    except NoSuchElementException:\n",
    "        d['Repository_desc'].append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        d['Contributors_count'].append(driver.find_element_by_xpath(\"//a[contains(text(),'Contributors')]/span\").text)\n",
    "    except NoSuchElementException:\n",
    "        d['Contributors_count'].append(\"1\")\n",
    "        \n",
    "    try:\n",
    "        lang = driver.find_elements_by_xpath(\"//h2[contains(text(),'Languages')]/following::ul[1]/li/a/span[1]\")\n",
    "        if len(lang)>0:\n",
    "            t =lang[0].text\n",
    "            for j in range(1,len(lang)):\n",
    "                t = t + \", \"+ lang[j].text\n",
    "        else:\n",
    "            t=\"-\"\n",
    "        d['Languages_used'].append(t)\n",
    "    except NoSuchElementException:\n",
    "        d['Languages_used'].append(\"-\")\n",
    "        \n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_desc</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Languages_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VaccineNotifier</td>\n",
       "      <td>VaccineNotifier\\nVaccineNotifier checks the co...</td>\n",
       "      <td>2</td>\n",
       "      <td>JavaScript, Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kubernetes The Hard Way</td>\n",
       "      <td>Kubernetes The Hard Way\\nThis tutorial walks y...</td>\n",
       "      <td>52</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnlyFans DataScraper (Python 3.9.X)</td>\n",
       "      <td>OnlyFans DataScraper (Python 3.9.X)\\nMandatory...</td>\n",
       "      <td>21</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Self-Supervised Vision Transformers with DINO</td>\n",
       "      <td>Self-Supervised Vision Transformers with DINO\\...</td>\n",
       "      <td>2</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>docs</td>\n",
       "      <td>GitHub Docs\\nThis repository contains the docu...</td>\n",
       "      <td>586</td>\n",
       "      <td>JavaScript, HTML, SCSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CoWIN vaccination slot availability using Python</td>\n",
       "      <td>CoWIN vaccination slot availability using Pyth...</td>\n",
       "      <td>5</td>\n",
       "      <td>Jupyter Notebook, Python, Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flashlight</td>\n",
       "      <td>Quickstart | Installation | Documentation\\nFla...</td>\n",
       "      <td>45</td>\n",
       "      <td>C++, Jupyter Notebook, CMake, Python, Cuda, C,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wave</td>\n",
       "      <td>Introduction\\nWave is a Software as a Service ...</td>\n",
       "      <td>2</td>\n",
       "      <td>PHP, Blade, Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tldr</td>\n",
       "      <td>What is tldr-pages?\\nThe tldr-pages project is...</td>\n",
       "      <td>1,341</td>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>whatfreewords</td>\n",
       "      <td>This was a small test to show how one might re...</td>\n",
       "      <td>1</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Algorithms - JavaScript</td>\n",
       "      <td>The Algorithms - JavaScript\\n    All algorithm...</td>\n",
       "      <td>128</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dogecoin Core [DOGE, Ð]</td>\n",
       "      <td>Dogecoin Core [DOGE, Ð]\\nDogecoin is a cryptoc...</td>\n",
       "      <td>201</td>\n",
       "      <td>C++, Python, C, M4, Makefile, HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Fuck</td>\n",
       "      <td>The Fuck\\nThe Fuck is a magnificent app, inspi...</td>\n",
       "      <td>156</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Table of Contents</td>\n",
       "      <td>Table of Contents\\nWhat is openpilot?\\nIntegra...</td>\n",
       "      <td>174</td>\n",
       "      <td>C++, C, Python, Shell, Perl, Makefile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>COVID-19 Vaccine Tracker</td>\n",
       "      <td>COVID-19 Vaccine Tracker\\n🇮🇳 Get email alerts ...</td>\n",
       "      <td>1</td>\n",
       "      <td>HTML, CSS, JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vfat-tools</td>\n",
       "      <td>yieldfarming.info\\nIt ain't much, but it's hon...</td>\n",
       "      <td>47</td>\n",
       "      <td>JavaScript, EJS, SCSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fork Explorer</td>\n",
       "      <td>Fork Explorer\\nFork Explorer let's you see the...</td>\n",
       "      <td>6</td>\n",
       "      <td>TypeScript, CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Art of Command Line</td>\n",
       "      <td>🌍 Čeština ∙ Deutsch ∙ Ελληνικά ∙ English ∙ Esp...</td>\n",
       "      <td>162</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>linux</td>\n",
       "      <td>-</td>\n",
       "      <td>5,000+</td>\n",
       "      <td>C, Assembly, C++, Shell, Makefile, Perl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tips</td>\n",
       "      <td>git-tips\\nCollection of git-tips, want to add ...</td>\n",
       "      <td>74</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chroma — A general purpose syntax highlighter ...</td>\n",
       "      <td>Chroma — A general purpose syntax highlighter ...</td>\n",
       "      <td>123</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AWS Amplify CLI</td>\n",
       "      <td>Reporting Bugs/Feature Requests\\nAWS Amplify C...</td>\n",
       "      <td>185</td>\n",
       "      <td>TypeScript, JavaScript, EJS, Python, Shell, Yacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The Solidity Contract-Oriented Programming Lan...</td>\n",
       "      <td>The Solidity Contract-Oriented Programming Lan...</td>\n",
       "      <td>388</td>\n",
       "      <td>C++, Solidity, Shell, Python, CMake, C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Interactsh</td>\n",
       "      <td>Interactsh\\nAn OOB interaction gathering serve...</td>\n",
       "      <td>3</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ionic Framework</td>\n",
       "      <td>Ionic Framework\\nIonic Framework is the open-s...</td>\n",
       "      <td>407</td>\n",
       "      <td>TypeScript, HTML, SCSS, JavaScript, Vue, CSS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository_title  \\\n",
       "0                                     VaccineNotifier   \n",
       "1                             Kubernetes The Hard Way   \n",
       "2                 OnlyFans DataScraper (Python 3.9.X)   \n",
       "3       Self-Supervised Vision Transformers with DINO   \n",
       "4                                                docs   \n",
       "5    CoWIN vaccination slot availability using Python   \n",
       "6                                          flashlight   \n",
       "7                                                wave   \n",
       "8                                                tldr   \n",
       "9                                       whatfreewords   \n",
       "10                        The Algorithms - JavaScript   \n",
       "11                            Dogecoin Core [DOGE, Ð]   \n",
       "12                                           The Fuck   \n",
       "13                                  Table of Contents   \n",
       "14                           COVID-19 Vaccine Tracker   \n",
       "15                                         vfat-tools   \n",
       "16                                      Fork Explorer   \n",
       "17                            The Art of Command Line   \n",
       "18                                              linux   \n",
       "19                                               tips   \n",
       "20  Chroma — A general purpose syntax highlighter ...   \n",
       "21                                    AWS Amplify CLI   \n",
       "22  The Solidity Contract-Oriented Programming Lan...   \n",
       "23                                         Interactsh   \n",
       "24                                    Ionic Framework   \n",
       "\n",
       "                                      Repository_desc Contributors_count  \\\n",
       "0   VaccineNotifier\\nVaccineNotifier checks the co...                  2   \n",
       "1   Kubernetes The Hard Way\\nThis tutorial walks y...                 52   \n",
       "2   OnlyFans DataScraper (Python 3.9.X)\\nMandatory...                 21   \n",
       "3   Self-Supervised Vision Transformers with DINO\\...                  2   \n",
       "4   GitHub Docs\\nThis repository contains the docu...                586   \n",
       "5   CoWIN vaccination slot availability using Pyth...                  5   \n",
       "6   Quickstart | Installation | Documentation\\nFla...                 45   \n",
       "7   Introduction\\nWave is a Software as a Service ...                  2   \n",
       "8   What is tldr-pages?\\nThe tldr-pages project is...              1,341   \n",
       "9   This was a small test to show how one might re...                  1   \n",
       "10  The Algorithms - JavaScript\\n    All algorithm...                128   \n",
       "11  Dogecoin Core [DOGE, Ð]\\nDogecoin is a cryptoc...                201   \n",
       "12  The Fuck\\nThe Fuck is a magnificent app, inspi...                156   \n",
       "13  Table of Contents\\nWhat is openpilot?\\nIntegra...                174   \n",
       "14  COVID-19 Vaccine Tracker\\n🇮🇳 Get email alerts ...                  1   \n",
       "15  yieldfarming.info\\nIt ain't much, but it's hon...                 47   \n",
       "16  Fork Explorer\\nFork Explorer let's you see the...                  6   \n",
       "17  🌍 Čeština ∙ Deutsch ∙ Ελληνικά ∙ English ∙ Esp...                162   \n",
       "18                                                  -             5,000+   \n",
       "19  git-tips\\nCollection of git-tips, want to add ...                 74   \n",
       "20  Chroma — A general purpose syntax highlighter ...                123   \n",
       "21  Reporting Bugs/Feature Requests\\nAWS Amplify C...                185   \n",
       "22  The Solidity Contract-Oriented Programming Lan...                388   \n",
       "23  Interactsh\\nAn OOB interaction gathering serve...                  3   \n",
       "24  Ionic Framework\\nIonic Framework is the open-s...                407   \n",
       "\n",
       "                                       Languages_used  \n",
       "0                                   JavaScript, Shell  \n",
       "1                                                   -  \n",
       "2                                              Python  \n",
       "3                                              Python  \n",
       "4                              JavaScript, HTML, SCSS  \n",
       "5                     Jupyter Notebook, Python, Shell  \n",
       "6   C++, Jupyter Notebook, CMake, Python, Cuda, C,...  \n",
       "7                                   PHP, Blade, Shell  \n",
       "8                                            Markdown  \n",
       "9                                                HTML  \n",
       "10                                         JavaScript  \n",
       "11                 C++, Python, C, M4, Makefile, HTML  \n",
       "12                                             Python  \n",
       "13              C++, C, Python, Shell, Perl, Makefile  \n",
       "14                              HTML, CSS, JavaScript  \n",
       "15                              JavaScript, EJS, SCSS  \n",
       "16                                    TypeScript, CSS  \n",
       "17                                                  -  \n",
       "18            C, Assembly, C++, Shell, Makefile, Perl  \n",
       "19                                         JavaScript  \n",
       "20                                                 Go  \n",
       "21   TypeScript, JavaScript, EJS, Python, Shell, Yacc  \n",
       "22             C++, Solidity, Shell, Python, CMake, C  \n",
       "23                                                 Go  \n",
       "24       TypeScript, HTML, SCSS, JavaScript, Vue, CSS  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of top 100 songs on billiboard.com.\n",
    "### Url = https://www.billboard.com/\n",
    "### You have to find the following details:\n",
    "### A) Song name\n",
    "### B) Artist name\n",
    "### C) Last week rank\n",
    "### D) Peak rank\n",
    "### E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to Charts Page\n",
    "Charts_page = driver.find_element_by_xpath(\"//header/div/ul/li/a[contains(text(),'Charts')]\").get_attribute('href')\n",
    "driver.get(Charts_page)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to Top 100 Page\n",
    "top_100_page = driver.find_element_by_xpath(\"//div[@class='charts-landing__block']/a\").get_attribute('href')\n",
    "driver.get(top_100_page)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the dictionary\n",
    "d = {\n",
    "    'Song_Name':[],\n",
    "    'Artist_Name':[],\n",
    "    'Last_Week_Rank':[],\n",
    "    'Peak_Rank':[],\n",
    "    'Weeks_on_Board':[],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Song_Name': ['Save Your Tears',\n",
       "  'Leave The Door Open',\n",
       "  'Peaches',\n",
       "  'Rapstar',\n",
       "  'Levitating',\n",
       "  'Kiss Me More',\n",
       "  'Montero (Call Me By Your Name)',\n",
       "  'Astronaut In The Ocean',\n",
       "  'Up',\n",
       "  'Drivers License',\n",
       "  'Blinding Lights',\n",
       "  'Deja Vu',\n",
       "  'Beat Box',\n",
       "  'Calling My Phone',\n",
       "  'On Me',\n",
       "  'Best Friend',\n",
       "  'Heartbreak Anniversary',\n",
       "  'Beautiful Mistakes',\n",
       "  'What You Know Bout Love',\n",
       "  'Mood',\n",
       "  \"My Ex's Best Friend\",\n",
       "  'Back In Blood',\n",
       "  'Without You',\n",
       "  'The Good Ones',\n",
       "  'Go Crazy',\n",
       "  'You Broke Me First.',\n",
       "  '34+35',\n",
       "  'Hell Of A View',\n",
       "  'Forever After All',\n",
       "  \"What's Next\",\n",
       "  'Time Today',\n",
       "  'Therefore I Am',\n",
       "  'Dakiti',\n",
       "  'Positions',\n",
       "  'Shottas (Lala)',\n",
       "  'Solid',\n",
       "  'Track Star',\n",
       "  'Ski',\n",
       "  'Wants And Needs',\n",
       "  \"You're Mines Still\",\n",
       "  \"We're Good\",\n",
       "  'Heat Waves',\n",
       "  'Made For You',\n",
       "  'Good Days',\n",
       "  'For The Night',\n",
       "  \"Breaking Up Was Easy In The 90's\",\n",
       "  'No More Parties',\n",
       "  'Goosebumps',\n",
       "  'Telepatia',\n",
       "  'Tombstone',\n",
       "  'Streets',\n",
       "  'Go!',\n",
       "  'Hard For The Next',\n",
       "  'If Pain Was A Person',\n",
       "  \"What's Your Country Song\",\n",
       "  'Just The Way',\n",
       "  'Hold On',\n",
       "  'Settling Down',\n",
       "  'Wockesha',\n",
       "  'Botella Tras Botella',\n",
       "  'Willow',\n",
       "  'Damage',\n",
       "  'Street Runner',\n",
       "  'Come Through',\n",
       "  'Somebody Like That',\n",
       "  'pov',\n",
       "  'Lil Bit',\n",
       "  'Gone',\n",
       "  'Nobody',\n",
       "  'Famous Friends',\n",
       "  'Quicksand',\n",
       "  'Lady',\n",
       "  'The Business',\n",
       "  'La Noche de Anoche',\n",
       "  'One Too Many',\n",
       "  'Richer',\n",
       "  'Almost Maybes',\n",
       "  'Follow You',\n",
       "  'Glad You Exist',\n",
       "  'Free Promo',\n",
       "  'Pick Up Your Feelings',\n",
       "  'Just Say Det',\n",
       "  'Big Gangsta',\n",
       "  'Down To One',\n",
       "  'Headshot',\n",
       "  'Hellcats & Trackhawks',\n",
       "  'Anyone',\n",
       "  'My Head And My Heart',\n",
       "  'How They Remember You',\n",
       "  'Arcade',\n",
       "  \"Drunk (And I Don't Wanna Go Home)\",\n",
       "  'Masterpiece',\n",
       "  'Long Live',\n",
       "  'Chasing After You',\n",
       "  'Drankin N Smokin',\n",
       "  '4 Da Gang',\n",
       "  'Blame It On You',\n",
       "  'Wasted On You',\n",
       "  'Way Less Sad',\n",
       "  'Clear Da Air'],\n",
       " 'Artist_Name': ['The Weeknd & Ariana Grande',\n",
       "  'Silk Sonic (Bruno Mars & Anderson .Paak)',\n",
       "  'Justin Bieber Featuring Daniel Caesar & Giveon',\n",
       "  'Polo G',\n",
       "  'Dua Lipa Featuring DaBaby',\n",
       "  'Doja Cat Featuring SZA',\n",
       "  'Lil Nas X',\n",
       "  'Masked Wolf',\n",
       "  'Cardi B',\n",
       "  'Olivia Rodrigo',\n",
       "  'The Weeknd',\n",
       "  'Olivia Rodrigo',\n",
       "  'SpotemGottem Featuring Pooh Shiesty Or DaBaby',\n",
       "  'Lil Tjay Featuring 6LACK',\n",
       "  'Lil Baby',\n",
       "  'Saweetie Featuring Doja Cat',\n",
       "  'Giveon',\n",
       "  'Maroon 5 Featuring Megan Thee Stallion',\n",
       "  'Pop Smoke',\n",
       "  '24kGoldn Featuring iann dior',\n",
       "  'Machine Gun Kelly X blackbear',\n",
       "  'Pooh Shiesty Featuring Lil Durk',\n",
       "  'The Kid LAROI',\n",
       "  'Gabby Barrett',\n",
       "  'Chris Brown & Young Thug',\n",
       "  'Tate McRae',\n",
       "  'Ariana Grande',\n",
       "  'Eric Church',\n",
       "  'Luke Combs',\n",
       "  'Drake',\n",
       "  'Moneybagg Yo',\n",
       "  'Billie Eilish',\n",
       "  'Bad Bunny & Jhay Cortez',\n",
       "  'Ariana Grande',\n",
       "  'Moneybagg Yo',\n",
       "  'Young Thug & Gunna Featuring Drake',\n",
       "  'Mooski',\n",
       "  'Young Thug & Gunna',\n",
       "  'Drake Featuring Lil Baby',\n",
       "  'Yung Bleu Featuring Drake',\n",
       "  'Dua Lipa',\n",
       "  'Glass Animals',\n",
       "  'Jake Owen',\n",
       "  'SZA',\n",
       "  'Pop Smoke Featuring Lil Baby & DaBaby',\n",
       "  'Sam Hunt',\n",
       "  'Coi Leray Featuring Lil Durk',\n",
       "  'Travis Scott & HVME',\n",
       "  'Kali Uchis',\n",
       "  'Rod Wave',\n",
       "  'Doja Cat',\n",
       "  'Moneybagg Yo Featuring BIG30',\n",
       "  'Moneybagg Yo & Future',\n",
       "  'Moneybagg Yo',\n",
       "  'Thomas Rhett',\n",
       "  'Parmalee x Blanco Brown',\n",
       "  'Justin Bieber',\n",
       "  'Miranda Lambert',\n",
       "  'Moneybagg Yo',\n",
       "  'Gera MX + Christian Nodal',\n",
       "  'Taylor Swift',\n",
       "  'H.E.R.',\n",
       "  'Rod Wave',\n",
       "  'H.E.R. Featuring Chris Brown',\n",
       "  'Tenille Arts',\n",
       "  'Ariana Grande',\n",
       "  'Nelly & Florida Georgia Line',\n",
       "  'Dierks Bentley',\n",
       "  'Dylan Scott',\n",
       "  'Chris Young + Kane Brown',\n",
       "  'Morray',\n",
       "  'Brett Young',\n",
       "  'Tiesto',\n",
       "  'Bad Bunny & Rosalia',\n",
       "  'Keith Urban Duet With P!nk',\n",
       "  'Rod Wave Featuring Polo G',\n",
       "  'Jordan Davis',\n",
       "  'Imagine Dragons',\n",
       "  'Dan + Shay',\n",
       "  'Moneybagg Yo Featuring Polo G & Lil Durk',\n",
       "  'Jazmine Sullivan',\n",
       "  'Moneybagg Yo',\n",
       "  'Kevin Gates',\n",
       "  'Luke Bryan',\n",
       "  'Lil Tjay, Polo G & Fivio Foreign',\n",
       "  'Lil Durk',\n",
       "  'Justin Bieber',\n",
       "  'Ava Max',\n",
       "  'Rascal Flatts',\n",
       "  'Duncan Laurence',\n",
       "  'Elle King & Miranda Lambert',\n",
       "  'DaBaby',\n",
       "  'Florida Georgia Line',\n",
       "  'Ryan Hurd With Maren Morris',\n",
       "  'Future & Lil Uzi Vert',\n",
       "  '42 Dugg & Roddy Ricch',\n",
       "  'Jason Aldean',\n",
       "  'Morgan Wallen',\n",
       "  'AJR',\n",
       "  'Moneybagg Yo'],\n",
       " 'Last_Week_Rank': ['6',\n",
       "  '2',\n",
       "  '3',\n",
       "  '1',\n",
       "  '5',\n",
       "  '8',\n",
       "  '4',\n",
       "  '7',\n",
       "  '9',\n",
       "  '10',\n",
       "  '13',\n",
       "  '11',\n",
       "  '14',\n",
       "  '16',\n",
       "  '32',\n",
       "  '15',\n",
       "  '20',\n",
       "  '22',\n",
       "  '17',\n",
       "  '19',\n",
       "  '27',\n",
       "  '23',\n",
       "  '31',\n",
       "  '21',\n",
       "  '24',\n",
       "  '25',\n",
       "  '26',\n",
       "  '41',\n",
       "  '35',\n",
       "  '28',\n",
       "  '53',\n",
       "  '30',\n",
       "  '29',\n",
       "  '33',\n",
       "  '-',\n",
       "  '12',\n",
       "  '37',\n",
       "  '18',\n",
       "  '36',\n",
       "  '34',\n",
       "  '38',\n",
       "  '39',\n",
       "  '42',\n",
       "  '44',\n",
       "  '40',\n",
       "  '49',\n",
       "  '43',\n",
       "  '47',\n",
       "  '54',\n",
       "  '48',\n",
       "  '51',\n",
       "  '96',\n",
       "  '-',\n",
       "  '-',\n",
       "  '52',\n",
       "  '58',\n",
       "  '56',\n",
       "  '65',\n",
       "  '-',\n",
       "  '-',\n",
       "  '60',\n",
       "  '61',\n",
       "  '57',\n",
       "  '-',\n",
       "  '50',\n",
       "  '81',\n",
       "  '89',\n",
       "  '74',\n",
       "  '86',\n",
       "  '73',\n",
       "  '71',\n",
       "  '70',\n",
       "  '78',\n",
       "  '64',\n",
       "  '72',\n",
       "  '62',\n",
       "  '76',\n",
       "  '84',\n",
       "  '63',\n",
       "  '-',\n",
       "  '88',\n",
       "  '-',\n",
       "  '87',\n",
       "  '69',\n",
       "  '67',\n",
       "  '83',\n",
       "  '68',\n",
       "  '75',\n",
       "  '-',\n",
       "  '94',\n",
       "  '79',\n",
       "  '80',\n",
       "  '82',\n",
       "  '91',\n",
       "  '97',\n",
       "  '100',\n",
       "  '-',\n",
       "  '92',\n",
       "  '-',\n",
       "  '-'],\n",
       " 'Peak_Rank': ['1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '5',\n",
       "  '6',\n",
       "  '1',\n",
       "  '7',\n",
       "  '1',\n",
       "  '1',\n",
       "  '1',\n",
       "  '8',\n",
       "  '12',\n",
       "  '3',\n",
       "  '15',\n",
       "  '14',\n",
       "  '17',\n",
       "  '18',\n",
       "  '9',\n",
       "  '1',\n",
       "  '21',\n",
       "  '13',\n",
       "  '23',\n",
       "  '19',\n",
       "  '3',\n",
       "  '17',\n",
       "  '2',\n",
       "  '28',\n",
       "  '2',\n",
       "  '1',\n",
       "  '31',\n",
       "  '2',\n",
       "  '5',\n",
       "  '1',\n",
       "  '35',\n",
       "  '12',\n",
       "  '35',\n",
       "  '18',\n",
       "  '2',\n",
       "  '18',\n",
       "  '38',\n",
       "  '39',\n",
       "  '42',\n",
       "  '9',\n",
       "  '6',\n",
       "  '46',\n",
       "  '26',\n",
       "  '47',\n",
       "  '39',\n",
       "  '11',\n",
       "  '16',\n",
       "  '52',\n",
       "  '49',\n",
       "  '54',\n",
       "  '29',\n",
       "  '31',\n",
       "  '20',\n",
       "  '58',\n",
       "  '59',\n",
       "  '60',\n",
       "  '1',\n",
       "  '44',\n",
       "  '16',\n",
       "  '64',\n",
       "  '50',\n",
       "  '40',\n",
       "  '67',\n",
       "  '68',\n",
       "  '69',\n",
       "  '70',\n",
       "  '71',\n",
       "  '52',\n",
       "  '69',\n",
       "  '53',\n",
       "  '62',\n",
       "  '22',\n",
       "  '73',\n",
       "  '78',\n",
       "  '63',\n",
       "  '80',\n",
       "  '75',\n",
       "  '82',\n",
       "  '81',\n",
       "  '36',\n",
       "  '42',\n",
       "  '69',\n",
       "  '6',\n",
       "  '45',\n",
       "  '89',\n",
       "  '90',\n",
       "  '79',\n",
       "  '55',\n",
       "  '45',\n",
       "  '91',\n",
       "  '31',\n",
       "  '67',\n",
       "  '97',\n",
       "  '9',\n",
       "  '99',\n",
       "  '100'],\n",
       " 'Weeks_on_Board': ['20',\n",
       "  '8',\n",
       "  '6',\n",
       "  '3',\n",
       "  '30',\n",
       "  '3',\n",
       "  '5',\n",
       "  '11',\n",
       "  '12',\n",
       "  '16',\n",
       "  '73',\n",
       "  '4',\n",
       "  '15',\n",
       "  '11',\n",
       "  '21',\n",
       "  '16',\n",
       "  '11',\n",
       "  '8',\n",
       "  '34',\n",
       "  '38',\n",
       "  '37',\n",
       "  '17',\n",
       "  '21',\n",
       "  '18',\n",
       "  '51',\n",
       "  '36',\n",
       "  '26',\n",
       "  '16',\n",
       "  '27',\n",
       "  '8',\n",
       "  '12',\n",
       "  '25',\n",
       "  '26',\n",
       "  '27',\n",
       "  '1',\n",
       "  '2',\n",
       "  '10',\n",
       "  '2',\n",
       "  '8',\n",
       "  '21',\n",
       "  '11',\n",
       "  '15',\n",
       "  '10',\n",
       "  '18',\n",
       "  '43',\n",
       "  '9',\n",
       "  '12',\n",
       "  '15',\n",
       "  '10',\n",
       "  '6',\n",
       "  '16',\n",
       "  '2',\n",
       "  '3',\n",
       "  '1',\n",
       "  '19',\n",
       "  '18',\n",
       "  '8',\n",
       "  '7',\n",
       "  '1',\n",
       "  '1',\n",
       "  '20',\n",
       "  '20',\n",
       "  '7',\n",
       "  '1',\n",
       "  '15',\n",
       "  '8',\n",
       "  '6',\n",
       "  '7',\n",
       "  '9',\n",
       "  '5',\n",
       "  '12',\n",
       "  '16',\n",
       "  '10',\n",
       "  '14',\n",
       "  '20',\n",
       "  '5',\n",
       "  '14',\n",
       "  '4',\n",
       "  '12',\n",
       "  '1',\n",
       "  '14',\n",
       "  '1',\n",
       "  '3',\n",
       "  '18',\n",
       "  '6',\n",
       "  '7',\n",
       "  '17',\n",
       "  '12',\n",
       "  '2',\n",
       "  '3',\n",
       "  '3',\n",
       "  '14',\n",
       "  '17',\n",
       "  '2',\n",
       "  '13',\n",
       "  '4',\n",
       "  '1',\n",
       "  '16',\n",
       "  '1',\n",
       "  '1']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching 'Song_Name', 'Artist_Name', 'Last_Week_Rank', 'Peak_Rank', 'Weeks_on_Board' details\n",
    "songs = driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "artist = driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "last_week = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "peak_rank = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "week_on_board = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "\n",
    "for i in range(100):\n",
    "    d['Song_Name'].append(songs[i].text)\n",
    "    d['Artist_Name'].append(artist[i].text)\n",
    "    d['Last_Week_Rank'].append(last_week[i].text)\n",
    "    d['Peak_Rank'].append(peak_rank[i].text)\n",
    "    d['Weeks_on_Board'].append(week_on_board[i].text)\n",
    "d    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "      <th>Peak_Rank</th>\n",
       "      <th>Weeks_on_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rapstar</td>\n",
       "      <td>Polo G</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4 Da Gang</td>\n",
       "      <td>42 Dugg &amp; Roddy Ricch</td>\n",
       "      <td>100</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Blame It On You</td>\n",
       "      <td>Jason Aldean</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wasted On You</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Way Less Sad</td>\n",
       "      <td>AJR</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Clear Da Air</td>\n",
       "      <td>Moneybagg Yo</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Song_Name                                     Artist_Name  \\\n",
       "0       Save Your Tears                      The Weeknd & Ariana Grande   \n",
       "1   Leave The Door Open        Silk Sonic (Bruno Mars & Anderson .Paak)   \n",
       "2               Peaches  Justin Bieber Featuring Daniel Caesar & Giveon   \n",
       "3               Rapstar                                          Polo G   \n",
       "4            Levitating                       Dua Lipa Featuring DaBaby   \n",
       "..                  ...                                             ...   \n",
       "95            4 Da Gang                           42 Dugg & Roddy Ricch   \n",
       "96      Blame It On You                                    Jason Aldean   \n",
       "97        Wasted On You                                   Morgan Wallen   \n",
       "98         Way Less Sad                                             AJR   \n",
       "99         Clear Da Air                                    Moneybagg Yo   \n",
       "\n",
       "   Last_Week_Rank Peak_Rank Weeks_on_Board  \n",
       "0               6         1             20  \n",
       "1               2         1              8  \n",
       "2               3         1              6  \n",
       "3               1         1              3  \n",
       "4               5         5             30  \n",
       "..            ...       ...            ...  \n",
       "95            100        67              4  \n",
       "96              -        97              1  \n",
       "97             92         9             16  \n",
       "98              -        99              1  \n",
       "99              -       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Scrape the details of Data science recruiters from naukri.com.\n",
    "### Url = https://www.naukri.com/\n",
    "### You have to find the following details:\n",
    "### A) Name\n",
    "### B) Designation\n",
    "### C) Company\n",
    "### D) Skills they hire for\n",
    "### E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing pop-ups\n",
    "try:\n",
    "    driver.find_element_by_xpath(\"//span[@id='block']\").click()\n",
    "except:\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to Recruiters Page\n",
    "Rec_page = driver.find_element_by_xpath(\"//a[@title='Search Recruiters']\").get_attribute('href')\n",
    "driver.get(Rec_page)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entering “Data Science” in  “Skill,Designations,Companies” field\n",
    "des_inp = driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "des_inp.send_keys(\"Data science\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search Button\n",
    "button =  driver.find_element_by_xpath(\"//button[@id='qsbFormBtn']\")\n",
    "button.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the dictionary\n",
    "d = {\n",
    "    'Name':[],\n",
    "    'Designation':[],\n",
    "    'Company':[],\n",
    "    'Skills_Required':[],\n",
    "    'Location':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching total number of rows\n",
    "rows = driver.find_elements_by_xpath(\"//div[@class='outerRecSec']\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising variables for xpath\n",
    "str_ = \"//div[@class='outerRecSec'][\"\n",
    "left_ = \"]/div[@class='recSec fl fadeInUp']\"\n",
    "right_ = \"]/div[@class='recSec fr fadeInUp']\"\n",
    "p_ = \"//p[@class='highlightable']\"\n",
    "skil_ = \"//div[@class='hireSec highlightable']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': ['Aakash Harit',\n",
       "  'shravan Kumar Gaddam',\n",
       "  'Talent Acquisition Executive',\n",
       "  'Anik Agrawal',\n",
       "  'MARSIAN Technologies LLP',\n",
       "  'subhas patel',\n",
       "  'Abhishek - Only Analytics Hiring - India and',\n",
       "  'Institute for Financial Management and Resear',\n",
       "  'Balu Ramesh',\n",
       "  'Asif Lucknowi',\n",
       "  'InstaFinancials',\n",
       "  'Kalpana Dumpala',\n",
       "  'Mubarak',\n",
       "  'Kushal Rastogi',\n",
       "  'Ruchi Dhote',\n",
       "  'Mahesh Babu Channa',\n",
       "  'Manisha Yadav',\n",
       "  'Kapil Devang',\n",
       "  'Priya Khare',\n",
       "  'Riya Rajesh',\n",
       "  'Rashmi Bhattacharjee',\n",
       "  'Faizan Kareem',\n",
       "  'Rithika dadwal',\n",
       "  'Azahar Shaikh',\n",
       "  'Sandhya Khandagale',\n",
       "  'Shaun Rao',\n",
       "  'Manas',\n",
       "  'kumar',\n",
       "  'Sunil Vedula',\n",
       "  'Rajat Kumar',\n",
       "  'Dhruv Dev Dubey',\n",
       "  'Jayanth N',\n",
       "  'SREEDHAR',\n",
       "  'Prateek Kumar',\n",
       "  'Amit Sharma',\n",
       "  'Kanan',\n",
       "  'Shashikant Chaudhary',\n",
       "  'Brad',\n",
       "  'Rutuja Pawar',\n",
       "  'Madhusudhan Sridhar',\n",
       "  'Ankit Sinha',\n",
       "  'Gaurav Chouhan',\n",
       "  'Rashi Kacker',\n",
       "  'Ashwini',\n",
       "  'Balaji Kolli',\n",
       "  'Rajani Nagaraj',\n",
       "  'ROHIT Kumar',\n",
       "  'Amir Chowdhury',\n",
       "  'Shailja Mishra',\n",
       "  'Sunny Sharma'],\n",
       " 'Designation': ['HR Manager',\n",
       "  'Company Recruiter',\n",
       "  'Recruitment Professional',\n",
       "  'Company Recruiter',\n",
       "  'Company HR',\n",
       "  'Founder CEO',\n",
       "  'Recruitment Lead Consultant',\n",
       "  'Programme Manager',\n",
       "  'HR Administrator',\n",
       "  'Director',\n",
       "  'Human Resource',\n",
       "  'Executive Hiring',\n",
       "  'Company HR',\n",
       "  'Company HR',\n",
       "  'Senior Executive Talent Acquisition',\n",
       "  'HR Team Lead',\n",
       "  'HR Executive',\n",
       "  'HR Manager',\n",
       "  'Senior Manager',\n",
       "  'Manager Talent Acquisition',\n",
       "  'HR Head',\n",
       "  'HR MANAGER',\n",
       "  'HR Recruiter',\n",
       "  'Company Recruiter',\n",
       "  'HR Recruiter',\n",
       "  'Manager Human Resources',\n",
       "  'Lead Talent acquisition',\n",
       "  'Proprietor',\n",
       "  'CEO',\n",
       "  'Founder CEO',\n",
       "  'Company Recruitment Head',\n",
       "  'Project Manager',\n",
       "  'Recruitment Consultant',\n",
       "  'Head',\n",
       "  'Consultant',\n",
       "  'senior technology instructor',\n",
       "  'HR Recruiter/HR Excutive',\n",
       "  'Manager, Technical Recruiting',\n",
       "  'Technical Recruiter',\n",
       "  'Erp Implementer',\n",
       "  'Head Analytics',\n",
       "  'Chief Technical Officer',\n",
       "  'Sr Product Manager',\n",
       "  'Director Global Delivery',\n",
       "  'Co Founder',\n",
       "  'HR Manager',\n",
       "  'Architect',\n",
       "  'Managing Partner',\n",
       "  'HR Manager',\n",
       "  'Managing Director - HR'],\n",
       " 'Company': ['Data Science Network',\n",
       "  'Shore Infotech India Pvt. Ltd',\n",
       "  'XenonStack',\n",
       "  'Enerlytics Software Solutions Pvt Ltd',\n",
       "  'MARSIAN Technologies LLP',\n",
       "  'LibraryXProject',\n",
       "  'Apidel Technologies Division of Transpower',\n",
       "  'IFMR',\n",
       "  'Techvantage Systems Pvt Ltd',\n",
       "  'Weupskill- Live Wire India',\n",
       "  'CBL Data Science Private Limited',\n",
       "  'Innominds Software',\n",
       "  'MoneyTap',\n",
       "  'QuantMagnum Technologies Pvt. Ltd.',\n",
       "  'Bristlecone India Ltd',\n",
       "  'SocialPrachar.com',\n",
       "  'Easi Tax',\n",
       "  'BISP Solutions',\n",
       "  'Independent Consultant',\n",
       "  'Novelworx Digital Solutions',\n",
       "  'AXESTRACK SOFTWARE SOLUTIONS PRIVATE...',\n",
       "  'FirstTech Consaltants Pvt.Ltd',\n",
       "  'Affine Analytics',\n",
       "  'NEAL ANALYTICS SERVICES PVT LTD',\n",
       "  'Compumatrice Multimedia Pvt Ltd',\n",
       "  'Exela Technologies',\n",
       "  'Autumn Leaf Consulting Services Private...',\n",
       "  'trainin',\n",
       "  'Nanoprecise Sci Corp',\n",
       "  'R.S Consultancy &amp; Services',\n",
       "  'Confidential',\n",
       "  'Dollarbird Information Services Pvt, Ltd',\n",
       "  'JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED',\n",
       "  'Trisect',\n",
       "  'ASCO consulting',\n",
       "  'NY INST',\n",
       "  '3D India Staffing Research &amp; Consulting...',\n",
       "  'O.C. Tanner',\n",
       "  'Demand Matrix',\n",
       "  'MADHUSUDHAN SRIDHAR',\n",
       "  'Suntech Global',\n",
       "  'Strategic Consulting Lab',\n",
       "  'Impel Labs Pvt. Ltd.',\n",
       "  'MRP Advisers',\n",
       "  'Saras Solutions India Pvt Ltd',\n",
       "  'WildJasmine',\n",
       "  'LNT Private Limited',\n",
       "  'Granular.ai',\n",
       "  'Certybox Pvt.Ltd.',\n",
       "  'Western Service Providers'],\n",
       " 'Skills_Required': ['Classic ASP Developer, Internet Marketing Professional, Data Science SME, Content Writers, SEO Professional, Revenue Professional',\n",
       "  '.Net, Java, Data Science, Linux Administration, Sql Server Development, Winforms, Wcf Services, Wpf, Telecom Engineering, Technical Management, Software',\n",
       "  'Web Designing, html5, Angular.js, seo, hadoop, Cloud Computing, python, Iphone Development, java, Machine Learning, aws, analytics, linux, puppet',\n",
       "  'Mean Stack, javascript, angularjs, mongodb, Web Services, rest, express, Node.js, Big Data, iot, Data Science, Cloud Computing, saas, Aws',\n",
       "  'Data Science, Artificial Intelligence, Machine Learning, Business Analytics',\n",
       "  'Hadoop, Spark, Digital Strategy, Data Architecture, Command Center, Cdp, Dmp, Kafka, Data Science, Data Analysis, Big Data Analytics, Real Time Analysis, SQL',\n",
       "  'Analytics, Business Intelligence, Business Analytics, Predictive Modeling, Predictive Analytics, Data Science, Data Analysis, Data Analytics, Big Data, Big',\n",
       "  'Data Science',\n",
       "  'Machine Learning, algorithms, Go Getter, Computer Science, spark, Big Data, hdfs, sql, cassandra, hadoop, python, scala, java, Data Science, Front End',\n",
       "  'Technical Training, Software Development, Presentation Skills, B.tech, M.tech, B.e., mca, msc, Computer Science, freshers, jobs in indore, Data Science, itil',\n",
       "  'Software Development, It Sales, Account Management, Data Analysis, Customer Service, Sr, Software Engineering, Mvc, Ajax, Asp.net, Html, C#, Javascript',\n",
       "  'Qa, Ui/ux, Java Developer, Java Architect, C++/qt, Php, Lamp, Api, J2ee, Java, Soa, Esb, Middleware, Bigdata Achitect, Hadoop Architect, Deep',\n",
       "  'Business Intelligence, Data Warehousing, Data Science, Business Analytics, Customer Support, Business Reporting, Bi',\n",
       "  'Office Administration, Hr Administration, telecalling, client relationship management, Client Acquisition, Sales, Reception, HR, Recruitment, Onboarding, Human',\n",
       "  'Qlikview, Qlik Sense, Microsoft Azure, Power Bi, Data Science, Machine Learning',\n",
       "  'Social Media, digital media maketing, seo, smm, smo, sem, Content Wirting, social media marketing, social media manager, digital media marketing manager',\n",
       "  'Telecalling, Client Interaction, Marketing, Research, Web Development, Social Media Marketing, Data Entry Operation, Excel, Ms Office, Invoicing',\n",
       "  'Big Data, Hadoop, Data Analytics, Data Science',\n",
       "  'Data Science, Artificial Intelligence, analytics, Business Intelligence, python, tableau, Power Bi, qlikview, sql, Data Warehousing, Data Visualization',\n",
       "  'Data Science',\n",
       "  'Corporate Sales, Software Development, Software Sales, Marketing, Creative Designing, Corporate Planning, Senior Management, Crm, Client Relationship',\n",
       "  'Data Analytics, Data Science, Machine Learning, Deep Learning, Nlp, Data Mining, Python, R, Database Administration, Text Mining',\n",
       "  'Data Science, Machine Learning, Python, R, Deep Learning, Big Data, Hadoop',\n",
       "  'Data Science, Artificial Intelligence, Machine Learning, Data Analytics',\n",
       "  'Big Data, Data Science, Artificial Intelligence, Hadoop, Ui Development, Php, Freelancing, .Net, Software Testing, Sap, Leadership Hiring',\n",
       "  'Java, Net, Angularjs, Hr, Infrastructure, Management, Project Management, Business Analysis, Data Science, Information Technology, Technology',\n",
       "  'Software Architecture, Vp Engineering, Product Management, analytics, Data Science, Node.js, Principal Engineer, Big Data, python, angularjs, React.js',\n",
       "  'Data Science, Hadoop, Rpas, Devops, Python, Aws, Teaching, Big Data',\n",
       "  'Signal Processing, Machine Learning, Neural Networks, Data Science, Predictive Analytics, Time Series Analysis, Data Visualization, Technical Leadership, Data',\n",
       "  'Web Technologies, Project Management, Software Architecture, Data Science, Object Oriented Programming, Computer Science, Electrical Engineering, Architecture',\n",
       "  'Server Administartion, Verilog, Vhdl, Digital Marketing, Market Research, Property Research, Legal, It And Non It Recruitment, Logistics, Supply Chain, Bfsi',\n",
       "  'Data Analytics, Managed Services, Team Leading, python, Machine Learning, Google Analytics, Dmp, Aws, Campaign Analytics, Digital Campaigns, Audience',\n",
       "  'Data Science, Machine Learning, Big Data Analytics, Spark, Python, R, Networking, Network Engineering, Placement, Training, Sql, Marketing, Mainframes, All',\n",
       "  'Java, Python, Angularjs, Software Testing, Machine Learning, Data Science, Javascript, Django, React.js, Node.js, Augmented Reality, Virtual Reality, Advanced',\n",
       "  'Machine Learning, Artificial Intelligence, Data Science, Software Engineering, Software Development, Graduate Engineer Trainee, Fresher, Data Analytics, Java',\n",
       "  'C, C++, Artificial Intelligence, Python, Php, Web Development, Matlab, Data Science, Augmented Reality, C C++',\n",
       "  'Relationship Management, Retail Sales, Private Banking, Mutual Funds, NISM, Equity, Finance, Financial Products, Financial Services, Verbal, Written',\n",
       "  'Data Science, Software Engineering',\n",
       "  'Data Science, Big Data Analytics, Digital Marketing, Content Writing, Ui Development, Database Development, Qa Automation, Python, Project Management',\n",
       "  'Data Science, Recruitment, Salary',\n",
       "  'B.Tech, Tableau, Statistics, R, Analytics, Time Series, Data Science, Business Solutions, SQL, Technical Skills, SSAS, SQL Server, Analysis Services, Qlikview',\n",
       "  'Software Development, Business Intelligence, Big Data Analytics, Database Administration, Data Science, Microsoft Azure, Spark, Cassandra, Object Oriented',\n",
       "  'Data Science, Node.js, Angularjs',\n",
       "  'Data Science, Media Marketing, Resource Planning, Managed Services, Display Advertising, Machine Learning, Python, Etl, Sql',\n",
       "  'Data Analysis, Learning, Data Science, Computer Science, Communication Skills',\n",
       "  'Java, Hadoop, R, Machine Learning, Spark, Flume, Hdfs, Data Mining, Sas, Big, Data Science, Cloudera, Impala, Bigdata',\n",
       "  'Software Development, Core Java, Unit Testing, Customer Experience, Problem Solving, Communication Skills, Mysql, Data Science, Sales Management, Analytics',\n",
       "  'Machine Learning, Data Science, Product Management, New Product, Data Analysis, Computer Vision, Deep Learning, Python, Remote Sensing',\n",
       "  'consulting, Education Counseling, Educational Sales, Institutional Sales, pmp, Data Science, Business Development, Revenue Generation, Sales Achievement, new',\n",
       "  'Software Professionals, Engineering, Technical Management, Financial Management, Human Resource Management, Banking, Google Adwords, Business Analysis, It'],\n",
       " 'Location': ['Delhi',\n",
       "  'Hyderabad / Secunderabad',\n",
       "  'Chandigarh',\n",
       "  'Ahmedabad',\n",
       "  'Pune',\n",
       "  'UK - (london)',\n",
       "  'Vadodara / Baroda',\n",
       "  'Chennai',\n",
       "  'Trivandrum',\n",
       "  'Indore',\n",
       "  'Bengaluru / Bangalore',\n",
       "  'Hyderabad / Secunderabad',\n",
       "  'Bengaluru / Bangalore',\n",
       "  'Mumbai',\n",
       "  'Nagpur',\n",
       "  'Hyderabad / Secunderabad',\n",
       "  'Navi Mumbai',\n",
       "  'Bhopal',\n",
       "  'Bengaluru / Bangalore',\n",
       "  'Cochin',\n",
       "  'Delhi',\n",
       "  'Hyderabad / Secunderabad',\n",
       "  'Pune',\n",
       "  'Pune',\n",
       "  'Pune',\n",
       "  'Pune',\n",
       "  'Bengaluru / Bangalore',\n",
       "  'Bengaluru / Bangalore',\n",
       "  '-',\n",
       "  'Delhi',\n",
       "  'Bengaluru / Bangalore',\n",
       "  'Mysoru / Mysore',\n",
       "  'Hyderabad / Secunderabad',\n",
       "  'Noida',\n",
       "  'New Delhi',\n",
       "  'Chennai',\n",
       "  'Aligarh',\n",
       "  'Salt Lake City',\n",
       "  'Pune',\n",
       "  'Bengaluru / Bangalore',\n",
       "  'Mumbai',\n",
       "  'Indore',\n",
       "  'Bengaluru / Bangalore',\n",
       "  'MYSORE',\n",
       "  'Hyderabad / Secunderabad',\n",
       "  'Bengaluru / Bangalore',\n",
       "  'Mumbai',\n",
       "  '-',\n",
       "  'Noida',\n",
       "  'Mumbai']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the 'Name', 'Designation', 'Company', 'Skills_Required', 'Location' details\n",
    "for i in range(len(rows)):\n",
    "    for j in range(2):\n",
    "        if (j+1)%2!=0:\n",
    "            path = str_+str(i+1)+left_\n",
    "        else:\n",
    "            path = str_+str(i+1)+right_\n",
    "\n",
    "        try:\n",
    "            d['Name'].append(driver.find_element_by_xpath(path+p_+\"/a[1]\").text)\n",
    "        except NoSuchElementException:\n",
    "            d['Name'].append(\"-\")\n",
    "\n",
    "        try:\n",
    "            d['Designation'].append(driver.find_element_by_xpath(path+p_+\"/span[1]\").text)\n",
    "        except NoSuchElementException:\n",
    "            d['Designation'].append(\"-\")\n",
    "\n",
    "        try:\n",
    "            d['Company'].append(driver.find_element_by_xpath(path+p_+\"/a[2]\").text)\n",
    "        except NoSuchElementException:\n",
    "            d['Company'].append(\"-\")\n",
    "\n",
    "        try:\n",
    "            d['Location'].append(driver.find_element_by_xpath(path+p_+\"/span[2]\").text)\n",
    "        except NoSuchElementException:\n",
    "            d['Location'].append(\"-\")\n",
    "\n",
    "        try:\n",
    "            d['Skills_Required'].append(driver.find_element_by_xpath(path+skil_).text)\n",
    "        except NoSuchElementException:\n",
    "            d['Skills_Required'].append(\"-\")\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills_Required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>Recruitment Professional</td>\n",
       "      <td>XenonStack</td>\n",
       "      <td>Web Designing, html5, Angular.js, seo, hadoop,...</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "      <td>Nagpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Head</td>\n",
       "      <td>Trisect</td>\n",
       "      <td>Java, Python, Angularjs, Software Testing, Mac...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Shailja Mishra</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Certybox Pvt.Ltd.</td>\n",
       "      <td>consulting, Education Counseling, Educational ...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sunny Sharma</td>\n",
       "      <td>Managing Director - HR</td>\n",
       "      <td>Western Service Providers</td>\n",
       "      <td>Software Professionals, Engineering, Technical...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                    Talent Acquisition Executive   \n",
       "3                                    Anik Agrawal   \n",
       "4                        MARSIAN Technologies LLP   \n",
       "5                                    subhas patel   \n",
       "6    Abhishek - Only Analytics Hiring - India and   \n",
       "7   Institute for Financial Management and Resear   \n",
       "8                                     Balu Ramesh   \n",
       "9                                   Asif Lucknowi   \n",
       "10                                InstaFinancials   \n",
       "11                                Kalpana Dumpala   \n",
       "12                                        Mubarak   \n",
       "13                                 Kushal Rastogi   \n",
       "14                                    Ruchi Dhote   \n",
       "15                             Mahesh Babu Channa   \n",
       "16                                  Manisha Yadav   \n",
       "17                                   Kapil Devang   \n",
       "18                                    Priya Khare   \n",
       "19                                    Riya Rajesh   \n",
       "20                           Rashmi Bhattacharjee   \n",
       "21                                  Faizan Kareem   \n",
       "22                                 Rithika dadwal   \n",
       "23                                  Azahar Shaikh   \n",
       "24                             Sandhya Khandagale   \n",
       "25                                      Shaun Rao   \n",
       "26                                          Manas   \n",
       "27                                          kumar   \n",
       "28                                   Sunil Vedula   \n",
       "29                                    Rajat Kumar   \n",
       "30                                Dhruv Dev Dubey   \n",
       "31                                      Jayanth N   \n",
       "32                                       SREEDHAR   \n",
       "33                                  Prateek Kumar   \n",
       "34                                    Amit Sharma   \n",
       "35                                          Kanan   \n",
       "36                           Shashikant Chaudhary   \n",
       "37                                           Brad   \n",
       "38                                   Rutuja Pawar   \n",
       "39                            Madhusudhan Sridhar   \n",
       "40                                    Ankit Sinha   \n",
       "41                                 Gaurav Chouhan   \n",
       "42                                   Rashi Kacker   \n",
       "43                                        Ashwini   \n",
       "44                                   Balaji Kolli   \n",
       "45                                 Rajani Nagaraj   \n",
       "46                                    ROHIT Kumar   \n",
       "47                                 Amir Chowdhury   \n",
       "48                                 Shailja Mishra   \n",
       "49                                   Sunny Sharma   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2              Recruitment Professional   \n",
       "3                     Company Recruiter   \n",
       "4                            Company HR   \n",
       "5                           Founder CEO   \n",
       "6           Recruitment Lead Consultant   \n",
       "7                     Programme Manager   \n",
       "8                      HR Administrator   \n",
       "9                              Director   \n",
       "10                       Human Resource   \n",
       "11                     Executive Hiring   \n",
       "12                           Company HR   \n",
       "13                           Company HR   \n",
       "14  Senior Executive Talent Acquisition   \n",
       "15                         HR Team Lead   \n",
       "16                         HR Executive   \n",
       "17                           HR Manager   \n",
       "18                       Senior Manager   \n",
       "19           Manager Talent Acquisition   \n",
       "20                              HR Head   \n",
       "21                           HR MANAGER   \n",
       "22                         HR Recruiter   \n",
       "23                    Company Recruiter   \n",
       "24                         HR Recruiter   \n",
       "25              Manager Human Resources   \n",
       "26              Lead Talent acquisition   \n",
       "27                           Proprietor   \n",
       "28                                  CEO   \n",
       "29                          Founder CEO   \n",
       "30             Company Recruitment Head   \n",
       "31                      Project Manager   \n",
       "32               Recruitment Consultant   \n",
       "33                                 Head   \n",
       "34                           Consultant   \n",
       "35         senior technology instructor   \n",
       "36             HR Recruiter/HR Excutive   \n",
       "37        Manager, Technical Recruiting   \n",
       "38                  Technical Recruiter   \n",
       "39                      Erp Implementer   \n",
       "40                       Head Analytics   \n",
       "41              Chief Technical Officer   \n",
       "42                   Sr Product Manager   \n",
       "43             Director Global Delivery   \n",
       "44                           Co Founder   \n",
       "45                           HR Manager   \n",
       "46                            Architect   \n",
       "47                     Managing Partner   \n",
       "48                           HR Manager   \n",
       "49               Managing Director - HR   \n",
       "\n",
       "                                           Company  \\\n",
       "0                             Data Science Network   \n",
       "1                    Shore Infotech India Pvt. Ltd   \n",
       "2                                       XenonStack   \n",
       "3            Enerlytics Software Solutions Pvt Ltd   \n",
       "4                         MARSIAN Technologies LLP   \n",
       "5                                  LibraryXProject   \n",
       "6       Apidel Technologies Division of Transpower   \n",
       "7                                             IFMR   \n",
       "8                      Techvantage Systems Pvt Ltd   \n",
       "9                       Weupskill- Live Wire India   \n",
       "10                CBL Data Science Private Limited   \n",
       "11                              Innominds Software   \n",
       "12                                        MoneyTap   \n",
       "13              QuantMagnum Technologies Pvt. Ltd.   \n",
       "14                           Bristlecone India Ltd   \n",
       "15                               SocialPrachar.com   \n",
       "16                                        Easi Tax   \n",
       "17                                  BISP Solutions   \n",
       "18                          Independent Consultant   \n",
       "19                     Novelworx Digital Solutions   \n",
       "20         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...   \n",
       "21                   FirstTech Consaltants Pvt.Ltd   \n",
       "22                                Affine Analytics   \n",
       "23                 NEAL ANALYTICS SERVICES PVT LTD   \n",
       "24                 Compumatrice Multimedia Pvt Ltd   \n",
       "25                              Exela Technologies   \n",
       "26      Autumn Leaf Consulting Services Private...   \n",
       "27                                         trainin   \n",
       "28                            Nanoprecise Sci Corp   \n",
       "29                  R.S Consultancy &amp; Services   \n",
       "30                                    Confidential   \n",
       "31        Dollarbird Information Services Pvt, Ltd   \n",
       "32     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "33                                         Trisect   \n",
       "34                                 ASCO consulting   \n",
       "35                                         NY INST   \n",
       "36  3D India Staffing Research &amp; Consulting...   \n",
       "37                                     O.C. Tanner   \n",
       "38                                   Demand Matrix   \n",
       "39                             MADHUSUDHAN SRIDHAR   \n",
       "40                                  Suntech Global   \n",
       "41                        Strategic Consulting Lab   \n",
       "42                            Impel Labs Pvt. Ltd.   \n",
       "43                                    MRP Advisers   \n",
       "44                   Saras Solutions India Pvt Ltd   \n",
       "45                                     WildJasmine   \n",
       "46                             LNT Private Limited   \n",
       "47                                     Granular.ai   \n",
       "48                               Certybox Pvt.Ltd.   \n",
       "49                       Western Service Providers   \n",
       "\n",
       "                                      Skills_Required  \\\n",
       "0   Classic ASP Developer, Internet Marketing Prof...   \n",
       "1   .Net, Java, Data Science, Linux Administration...   \n",
       "2   Web Designing, html5, Angular.js, seo, hadoop,...   \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...   \n",
       "4   Data Science, Artificial Intelligence, Machine...   \n",
       "5   Hadoop, Spark, Digital Strategy, Data Architec...   \n",
       "6   Analytics, Business Intelligence, Business Ana...   \n",
       "7                                        Data Science   \n",
       "8   Machine Learning, algorithms, Go Getter, Compu...   \n",
       "9   Technical Training, Software Development, Pres...   \n",
       "10  Software Development, It Sales, Account Manage...   \n",
       "11  Qa, Ui/ux, Java Developer, Java Architect, C++...   \n",
       "12  Business Intelligence, Data Warehousing, Data ...   \n",
       "13  Office Administration, Hr Administration, tele...   \n",
       "14  Qlikview, Qlik Sense, Microsoft Azure, Power B...   \n",
       "15  Social Media, digital media maketing, seo, smm...   \n",
       "16  Telecalling, Client Interaction, Marketing, Re...   \n",
       "17     Big Data, Hadoop, Data Analytics, Data Science   \n",
       "18  Data Science, Artificial Intelligence, analyti...   \n",
       "19                                       Data Science   \n",
       "20  Corporate Sales, Software Development, Softwar...   \n",
       "21  Data Analytics, Data Science, Machine Learning...   \n",
       "22  Data Science, Machine Learning, Python, R, Dee...   \n",
       "23  Data Science, Artificial Intelligence, Machine...   \n",
       "24  Big Data, Data Science, Artificial Intelligenc...   \n",
       "25  Java, Net, Angularjs, Hr, Infrastructure, Mana...   \n",
       "26  Software Architecture, Vp Engineering, Product...   \n",
       "27  Data Science, Hadoop, Rpas, Devops, Python, Aw...   \n",
       "28  Signal Processing, Machine Learning, Neural Ne...   \n",
       "29  Web Technologies, Project Management, Software...   \n",
       "30  Server Administartion, Verilog, Vhdl, Digital ...   \n",
       "31  Data Analytics, Managed Services, Team Leading...   \n",
       "32  Data Science, Machine Learning, Big Data Analy...   \n",
       "33  Java, Python, Angularjs, Software Testing, Mac...   \n",
       "34  Machine Learning, Artificial Intelligence, Dat...   \n",
       "35  C, C++, Artificial Intelligence, Python, Php, ...   \n",
       "36  Relationship Management, Retail Sales, Private...   \n",
       "37                 Data Science, Software Engineering   \n",
       "38  Data Science, Big Data Analytics, Digital Mark...   \n",
       "39                  Data Science, Recruitment, Salary   \n",
       "40  B.Tech, Tableau, Statistics, R, Analytics, Tim...   \n",
       "41  Software Development, Business Intelligence, B...   \n",
       "42                   Data Science, Node.js, Angularjs   \n",
       "43  Data Science, Media Marketing, Resource Planni...   \n",
       "44  Data Analysis, Learning, Data Science, Compute...   \n",
       "45  Java, Hadoop, R, Machine Learning, Spark, Flum...   \n",
       "46  Software Development, Core Java, Unit Testing,...   \n",
       "47  Machine Learning, Data Science, Product Manage...   \n",
       "48  consulting, Education Counseling, Educational ...   \n",
       "49  Software Professionals, Engineering, Technical...   \n",
       "\n",
       "                    Location  \n",
       "0                      Delhi  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                 Chandigarh  \n",
       "3                  Ahmedabad  \n",
       "4                       Pune  \n",
       "5              UK - (london)  \n",
       "6          Vadodara / Baroda  \n",
       "7                    Chennai  \n",
       "8                 Trivandrum  \n",
       "9                     Indore  \n",
       "10     Bengaluru / Bangalore  \n",
       "11  Hyderabad / Secunderabad  \n",
       "12     Bengaluru / Bangalore  \n",
       "13                    Mumbai  \n",
       "14                    Nagpur  \n",
       "15  Hyderabad / Secunderabad  \n",
       "16               Navi Mumbai  \n",
       "17                    Bhopal  \n",
       "18     Bengaluru / Bangalore  \n",
       "19                    Cochin  \n",
       "20                     Delhi  \n",
       "21  Hyderabad / Secunderabad  \n",
       "22                      Pune  \n",
       "23                      Pune  \n",
       "24                      Pune  \n",
       "25                      Pune  \n",
       "26     Bengaluru / Bangalore  \n",
       "27     Bengaluru / Bangalore  \n",
       "28                         -  \n",
       "29                     Delhi  \n",
       "30     Bengaluru / Bangalore  \n",
       "31           Mysoru / Mysore  \n",
       "32  Hyderabad / Secunderabad  \n",
       "33                     Noida  \n",
       "34                 New Delhi  \n",
       "35                   Chennai  \n",
       "36                   Aligarh  \n",
       "37            Salt Lake City  \n",
       "38                      Pune  \n",
       "39     Bengaluru / Bangalore  \n",
       "40                    Mumbai  \n",
       "41                    Indore  \n",
       "42     Bengaluru / Bangalore  \n",
       "43                    MYSORE  \n",
       "44  Hyderabad / Secunderabad  \n",
       "45     Bengaluru / Bangalore  \n",
       "46                    Mumbai  \n",
       "47                         -  \n",
       "48                     Noida  \n",
       "49                    Mumbai  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Scrape the details of Highest selling novels.\n",
    "### Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "### You have to find the following details:\n",
    "### A) Book name\n",
    "### B) Author name\n",
    "### C) Volumes sold\n",
    "### D) Publisher\n",
    "### E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the dictionary\n",
    "d ={\n",
    "    'Book_Name':[],\n",
    "    'Author_Name':[],\n",
    "    'Volumes_Sold':[],\n",
    "    'Publisher':[],\n",
    "    'Genre':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching total number of rows\n",
    "rows = driver.find_elements_by_xpath(\"//table/tbody/tr\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Book_Name': ['Da Vinci Code,The',\n",
       "  'Harry Potter and the Deathly Hallows',\n",
       "  \"Harry Potter and the Philosopher's Stone\",\n",
       "  'Harry Potter and the Order of the Phoenix',\n",
       "  'Fifty Shades of Grey',\n",
       "  'Harry Potter and the Goblet of Fire',\n",
       "  'Harry Potter and the Chamber of Secrets',\n",
       "  'Harry Potter and the Prisoner of Azkaban',\n",
       "  'Angels and Demons',\n",
       "  \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       "  'Fifty Shades Darker',\n",
       "  'Twilight',\n",
       "  'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       "  'Fifty Shades Freed',\n",
       "  'Lost Symbol,The',\n",
       "  'New Moon',\n",
       "  'Deception Point',\n",
       "  'Eclipse',\n",
       "  'Lovely Bones,The',\n",
       "  'Curious Incident of the Dog in the Night-time,The',\n",
       "  'Digital Fortress',\n",
       "  'Short History of Nearly Everything,A',\n",
       "  'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       "  'Breaking Dawn',\n",
       "  'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       "  'Gruffalo,The',\n",
       "  \"Jamie's 30-Minute Meals\",\n",
       "  'Kite Runner,The',\n",
       "  'One Day',\n",
       "  'Thousand Splendid Suns,A',\n",
       "  \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       "  \"Time Traveler's Wife,The\",\n",
       "  'Atonement',\n",
       "  \"Bridget Jones's Diary:A Novel\",\n",
       "  'World According to Clarkson,The',\n",
       "  \"Captain Corelli's Mandolin\",\n",
       "  'Sound of Laughter,The',\n",
       "  'Life of Pi',\n",
       "  'Billy Connolly',\n",
       "  'Child Called It,A',\n",
       "  \"Gruffalo's Child,The\",\n",
       "  \"Angela's Ashes:A Memoir of a Childhood\",\n",
       "  'Birdsong',\n",
       "  'Northern Lights:His Dark Materials S.',\n",
       "  'Labyrinth',\n",
       "  'Harry Potter and the Half-blood Prince',\n",
       "  'Help,The',\n",
       "  'Man and Boy',\n",
       "  'Memoirs of a Geisha',\n",
       "  \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       "  'Island,The',\n",
       "  'PS, I Love You',\n",
       "  'You are What You Eat:The Plan That Will Change Your Life',\n",
       "  'Shadow of the Wind,The',\n",
       "  'Tales of Beedle the Bard,The',\n",
       "  'Broker,The',\n",
       "  \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       "  'Subtle Knife,The:His Dark Materials S.',\n",
       "  'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       "  \"Delia's How to Cook:(Bk.1)\",\n",
       "  'Chocolat',\n",
       "  'Boy in the Striped Pyjamas,The',\n",
       "  \"My Sister's Keeper\",\n",
       "  'Amber Spyglass,The:His Dark Materials S.',\n",
       "  'To Kill a Mockingbird',\n",
       "  'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       "  'Dear Fatty',\n",
       "  'Short History of Tractors in Ukrainian,A',\n",
       "  'Hannibal',\n",
       "  'Lord of the Rings,The',\n",
       "  'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       "  'Interpretation of Murder,The',\n",
       "  'Sharon Osbourne Extreme:My Autobiography',\n",
       "  'Alchemist,The:A Fable About Following Your Dream',\n",
       "  \"At My Mother's Knee ...:and Other Low Joints\",\n",
       "  'Notes from a Small Island',\n",
       "  'Return of the Naked Chef,The',\n",
       "  'Bridget Jones: The Edge of Reason',\n",
       "  \"Jamie's Italy\",\n",
       "  'I Can Make You Thin',\n",
       "  'Down Under',\n",
       "  'Summons,The',\n",
       "  'Small Island',\n",
       "  'Nigella Express',\n",
       "  'Brick Lane',\n",
       "  \"Memory Keeper's Daughter,The\",\n",
       "  'Room on the Broom',\n",
       "  'About a Boy',\n",
       "  'My Booky Wook',\n",
       "  'God Delusion,The',\n",
       "  '\"Beano\" Annual,The',\n",
       "  'White Teeth',\n",
       "  'House at Riverton,The',\n",
       "  'Book Thief,The',\n",
       "  'Nights of Rain and Stars',\n",
       "  'Ghost,The',\n",
       "  'Happy Days with the Naked Chef',\n",
       "  'Hunger Games,The:Hunger Games Trilogy',\n",
       "  \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       "  \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"],\n",
       " 'Author_Name': ['Brown, Dan',\n",
       "  'Rowling, J.K.',\n",
       "  'Rowling, J.K.',\n",
       "  'Rowling, J.K.',\n",
       "  'James, E. L.',\n",
       "  'Rowling, J.K.',\n",
       "  'Rowling, J.K.',\n",
       "  'Rowling, J.K.',\n",
       "  'Brown, Dan',\n",
       "  'Rowling, J.K.',\n",
       "  'James, E. L.',\n",
       "  'Meyer, Stephenie',\n",
       "  'Larsson, Stieg',\n",
       "  'James, E. L.',\n",
       "  'Brown, Dan',\n",
       "  'Meyer, Stephenie',\n",
       "  'Brown, Dan',\n",
       "  'Meyer, Stephenie',\n",
       "  'Sebold, Alice',\n",
       "  'Haddon, Mark',\n",
       "  'Brown, Dan',\n",
       "  'Bryson, Bill',\n",
       "  'Larsson, Stieg',\n",
       "  'Meyer, Stephenie',\n",
       "  'Carle, Eric',\n",
       "  'Donaldson, Julia',\n",
       "  'Oliver, Jamie',\n",
       "  'Hosseini, Khaled',\n",
       "  'Nicholls, David',\n",
       "  'Hosseini, Khaled',\n",
       "  'Larsson, Stieg',\n",
       "  'Niffenegger, Audrey',\n",
       "  'McEwan, Ian',\n",
       "  'Fielding, Helen',\n",
       "  'Clarkson, Jeremy',\n",
       "  'Bernieres, Louis de',\n",
       "  'Kay, Peter',\n",
       "  'Martel, Yann',\n",
       "  'Stephenson, Pamela',\n",
       "  'Pelzer, Dave',\n",
       "  'Donaldson, Julia',\n",
       "  'McCourt, Frank',\n",
       "  'Faulks, Sebastian',\n",
       "  'Pullman, Philip',\n",
       "  'Mosse, Kate',\n",
       "  'Rowling, J.K.',\n",
       "  'Stockett, Kathryn',\n",
       "  'Parsons, Tony',\n",
       "  'Golden, Arthur',\n",
       "  'McCall Smith, Alexander',\n",
       "  'Hislop, Victoria',\n",
       "  'Ahern, Cecelia',\n",
       "  'McKeith, Gillian',\n",
       "  'Zafon, Carlos Ruiz',\n",
       "  'Rowling, J.K.',\n",
       "  'Grisham, John',\n",
       "  'Atkins, Robert C.',\n",
       "  'Pullman, Philip',\n",
       "  'Truss, Lynne',\n",
       "  'Smith, Delia',\n",
       "  'Harris, Joanne',\n",
       "  'Boyne, John',\n",
       "  'Picoult, Jodi',\n",
       "  'Pullman, Philip',\n",
       "  'Lee, Harper',\n",
       "  'Gray, John',\n",
       "  'French, Dawn',\n",
       "  'Lewycka, Marina',\n",
       "  'Harris, Thomas',\n",
       "  'Tolkien, J. R. R.',\n",
       "  'Moore, Michael',\n",
       "  'Rubenfeld, Jed',\n",
       "  'Osbourne, Sharon',\n",
       "  'Coelho, Paulo',\n",
       "  \"O'Grady, Paul\",\n",
       "  'Bryson, Bill',\n",
       "  'Oliver, Jamie',\n",
       "  'Fielding, Helen',\n",
       "  'Oliver, Jamie',\n",
       "  'McKenna, Paul',\n",
       "  'Bryson, Bill',\n",
       "  'Grisham, John',\n",
       "  'Levy, Andrea',\n",
       "  'Lawson, Nigella',\n",
       "  'Ali, Monica',\n",
       "  'Edwards, Kim',\n",
       "  'Donaldson, Julia',\n",
       "  'Hornby, Nick',\n",
       "  'Brand, Russell',\n",
       "  'Dawkins, Richard',\n",
       "  '0',\n",
       "  'Smith, Zadie',\n",
       "  'Morton, Kate',\n",
       "  'Zusak, Markus',\n",
       "  'Binchy, Maeve',\n",
       "  'Harris, Robert',\n",
       "  'Oliver, Jamie',\n",
       "  'Collins, Suzanne',\n",
       "  'Pelzer, Dave',\n",
       "  'Oliver, Jamie'],\n",
       " 'Volumes_Sold': ['5,094,805',\n",
       "  '4,475,152',\n",
       "  '4,200,654',\n",
       "  '4,179,479',\n",
       "  '3,758,936',\n",
       "  '3,583,215',\n",
       "  '3,484,047',\n",
       "  '3,377,906',\n",
       "  '3,193,946',\n",
       "  '2,950,264',\n",
       "  '2,479,784',\n",
       "  '2,315,405',\n",
       "  '2,233,570',\n",
       "  '2,193,928',\n",
       "  '2,183,031',\n",
       "  '2,152,737',\n",
       "  '2,062,145',\n",
       "  '2,052,876',\n",
       "  '2,005,598',\n",
       "  '1,979,552',\n",
       "  '1,928,900',\n",
       "  '1,852,919',\n",
       "  '1,814,784',\n",
       "  '1,787,118',\n",
       "  '1,783,535',\n",
       "  '1,781,269',\n",
       "  '1,743,266',\n",
       "  '1,629,119',\n",
       "  '1,616,068',\n",
       "  '1,583,992',\n",
       "  '1,555,135',\n",
       "  '1,546,886',\n",
       "  '1,539,428',\n",
       "  '1,508,205',\n",
       "  '1,489,403',\n",
       "  '1,352,318',\n",
       "  '1,310,207',\n",
       "  '1,310,176',\n",
       "  '1,231,957',\n",
       "  '1,217,712',\n",
       "  '1,208,711',\n",
       "  '1,204,058',\n",
       "  '1,184,967',\n",
       "  '1,181,503',\n",
       "  '1,181,093',\n",
       "  '1,153,181',\n",
       "  '1,132,336',\n",
       "  '1,130,802',\n",
       "  '1,126,337',\n",
       "  '1,115,549',\n",
       "  '1,108,328',\n",
       "  '1,107,379',\n",
       "  '1,104,403',\n",
       "  '1,092,349',\n",
       "  '1,090,847',\n",
       "  '1,087,262',\n",
       "  '1,054,196',\n",
       "  '1,037,160',\n",
       "  '1,023,688',\n",
       "  '1,015,956',\n",
       "  '1,009,873',\n",
       "  '1,004,414',\n",
       "  '1,003,780',\n",
       "  '1,002,314',\n",
       "  '998,213',\n",
       "  '992,846',\n",
       "  '986,753',\n",
       "  '986,115',\n",
       "  '970,509',\n",
       "  '967,466',\n",
       "  '963,353',\n",
       "  '962,515',\n",
       "  '959,496',\n",
       "  '956,114',\n",
       "  '945,640',\n",
       "  '931,312',\n",
       "  '925,425',\n",
       "  '924,695',\n",
       "  '906,968',\n",
       "  '905,086',\n",
       "  '890,847',\n",
       "  '869,671',\n",
       "  '869,659',\n",
       "  '862,602',\n",
       "  '856,540',\n",
       "  '845,858',\n",
       "  '842,535',\n",
       "  '828,215',\n",
       "  '820,563',\n",
       "  '816,907',\n",
       "  '816,585',\n",
       "  '815,586',\n",
       "  '814,370',\n",
       "  '809,641',\n",
       "  '808,900',\n",
       "  '807,311',\n",
       "  '794,201',\n",
       "  '792,187',\n",
       "  '791,507',\n",
       "  '791,095'],\n",
       " 'Publisher': ['Transworld',\n",
       "  'Bloomsbury',\n",
       "  'Bloomsbury',\n",
       "  'Bloomsbury',\n",
       "  'Random House',\n",
       "  'Bloomsbury',\n",
       "  'Bloomsbury',\n",
       "  'Bloomsbury',\n",
       "  'Transworld',\n",
       "  'Bloomsbury',\n",
       "  'Random House',\n",
       "  'Little, Brown Book',\n",
       "  'Quercus',\n",
       "  'Random House',\n",
       "  'Transworld',\n",
       "  'Little, Brown Book',\n",
       "  'Transworld',\n",
       "  'Little, Brown Book',\n",
       "  'Pan Macmillan',\n",
       "  'Random House',\n",
       "  'Transworld',\n",
       "  'Transworld',\n",
       "  'Quercus',\n",
       "  'Little, Brown Book',\n",
       "  'Penguin',\n",
       "  'Pan Macmillan',\n",
       "  'Penguin',\n",
       "  'Bloomsbury',\n",
       "  'Hodder & Stoughton',\n",
       "  'Bloomsbury',\n",
       "  'Quercus',\n",
       "  'Random House',\n",
       "  'Random House',\n",
       "  'Pan Macmillan',\n",
       "  'Penguin',\n",
       "  'Random House',\n",
       "  'Random House',\n",
       "  'Canongate',\n",
       "  'HarperCollins',\n",
       "  'Orion',\n",
       "  'Pan Macmillan',\n",
       "  'HarperCollins',\n",
       "  'Random House',\n",
       "  'Scholastic Ltd.',\n",
       "  'Orion',\n",
       "  'Bloomsbury',\n",
       "  'Penguin',\n",
       "  'HarperCollins',\n",
       "  'Random House',\n",
       "  'Little, Brown Book',\n",
       "  'Headline',\n",
       "  'HarperCollins',\n",
       "  'Penguin',\n",
       "  'Orion',\n",
       "  'Bloomsbury',\n",
       "  'Random House',\n",
       "  'Random House',\n",
       "  'Scholastic Ltd.',\n",
       "  'Profile Books Group',\n",
       "  'Random House',\n",
       "  'Transworld',\n",
       "  'Random House Childrens Books G',\n",
       "  'Hodder & Stoughton',\n",
       "  'Scholastic Ltd.',\n",
       "  'Random House',\n",
       "  'HarperCollins',\n",
       "  'Random House',\n",
       "  'Penguin',\n",
       "  'Random House',\n",
       "  'HarperCollins',\n",
       "  'Penguin',\n",
       "  'Headline',\n",
       "  'Little, Brown Book',\n",
       "  'HarperCollins',\n",
       "  'Transworld',\n",
       "  'Transworld',\n",
       "  'Penguin',\n",
       "  'Pan Macmillan',\n",
       "  'Penguin',\n",
       "  'Transworld',\n",
       "  'Transworld',\n",
       "  'Random House',\n",
       "  'Headline',\n",
       "  'Random House',\n",
       "  'Transworld',\n",
       "  'Penguin',\n",
       "  'Pan Macmillan',\n",
       "  'Penguin',\n",
       "  'Hodder & Stoughton',\n",
       "  'Transworld',\n",
       "  'D.C. Thomson',\n",
       "  'Penguin',\n",
       "  'Pan Macmillan',\n",
       "  'Transworld',\n",
       "  'Orion',\n",
       "  'Random House',\n",
       "  'Penguin',\n",
       "  'Scholastic Ltd.',\n",
       "  'Orion',\n",
       "  'Penguin'],\n",
       " 'Genre': ['Crime, Thriller & Adventure',\n",
       "  \"Children's Fiction\",\n",
       "  \"Children's Fiction\",\n",
       "  \"Children's Fiction\",\n",
       "  'Romance & Sagas',\n",
       "  \"Children's Fiction\",\n",
       "  \"Children's Fiction\",\n",
       "  \"Children's Fiction\",\n",
       "  'Crime, Thriller & Adventure',\n",
       "  \"Children's Fiction\",\n",
       "  'Romance & Sagas',\n",
       "  'Young Adult Fiction',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'Romance & Sagas',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'Young Adult Fiction',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'Young Adult Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'Popular Science',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'Young Adult Fiction',\n",
       "  'Picture Books',\n",
       "  'Picture Books',\n",
       "  'Food & Drink: General',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Humour: Collections & General',\n",
       "  'General & Literary Fiction',\n",
       "  'Autobiography: General',\n",
       "  'General & Literary Fiction',\n",
       "  'Biography: The Arts',\n",
       "  'Autobiography: General',\n",
       "  'Picture Books',\n",
       "  'Autobiography: General',\n",
       "  'General & Literary Fiction',\n",
       "  'Young Adult Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Science Fiction & Fantasy',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Fitness & Diet',\n",
       "  'General & Literary Fiction',\n",
       "  \"Children's Fiction\",\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'Fitness & Diet',\n",
       "  'Young Adult Fiction',\n",
       "  'Usage & Writing Guides',\n",
       "  'Food & Drink: General',\n",
       "  'General & Literary Fiction',\n",
       "  'Young Adult Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Young Adult Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Popular Culture & Media: General Interest',\n",
       "  'Autobiography: The Arts',\n",
       "  'General & Literary Fiction',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'Science Fiction & Fantasy',\n",
       "  'Current Affairs & Issues',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'Autobiography: The Arts',\n",
       "  'General & Literary Fiction',\n",
       "  'Autobiography: The Arts',\n",
       "  'Travel Writing',\n",
       "  'Food & Drink: General',\n",
       "  'General & Literary Fiction',\n",
       "  'National & Regional Cuisine',\n",
       "  'Fitness & Diet',\n",
       "  'Travel Writing',\n",
       "  'Crime, Thriller & Adventure',\n",
       "  'General & Literary Fiction',\n",
       "  'Food & Drink: General',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Picture Books',\n",
       "  'General & Literary Fiction',\n",
       "  'Autobiography: The Arts',\n",
       "  'Popular Science',\n",
       "  \"Children's Annuals\",\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'General & Literary Fiction',\n",
       "  'Food & Drink: General',\n",
       "  'Young Adult Fiction',\n",
       "  'Biography: General',\n",
       "  'Food & Drink: General']}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the 'Book_Name', 'Author_Name', 'Volumes_Sold', 'Publisher', 'Genre' details\n",
    "str_ = \"//table/tbody/tr[\"\n",
    "keys = list(d.keys())\n",
    "for i in range(len(rows)):\n",
    "    path = str_+str(i+1)+\"]/td\"\n",
    "    l = driver.find_elements_by_xpath(path)\n",
    "    for j in range(1,6):\n",
    "        d[keys[j-1]].append(l[j].text)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Volumes_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_Name       Author_Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "### Url = https://www.imdb.com/list/ls095964455/\n",
    "### You have to find the following details:\n",
    "### A) Name\n",
    "### B) Year span\n",
    "### C) Genre\n",
    "### D) Run time\n",
    "### E) Ratings\n",
    "### F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the dictionary\n",
    "d = {\n",
    "    'Name':[],\n",
    "    'Year_span':[],\n",
    "    'Genre':[],\n",
    "    'Run_Time':[],\n",
    "    'Ratings':[],\n",
    "    'Votes':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': ['Game of Thrones',\n",
       "  'Stranger Things',\n",
       "  'The Walking Dead',\n",
       "  '13 Reasons Why',\n",
       "  'The 100',\n",
       "  'Orange Is the New Black',\n",
       "  'Riverdale',\n",
       "  \"Grey's Anatomy\",\n",
       "  'The Flash',\n",
       "  'Arrow',\n",
       "  'Money Heist',\n",
       "  'The Big Bang Theory',\n",
       "  'Black Mirror',\n",
       "  'Sherlock',\n",
       "  'Vikings',\n",
       "  'Pretty Little Liars',\n",
       "  'The Vampire Diaries',\n",
       "  'American Horror Story',\n",
       "  'Breaking Bad',\n",
       "  'Lucifer',\n",
       "  'Supernatural',\n",
       "  'Prison Break',\n",
       "  'How to Get Away with Murder',\n",
       "  'Teen Wolf',\n",
       "  'The Simpsons',\n",
       "  'Once Upon a Time',\n",
       "  'Narcos',\n",
       "  'Daredevil',\n",
       "  'Friends',\n",
       "  'How I Met Your Mother',\n",
       "  'Suits',\n",
       "  'Mr. Robot',\n",
       "  'The Originals',\n",
       "  'Supergirl',\n",
       "  'Gossip Girl',\n",
       "  'Sense8',\n",
       "  'Gotham',\n",
       "  'Westworld',\n",
       "  'Jessica Jones',\n",
       "  'Modern Family',\n",
       "  'Rick and Morty',\n",
       "  'Shadowhunters',\n",
       "  'The End of the F***ing World',\n",
       "  'House of Cards',\n",
       "  'Dark',\n",
       "  'Elite',\n",
       "  'Sex Education',\n",
       "  'Shameless',\n",
       "  'New Girl',\n",
       "  'Agents of S.H.I.E.L.D.',\n",
       "  'You',\n",
       "  'Dexter',\n",
       "  'Fear the Walking Dead',\n",
       "  'Family Guy',\n",
       "  'The Blacklist',\n",
       "  'Lost',\n",
       "  'Peaky Blinders',\n",
       "  'House',\n",
       "  'Quantico',\n",
       "  'Orphan Black',\n",
       "  'Homeland',\n",
       "  'Blindspot',\n",
       "  \"DC's Legends of Tomorrow\",\n",
       "  \"The Handmaid's Tale\",\n",
       "  'Chilling Adventures of Sabrina',\n",
       "  'The Good Doctor',\n",
       "  'Jane the Virgin',\n",
       "  'Glee',\n",
       "  'South Park',\n",
       "  'Brooklyn Nine-Nine',\n",
       "  'Under the Dome',\n",
       "  'The Umbrella Academy',\n",
       "  'True Detective',\n",
       "  'The OA',\n",
       "  'Desperate Housewives',\n",
       "  'Better Call Saul',\n",
       "  'Bates Motel',\n",
       "  'The Punisher',\n",
       "  'Atypical',\n",
       "  'Dynasty',\n",
       "  'This Is Us',\n",
       "  'The Good Place',\n",
       "  'Iron Fist',\n",
       "  'The Rain',\n",
       "  'Mindhunter',\n",
       "  'Revenge',\n",
       "  'Luke Cage',\n",
       "  'Scandal',\n",
       "  'The Defenders',\n",
       "  'Big Little Lies',\n",
       "  'Insatiable',\n",
       "  'The Mentalist',\n",
       "  'The Crown',\n",
       "  'Chernobyl',\n",
       "  'iZombie',\n",
       "  'Reign',\n",
       "  'A Series of Unfortunate Events',\n",
       "  'Criminal Minds',\n",
       "  'Scream: The TV Series',\n",
       "  'The Haunting of Hill House'],\n",
       " 'Year_span': ['(2011–2019)',\n",
       "  '(2016– )',\n",
       "  '(2010–2022)',\n",
       "  '(2017–2020)',\n",
       "  '(2014–2020)',\n",
       "  '(2013–2019)',\n",
       "  '(2017– )',\n",
       "  '(2005– )',\n",
       "  '(2014– )',\n",
       "  '(2012–2020)',\n",
       "  '(2017– )',\n",
       "  '(2007–2019)',\n",
       "  '(2011– )',\n",
       "  '(2010–2017)',\n",
       "  '(2013–2020)',\n",
       "  '(2010–2017)',\n",
       "  '(2009–2017)',\n",
       "  '(2011– )',\n",
       "  '(2008–2013)',\n",
       "  '(2016– )',\n",
       "  '(2005–2020)',\n",
       "  '(2005–2017)',\n",
       "  '(2014–2020)',\n",
       "  '(2011–2017)',\n",
       "  '(1989– )',\n",
       "  '(2011–2018)',\n",
       "  '(2015–2017)',\n",
       "  '(2015–2018)',\n",
       "  '(1994–2004)',\n",
       "  '(2005–2014)',\n",
       "  '(2011–2019)',\n",
       "  '(2015–2019)',\n",
       "  '(2013–2018)',\n",
       "  '(2015–2021)',\n",
       "  '(2007–2012)',\n",
       "  '(2015–2018)',\n",
       "  '(2014–2019)',\n",
       "  '(2016– )',\n",
       "  '(2015–2019)',\n",
       "  '(2009–2020)',\n",
       "  '(2013– )',\n",
       "  '(2016–2019)',\n",
       "  '(2017–2019)',\n",
       "  '(2013–2018)',\n",
       "  '(2017–2020)',\n",
       "  '(2018– )',\n",
       "  '(2019– )',\n",
       "  '(2011–2021)',\n",
       "  '(2011–2018)',\n",
       "  '(2013–2020)',\n",
       "  '(2018– )',\n",
       "  '(2006–2021)',\n",
       "  '(2015– )',\n",
       "  '(1999– )',\n",
       "  '(2013– )',\n",
       "  '(2004–2010)',\n",
       "  '(2013– )',\n",
       "  '(2004–2012)',\n",
       "  '(2015–2018)',\n",
       "  '(2013–2017)',\n",
       "  '(2011–2020)',\n",
       "  '(2015–2020)',\n",
       "  '(2016– )',\n",
       "  '(2017– )',\n",
       "  '(2018–2020)',\n",
       "  '(2017–2021)',\n",
       "  '(2014–2019)',\n",
       "  '(2009–2015)',\n",
       "  '(1997– )',\n",
       "  '(2013–2022)',\n",
       "  '(2013–2015)',\n",
       "  '(2019– )',\n",
       "  '(2014–2019)',\n",
       "  '(2016–2019)',\n",
       "  '(2004–2012)',\n",
       "  '(2015–2021)',\n",
       "  '(2013–2017)',\n",
       "  '(2017–2019)',\n",
       "  '(2017–2021)',\n",
       "  '(2017– )',\n",
       "  '(2016– )',\n",
       "  '(2016–2020)',\n",
       "  '(2017–2018)',\n",
       "  '(2018–2020)',\n",
       "  '(2017–2019)',\n",
       "  '(2011–2015)',\n",
       "  '(2016–2018)',\n",
       "  '(2012–2018)',\n",
       "  '(2017)',\n",
       "  '(2017–2019)',\n",
       "  '(2018–2019)',\n",
       "  '(2008–2015)',\n",
       "  '(2016– )',\n",
       "  '(2019)',\n",
       "  '(2015–2019)',\n",
       "  '(2013–2017)',\n",
       "  '(2017–2019)',\n",
       "  '(2005–2020)',\n",
       "  '(2015–2019)',\n",
       "  '(2018)'],\n",
       " 'Genre': ['Action, Adventure, Drama',\n",
       "  'Drama, Fantasy, Horror',\n",
       "  'Drama, Horror, Thriller',\n",
       "  'Drama, Mystery, Thriller',\n",
       "  'Drama, Mystery, Sci-Fi',\n",
       "  'Comedy, Crime, Drama',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Drama, Romance',\n",
       "  'Action, Adventure, Drama',\n",
       "  'Action, Adventure, Crime',\n",
       "  'Action, Crime, Mystery',\n",
       "  'Comedy, Romance',\n",
       "  'Drama, Sci-Fi, Thriller',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Action, Adventure, Drama',\n",
       "  'Drama, Mystery, Romance',\n",
       "  'Drama, Fantasy, Horror',\n",
       "  'Drama, Horror, Thriller',\n",
       "  'Crime, Drama, Thriller',\n",
       "  'Crime, Drama, Fantasy',\n",
       "  'Drama, Fantasy, Horror',\n",
       "  'Action, Crime, Drama',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Action, Drama, Fantasy',\n",
       "  'Animation, Comedy',\n",
       "  'Adventure, Fantasy, Romance',\n",
       "  'Biography, Crime, Drama',\n",
       "  'Action, Crime, Drama',\n",
       "  'Comedy, Romance',\n",
       "  'Comedy, Romance',\n",
       "  'Comedy, Drama',\n",
       "  'Crime, Drama, Thriller',\n",
       "  'Drama, Fantasy, Horror',\n",
       "  'Action, Adventure, Drama',\n",
       "  'Drama, Romance',\n",
       "  'Drama, Mystery, Sci-Fi',\n",
       "  'Action, Crime, Drama',\n",
       "  'Drama, Mystery, Sci-Fi',\n",
       "  'Action, Crime, Drama',\n",
       "  'Comedy, Drama, Romance',\n",
       "  'Animation, Adventure, Comedy',\n",
       "  'Action, Drama, Fantasy',\n",
       "  'Adventure, Comedy, Crime',\n",
       "  'Drama',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Crime, Drama, Thriller',\n",
       "  'Comedy, Drama',\n",
       "  'Comedy, Drama',\n",
       "  'Comedy',\n",
       "  'Action, Adventure, Drama',\n",
       "  'Crime, Drama, Romance',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Drama, Horror, Sci-Fi',\n",
       "  'Animation, Comedy',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Adventure, Drama, Fantasy',\n",
       "  'Crime, Drama',\n",
       "  'Drama, Mystery',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Action, Drama, Sci-Fi',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Action, Crime, Drama',\n",
       "  'Action, Adventure, Drama',\n",
       "  'Drama, Sci-Fi, Thriller',\n",
       "  'Drama, Fantasy, Horror',\n",
       "  'Drama',\n",
       "  'Comedy',\n",
       "  'Comedy, Drama, Music',\n",
       "  'Animation, Comedy',\n",
       "  'Comedy, Crime',\n",
       "  'Drama, Mystery, Sci-Fi',\n",
       "  'Action, Adventure, Comedy',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Drama, Fantasy, Mystery',\n",
       "  'Comedy, Drama, Mystery',\n",
       "  'Crime, Drama',\n",
       "  'Drama, Horror, Mystery',\n",
       "  'Action, Crime, Drama',\n",
       "  'Comedy, Drama',\n",
       "  'Drama',\n",
       "  'Comedy, Drama, Romance',\n",
       "  'Comedy, Drama, Fantasy',\n",
       "  'Action, Adventure, Crime',\n",
       "  'Drama, Sci-Fi, Thriller',\n",
       "  'Crime, Drama, Thriller',\n",
       "  'Drama, Mystery, Thriller',\n",
       "  'Action, Crime, Drama',\n",
       "  'Drama, Thriller',\n",
       "  'Action, Adventure, Crime',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Comedy, Drama, Thriller',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Biography, Drama, History',\n",
       "  'Drama, History, Thriller',\n",
       "  'Comedy, Crime, Drama',\n",
       "  'Drama, Fantasy',\n",
       "  'Adventure, Comedy, Drama',\n",
       "  'Crime, Drama, Mystery',\n",
       "  'Comedy, Crime, Drama',\n",
       "  'Drama, Horror, Mystery'],\n",
       " 'Run_Time': ['57 min',\n",
       "  '51 min',\n",
       "  '44 min',\n",
       "  '60 min',\n",
       "  '43 min',\n",
       "  '59 min',\n",
       "  '45 min',\n",
       "  '41 min',\n",
       "  '43 min',\n",
       "  '42 min',\n",
       "  '70 min',\n",
       "  '22 min',\n",
       "  '60 min',\n",
       "  '88 min',\n",
       "  '44 min',\n",
       "  '44 min',\n",
       "  '43 min',\n",
       "  '60 min',\n",
       "  '49 min',\n",
       "  '42 min',\n",
       "  '44 min',\n",
       "  '44 min',\n",
       "  '43 min',\n",
       "  '41 min',\n",
       "  '22 min',\n",
       "  '60 min',\n",
       "  '49 min',\n",
       "  '54 min',\n",
       "  '22 min',\n",
       "  '22 min',\n",
       "  '44 min',\n",
       "  '49 min',\n",
       "  '45 min',\n",
       "  '43 min',\n",
       "  '42 min',\n",
       "  '60 min',\n",
       "  '42 min',\n",
       "  '62 min',\n",
       "  '56 min',\n",
       "  '22 min',\n",
       "  '23 min',\n",
       "  '42 min',\n",
       "  '25 min',\n",
       "  '51 min',\n",
       "  '60 min',\n",
       "  '60 min',\n",
       "  '45 min',\n",
       "  '46 min',\n",
       "  '22 min',\n",
       "  '45 min',\n",
       "  '45 min',\n",
       "  '53 min',\n",
       "  '44 min',\n",
       "  '22 min',\n",
       "  '43 min',\n",
       "  '44 min',\n",
       "  '60 min',\n",
       "  '44 min',\n",
       "  '42 min',\n",
       "  '44 min',\n",
       "  '55 min',\n",
       "  '42 min',\n",
       "  '42 min',\n",
       "  '60 min',\n",
       "  '60 min',\n",
       "  '41 min',\n",
       "  '60 min',\n",
       "  '44 min',\n",
       "  '22 min',\n",
       "  '22 min',\n",
       "  '43 min',\n",
       "  '60 min',\n",
       "  '55 min',\n",
       "  '60 min',\n",
       "  '45 min',\n",
       "  '46 min',\n",
       "  '45 min',\n",
       "  '53 min',\n",
       "  '30 min',\n",
       "  '42 min',\n",
       "  '45 min',\n",
       "  '22 min',\n",
       "  '55 min',\n",
       "  '45 min',\n",
       "  '60 min',\n",
       "  '44 min',\n",
       "  '55 min',\n",
       "  '43 min',\n",
       "  '50 min',\n",
       "  '60 min',\n",
       "  '45 min',\n",
       "  '43 min',\n",
       "  '58 min',\n",
       "  '330 min',\n",
       "  '42 min',\n",
       "  '42 min',\n",
       "  '50 min',\n",
       "  '42 min',\n",
       "  '45 min',\n",
       "  '572 min'],\n",
       " 'Ratings': ['9.3',\n",
       "  '8.7',\n",
       "  '8.2',\n",
       "  '7.6',\n",
       "  '7.6',\n",
       "  '8.1',\n",
       "  '6.9',\n",
       "  '7.6',\n",
       "  '7.7',\n",
       "  '7.5',\n",
       "  '8.3',\n",
       "  '8.1',\n",
       "  '8.8',\n",
       "  '9.1',\n",
       "  '8.5',\n",
       "  '7.4',\n",
       "  '7.7',\n",
       "  '8',\n",
       "  '9.5',\n",
       "  '8.1',\n",
       "  '8.4',\n",
       "  '8.3',\n",
       "  '8.1',\n",
       "  '7.6',\n",
       "  '8.6',\n",
       "  '7.7',\n",
       "  '8.8',\n",
       "  '8.6',\n",
       "  '8.9',\n",
       "  '8.3',\n",
       "  '8.5',\n",
       "  '8.5',\n",
       "  '8.2',\n",
       "  '6.2',\n",
       "  '7.4',\n",
       "  '8.3',\n",
       "  '7.8',\n",
       "  '8.6',\n",
       "  '7.9',\n",
       "  '8.4',\n",
       "  '9.2',\n",
       "  '6.6',\n",
       "  '8.1',\n",
       "  '8.7',\n",
       "  '8.8',\n",
       "  '7.6',\n",
       "  '8.3',\n",
       "  '8.6',\n",
       "  '7.7',\n",
       "  '7.5',\n",
       "  '7.7',\n",
       "  '8.6',\n",
       "  '6.9',\n",
       "  '8.1',\n",
       "  '8',\n",
       "  '8.3',\n",
       "  '8.8',\n",
       "  '8.7',\n",
       "  '6.7',\n",
       "  '8.3',\n",
       "  '8.3',\n",
       "  '7.4',\n",
       "  '6.8',\n",
       "  '8.4',\n",
       "  '7.5',\n",
       "  '8.2',\n",
       "  '7.8',\n",
       "  '6.7',\n",
       "  '8.7',\n",
       "  '8.4',\n",
       "  '6.6',\n",
       "  '8',\n",
       "  '8.9',\n",
       "  '7.9',\n",
       "  '7.5',\n",
       "  '8.7',\n",
       "  '8.1',\n",
       "  '8.5',\n",
       "  '8.3',\n",
       "  '7.3',\n",
       "  '8.7',\n",
       "  '8.2',\n",
       "  '6.5',\n",
       "  '6.3',\n",
       "  '8.6',\n",
       "  '7.8',\n",
       "  '7.3',\n",
       "  '7.7',\n",
       "  '7.3',\n",
       "  '8.5',\n",
       "  '6.5',\n",
       "  '8.1',\n",
       "  '8.7',\n",
       "  '9.4',\n",
       "  '7.8',\n",
       "  '7.5',\n",
       "  '7.8',\n",
       "  '8.1',\n",
       "  '7.2',\n",
       "  '8.6'],\n",
       " 'Votes': ['1,802,701',\n",
       "  '847,804',\n",
       "  '867,923',\n",
       "  '260,258',\n",
       "  '221,229',\n",
       "  '281,344',\n",
       "  '123,353',\n",
       "  '257,751',\n",
       "  '311,332',\n",
       "  '410,827',\n",
       "  '317,170',\n",
       "  '732,298',\n",
       "  '455,992',\n",
       "  '821,584',\n",
       "  '445,327',\n",
       "  '153,971',\n",
       "  '287,825',\n",
       "  '280,809',\n",
       "  '1,502,022',\n",
       "  '241,833',\n",
       "  '397,329',\n",
       "  '483,589',\n",
       "  '132,712',\n",
       "  '129,574',\n",
       "  '370,203',\n",
       "  '210,252',\n",
       "  '366,058',\n",
       "  '367,795',\n",
       "  '846,601',\n",
       "  '612,402',\n",
       "  '368,661',\n",
       "  '339,218',\n",
       "  '119,891',\n",
       "  '113,398',\n",
       "  '156,532',\n",
       "  '141,574',\n",
       "  '213,897',\n",
       "  '435,501',\n",
       "  '195,216',\n",
       "  '365,996',\n",
       "  '387,584',\n",
       "  '54,663',\n",
       "  '151,315',\n",
       "  '471,197',\n",
       "  '297,025',\n",
       "  '51,767',\n",
       "  '166,219',\n",
       "  '208,948',\n",
       "  '195,960',\n",
       "  '202,511',\n",
       "  '149,993',\n",
       "  '653,474',\n",
       "  '114,731',\n",
       "  '308,382',\n",
       "  '203,948',\n",
       "  '503,045',\n",
       "  '368,731',\n",
       "  '419,745',\n",
       "  '57,617',\n",
       "  '102,719',\n",
       "  '318,284',\n",
       "  '67,250',\n",
       "  '93,514',\n",
       "  '179,604',\n",
       "  '80,097',\n",
       "  '65,783',\n",
       "  '39,920',\n",
       "  '138,037',\n",
       "  '335,494',\n",
       "  '236,645',\n",
       "  '101,743',\n",
       "  '166,241',\n",
       "  '506,878',\n",
       "  '92,570',\n",
       "  '117,559',\n",
       "  '335,160',\n",
       "  '98,400',\n",
       "  '188,841',\n",
       "  '62,904',\n",
       "  '15,570',\n",
       "  '111,912',\n",
       "  '120,581',\n",
       "  '116,539',\n",
       "  '31,784',\n",
       "  '225,523',\n",
       "  '113,523',\n",
       "  '118,224',\n",
       "  '67,852',\n",
       "  '92,501',\n",
       "  '161,942',\n",
       "  '23,233',\n",
       "  '167,586',\n",
       "  '161,737',\n",
       "  '567,566',\n",
       "  '61,178',\n",
       "  '44,219',\n",
       "  '54,678',\n",
       "  '165,500',\n",
       "  '34,585',\n",
       "  '188,198']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the 'Name', 'Year_span', 'Genre', 'Run_Time', 'Ratings', 'Votes' details\n",
    "names = driver.find_elements_by_xpath(\"//h3/a\")\n",
    "years = driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "genres = driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "run_times = driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "ratings = driver.find_elements_by_xpath(\"//div[@class='ipl-rating-widget']/div/span[2]\")\n",
    "votes = driver.find_elements_by_xpath(\"//span[@name='nv']\")\n",
    "for i in range(len(names)):\n",
    "    d['Name'].append(names[i].text)\n",
    "    d['Year_span'].append(years[i].text)\n",
    "    d['Genre'].append(genres[i].text)\n",
    "    d['Run_Time'].append(run_times[i].text)\n",
    "    d['Ratings'].append(ratings[i].text)\n",
    "    d['Votes'].append(votes[i].text)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,802,701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>847,804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>867,923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>260,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>221,229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>54,678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>165,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.2</td>\n",
       "      <td>34,585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>188,198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_Time Ratings      Votes  \n",
       "0    57 min     9.3  1,802,701  \n",
       "1    51 min     8.7    847,804  \n",
       "2    44 min     8.2    867,923  \n",
       "3    60 min     7.6    260,258  \n",
       "4    43 min     7.6    221,229  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     44,219  \n",
       "96   50 min     7.8     54,678  \n",
       "97   42 min     8.1    165,500  \n",
       "98   45 min     7.2     34,585  \n",
       "99  572 min     8.6    188,198  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Details of Datasets from UCI machine learning repositories.\n",
    "### Url = https://archive.ics.uci.edu/\n",
    "### You have to find the following details:\n",
    "### A) Dataset name\n",
    "### B) Data type\n",
    "### C) Task\n",
    "### D) Attribute type\n",
    "### E) No of instances\n",
    "### F) No of attribute\n",
    "### G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the website\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to all datasets page\n",
    "dataset_page = driver.find_element_by_xpath(\"//b[contains(text(),'View ALL Data Sets')]//ancestor::a\").get_attribute('href')\n",
    "driver.get(dataset_page)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the dictionary\n",
    "d = {\n",
    "    'Dataset_Name':[],\n",
    "    'Data_Type':[],\n",
    "    'Task':[],\n",
    "    'Attribute_Type':[],\n",
    "    'No_of_Instances':[],\n",
    "    'No_of_Attributes':[],\n",
    "    'Year':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching total number of rows\n",
    "rows = driver.find_elements_by_xpath(\"//table[@border='1']/tbody/tr\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dataset_Name': ['  Abalone',\n",
       "  '  Adult',\n",
       "  '  Annealing',\n",
       "  '  Anonymous Microsoft Web Data',\n",
       "  '  Arrhythmia',\n",
       "  '  Artificial Characters',\n",
       "  '  Audiology (Original)',\n",
       "  '  Audiology (Standardized)',\n",
       "  '  Auto MPG',\n",
       "  '  Automobile',\n",
       "  '  Badges',\n",
       "  '  Balance Scale',\n",
       "  '  Balloons',\n",
       "  '  Breast Cancer',\n",
       "  '  Breast Cancer Wisconsin (Original)',\n",
       "  '  Breast Cancer Wisconsin (Prognostic)',\n",
       "  '  Breast Cancer Wisconsin (Diagnostic)',\n",
       "  '  Pittsburgh Bridges',\n",
       "  '  Car Evaluation',\n",
       "  '  Census Income',\n",
       "  '  Chess (King-Rook vs. King-Knight)',\n",
       "  '  Chess (King-Rook vs. King-Pawn)',\n",
       "  '  Chess (King-Rook vs. King)',\n",
       "  '  Chess (Domain Theories)',\n",
       "  '  Bach Chorales',\n",
       "  '  Connect-4',\n",
       "  '  Credit Approval',\n",
       "  '  Japanese Credit Screening',\n",
       "  '  Computer Hardware',\n",
       "  '  Contraceptive Method Choice',\n",
       "  '  Covertype',\n",
       "  '  Cylinder Bands',\n",
       "  '  Dermatology',\n",
       "  '  Diabetes',\n",
       "  '  DGP2 - The Second Data Generation Program',\n",
       "  '  Document Understanding',\n",
       "  '  EBL Domain Theories',\n",
       "  '  Echocardiogram',\n",
       "  '  Ecoli',\n",
       "  '  Flags',\n",
       "  '  Function Finding',\n",
       "  '  Glass Identification',\n",
       "  \"  Haberman's Survival\",\n",
       "  '  Hayes-Roth',\n",
       "  '  Heart Disease',\n",
       "  '  Hepatitis',\n",
       "  '  Horse Colic',\n",
       "  '  ICU',\n",
       "  '  Image Segmentation',\n",
       "  '  Internet Advertisements',\n",
       "  '  Ionosphere',\n",
       "  '  Iris',\n",
       "  '  ISOLET',\n",
       "  '  Kinship',\n",
       "  '  Labor Relations',\n",
       "  '  LED Display Domain',\n",
       "  '  Lenses',\n",
       "  '  Letter Recognition',\n",
       "  '  Liver Disorders',\n",
       "  '  Logic Theorist',\n",
       "  '  Lung Cancer',\n",
       "  '  Lymphography',\n",
       "  '  Mechanical Analysis',\n",
       "  '  Meta-data',\n",
       "  '  Mobile Robots',\n",
       "  '  Molecular Biology (Promoter Gene Sequences)',\n",
       "  '  Molecular Biology (Protein Secondary Structure)',\n",
       "  '  Molecular Biology (Splice-junction Gene Sequences)',\n",
       "  \"  MONK's Problems\",\n",
       "  '  Moral Reasoner',\n",
       "  '  Multiple Features',\n",
       "  '  Mushroom',\n",
       "  '  Musk (Version 1)',\n",
       "  '  Musk (Version 2)',\n",
       "  '  Nursery',\n",
       "  '  Othello Domain Theory',\n",
       "  '  Page Blocks Classification',\n",
       "  '  Optical Recognition of Handwritten Digits',\n",
       "  '  Pen-Based Recognition of Handwritten Digits',\n",
       "  '  Post-Operative Patient',\n",
       "  '  Primary Tumor',\n",
       "  '  Prodigy',\n",
       "  '  Qualitative Structure Activity Relationships',\n",
       "  '  Quadruped Mammals',\n",
       "  '  Servo',\n",
       "  '  Shuttle Landing Control',\n",
       "  '  Solar Flare',\n",
       "  '  Soybean (Large)',\n",
       "  '  Soybean (Small)',\n",
       "  '  Challenger USA Space Shuttle O-Ring',\n",
       "  '  Low Resolution Spectrometer',\n",
       "  '  Spambase',\n",
       "  '  SPECT Heart',\n",
       "  '  SPECTF Heart',\n",
       "  '  Sponge',\n",
       "  '  Statlog Project',\n",
       "  '  Student Loan Relational',\n",
       "  '  Teaching Assistant Evaluation',\n",
       "  '  Tic-Tac-Toe Endgame',\n",
       "  '  Thyroid Disease',\n",
       "  '  Trains',\n",
       "  '  University',\n",
       "  '  Congressional Voting Records',\n",
       "  '  Water Treatment Plant',\n",
       "  '  Waveform Database Generator (Version 1)',\n",
       "  '  Waveform Database Generator (Version 2)',\n",
       "  '  Wine',\n",
       "  '  Yeast',\n",
       "  '  Zoo',\n",
       "  '  Undocumented',\n",
       "  '  Twenty Newsgroups',\n",
       "  '  Australian Sign Language signs',\n",
       "  '  Australian Sign Language signs (High Quality)',\n",
       "  '  US Census Data (1990)',\n",
       "  '  Census-Income (KDD)',\n",
       "  '  Coil 1999 Competition Data',\n",
       "  '  Corel Image Features',\n",
       "  '  E. Coli Genes',\n",
       "  '  EEG Database',\n",
       "  '  El Nino',\n",
       "  '  Entree Chicago Recommendation Data',\n",
       "  '  CMU Face Images',\n",
       "  '  Insurance Company Benchmark (COIL 2000)',\n",
       "  '  Internet Usage Data',\n",
       "  '  IPUMS Census Database',\n",
       "  '  Japanese Vowels',\n",
       "  '  KDD Cup 1998 Data',\n",
       "  '  KDD Cup 1999 Data',\n",
       "  '  M. Tuberculosis Genes',\n",
       "  '  Movie',\n",
       "  '  MSNBC.com Anonymous Web Data',\n",
       "  '  NSF Research Award Abstracts 1990-2003',\n",
       "  '  Pioneer-1 Mobile Robot Data',\n",
       "  '  Pseudo Periodic Synthetic Time Series',\n",
       "  '  Reuters-21578 Text Categorization Collection',\n",
       "  '  Robot Execution Failures',\n",
       "  '  Synthetic Control Chart Time Series',\n",
       "  '  Syskill and Webert Web Page Ratings',\n",
       "  '  UNIX User Data',\n",
       "  '  Volcanoes on Venus - JARtool experiment',\n",
       "  '  Statlog (Australian Credit Approval)',\n",
       "  '  Statlog (German Credit Data)',\n",
       "  '  Statlog (Heart)',\n",
       "  '  Statlog (Landsat Satellite)',\n",
       "  '  Statlog (Image Segmentation)',\n",
       "  '  Statlog (Shuttle)',\n",
       "  '  Statlog (Vehicle Silhouettes)',\n",
       "  '  Connectionist Bench (Nettalk Corpus)',\n",
       "  '  Connectionist Bench (Sonar, Mines vs. Rocks)',\n",
       "  '  Connectionist Bench (Vowel Recognition - Deterding Data)',\n",
       "  '  Economic Sanctions',\n",
       "  '  Protein Data',\n",
       "  '  Cloud',\n",
       "  '  CalIt2 Building People Counts',\n",
       "  '  Dodgers Loop Sensor',\n",
       "  '  Poker Hand',\n",
       "  '  MAGIC Gamma Telescope',\n",
       "  '  UJI Pen Characters',\n",
       "  '  Mammographic Mass',\n",
       "  '  Forest Fires',\n",
       "  '  Reuters Transcribed Subset',\n",
       "  '  Bag of Words',\n",
       "  '  Concrete Compressive Strength',\n",
       "  '  Hill-Valley',\n",
       "  '  Arcene',\n",
       "  '  Dexter',\n",
       "  '  Dorothea',\n",
       "  '  Gisette',\n",
       "  '  Madelon',\n",
       "  '  Ozone Level Detection',\n",
       "  '  Abscisic Acid Signaling Network',\n",
       "  '  Parkinsons',\n",
       "  '  Character Trajectories',\n",
       "  '  Blood Transfusion Service Center',\n",
       "  '  UJI Pen Characters (Version 2)',\n",
       "  '  Semeion Handwritten Digit',\n",
       "  '  SECOM',\n",
       "  '  Plants',\n",
       "  '  Libras Movement',\n",
       "  '  Concrete Slump Test',\n",
       "  '  Communities and Crime',\n",
       "  '  Acute Inflammations',\n",
       "  '  Wine Quality',\n",
       "  '  URL Reputation',\n",
       "  '  p53 Mutants',\n",
       "  '  Parkinsons Telemonitoring',\n",
       "  '  Demospongiae',\n",
       "  '  Opinosis Opinion ⁄ Review',\n",
       "  '  Breast Tissue',\n",
       "  '  Cardiotocography',\n",
       "  '  Wall-Following Robot Navigation Data',\n",
       "  '  Spoken Arabic Digit',\n",
       "  '  Localization Data for Person Activity',\n",
       "  '  AutoUniv',\n",
       "  '  Steel Plates Faults',\n",
       "  '  MiniBooNE particle identification',\n",
       "  '  YearPredictionMSD',\n",
       "  '  PEMS-SF',\n",
       "  '  OpinRank Review Dataset',\n",
       "  '  Relative location of CT slices on axial axis',\n",
       "  '  Online Handwritten Assamese Characters Dataset',\n",
       "  '  PubChem Bioassay Data',\n",
       "  '  Record Linkage Comparison Patterns',\n",
       "  '  Communities and Crime Unnormalized',\n",
       "  '  Vertebral Column',\n",
       "  '  EMG Physical Action Data Set',\n",
       "  '  Vicon Physical Action Data Set',\n",
       "  '  Amazon Commerce reviews set',\n",
       "  '  Amazon Access Samples',\n",
       "  '  Reuter_50_50',\n",
       "  '  Farm Ads',\n",
       "  '  DBWorld e-mails',\n",
       "  '  KEGG Metabolic Relation Network (Directed)',\n",
       "  '  KEGG Metabolic Reaction Network (Undirected)',\n",
       "  '  Bank Marketing',\n",
       "  '  YouTube Comedy Slam Preference Data',\n",
       "  '  Gas Sensor Array Drift Dataset',\n",
       "  '  ILPD (Indian Liver Patient Dataset)',\n",
       "  '  OPPORTUNITY Activity Recognition',\n",
       "  '  Nomao',\n",
       "  '  SMS Spam Collection',\n",
       "  '  Skin Segmentation',\n",
       "  '  Planning Relax',\n",
       "  '  PAMAP2 Physical Activity Monitoring',\n",
       "  '  Restaurant & consumer data',\n",
       "  '  CNAE-9',\n",
       "  '  Individual household electric power consumption',\n",
       "  '  seeds',\n",
       "  '  Northix',\n",
       "  '  QtyT40I10D100K',\n",
       "  '  Legal Case Reports',\n",
       "  '  Human Activity Recognition Using Smartphones',\n",
       "  '  One-hundred plant species leaves data set',\n",
       "  '  Energy efficiency',\n",
       "  '  Yacht Hydrodynamics',\n",
       "  '  Fertility',\n",
       "  '  Daphnet Freezing of Gait',\n",
       "  '  3D Road Network (North Jutland, Denmark)',\n",
       "  '  ISTANBUL STOCK EXCHANGE',\n",
       "  '  Buzz in social media',\n",
       "  '  First-order theorem proving',\n",
       "  '  Wearable Computing: Classification of Body Postures and Movements (PUC-Rio)',\n",
       "  '  Gas sensor arrays in open sampling settings',\n",
       "  '  Climate Model Simulation Crashes',\n",
       "  '  MicroMass',\n",
       "  '  QSAR biodegradation',\n",
       "  '  BLOGGER',\n",
       "  '  Daily and Sports Activities',\n",
       "  '  User Knowledge Modeling',\n",
       "  '  Reuters RCV1 RCV2 Multilingual, Multiview Text Categorization Test collection',\n",
       "  '  NYSK',\n",
       "  '  Turkiye Student Evaluation',\n",
       "  \"  ser Knowledge Modeling Data (Students' Knowledge Levels on DC Electrical Machines)\",\n",
       "  '  EEG Eye State',\n",
       "  '  Physicochemical Properties of Protein Tertiary Structure',\n",
       "  '  seismic-bumps',\n",
       "  '  banknote authentication',\n",
       "  '  USPTO Algorithm Challenge, run by NASA-Harvard Tournament Lab and TopCoder Problem: Pat',\n",
       "  '  YouTube Multiview Video Games Dataset',\n",
       "  '  Gas Sensor Array Drift Dataset at Different Concentrations',\n",
       "  '  Activities of Daily Living (ADLs) Recognition Using Binary Sensors',\n",
       "  '  SkillCraft1 Master Table Dataset',\n",
       "  '  Weight Lifting Exercises monitored with Inertial Measurement Units',\n",
       "  '  SML2010',\n",
       "  '  Bike Sharing Dataset',\n",
       "  '  Predict keywords activities in a online social media',\n",
       "  '  Thoracic Surgery Data',\n",
       "  '  EMG dataset in Lower Limb',\n",
       "  '  SUSY',\n",
       "  '  HIGGS',\n",
       "  '  Qualitative_Bankruptcy',\n",
       "  '  LSVT Voice Rehabilitation',\n",
       "  '  Dataset for ADL Recognition with Wrist-worn Accelerometer',\n",
       "  '  Wilt',\n",
       "  '  User Identification From Walking Activity',\n",
       "  '  Activity Recognition from Single Chest-Mounted Accelerometer',\n",
       "  '  Leaf',\n",
       "  '  Dresses_Attribute_Sales',\n",
       "  '  Tamilnadu Electricity Board Hourly Readings',\n",
       "  '  Airfoil Self-Noise',\n",
       "  '  Wholesale customers',\n",
       "  '  Twitter Data set for Arabic Sentiment Analysis',\n",
       "  '  Combined Cycle Power Plant',\n",
       "  '  Urban Land Cover',\n",
       "  '  Diabetes 130-US hospitals for years 1999-2008',\n",
       "  '  Bach Choral Harmony',\n",
       "  '  StoneFlakes',\n",
       "  '  Tennis Major Tournament Match Statistics',\n",
       "  '  Parkinson Speech Dataset with Multiple Types of Sound Recordings',\n",
       "  '  Gesture Phase Segmentation',\n",
       "  '  Perfume Data',\n",
       "  '  BlogFeedback',\n",
       "  '  REALDISP Activity Recognition Dataset',\n",
       "  '  Newspaper and magazine images segmentation dataset',\n",
       "  '  AAAI 2014 Accepted Papers',\n",
       "  '  Gas sensor array under flow modulation',\n",
       "  '  Gas sensor array exposed to turbulent gas mixtures',\n",
       "  '  UJIIndoorLoc',\n",
       "  '  Sentence Classification',\n",
       "  '  Dow Jones Index',\n",
       "  '  sEMG for Basic Hand movements',\n",
       "  '  AAAI 2013 Accepted Papers',\n",
       "  '  Geographical Original of Music',\n",
       "  '  Condition Based Maintenance of Naval Propulsion Plants',\n",
       "  '  Grammatical Facial Expressions',\n",
       "  '  NoisyOffice',\n",
       "  '  MHEALTH Dataset',\n",
       "  '  Student Performance',\n",
       "  '  ElectricityLoadDiagrams20112014',\n",
       "  '  Gas sensor array under dynamic gas mixtures',\n",
       "  '  microblogPCU',\n",
       "  '  Firm-Teacher_Clave-Direction_Classification',\n",
       "  '  Dataset for Sensorless Drive Diagnosis',\n",
       "  '  TV News Channel Commercial Detection Dataset',\n",
       "  '  Phishing Websites',\n",
       "  '  Greenhouse Gas Observing Network',\n",
       "  '  Diabetic Retinopathy Debrecen Data Set',\n",
       "  '  HIV-1 protease cleavage',\n",
       "  '  Sentiment Labelled Sentences',\n",
       "  '  Online News Popularity',\n",
       "  '  Forest type mapping',\n",
       "  '  wiki4HE',\n",
       "  '  Online Video Characteristics and Transcoding Time Dataset',\n",
       "  '  Chronic_Kidney_Disease',\n",
       "  '  Machine Learning based ZZAlpha Ltd. Stock Recommendations 2012-2014',\n",
       "  '  Folio',\n",
       "  '  Taxi Service Trajectory - Prediction Challenge, ECML PKDD 2015',\n",
       "  '  Cuff-Less Blood Pressure Estimation',\n",
       "  '  Smartphone-Based Recognition of Human Activities and Postural Transitions',\n",
       "  '  Mice Protein Expression',\n",
       "  '  UJIIndoorLoc-Mag',\n",
       "  '  Heterogeneity Activity Recognition',\n",
       "  '  Educational Process Mining (EPM): A Learning Analytics Data Set',\n",
       "  '  HEPMASS',\n",
       "  '  Indoor User Movement Prediction from RSS data',\n",
       "  '  Open University Learning Analytics dataset',\n",
       "  '  default of credit card clients',\n",
       "  '  Mesothelioma’s disease data set',\n",
       "  '  Online Retail',\n",
       "  '  SIFT10M',\n",
       "  '  GPS Trajectories',\n",
       "  '  Detect Malacious Executable(AntiVirus)',\n",
       "  '  Occupancy Detection',\n",
       "  '  Improved Spiral Test Using Digitized Graphics Tablet for Monitoring Parkinson’s Disease',\n",
       "  '  News Aggregator',\n",
       "  '  Air Quality',\n",
       "  '  Twin gas sensor arrays',\n",
       "  '  Gas sensors for home activity monitoring',\n",
       "  '  Facebook Comment Volume Dataset',\n",
       "  '  Smartphone Dataset for Human Activity Recognition (HAR) in Ambient Assisted Living (AAL)',\n",
       "  '  Polish companies bankruptcy data',\n",
       "  '  Activity Recognition system based on Multisensor data fusion (AReM)',\n",
       "  '  Dota2 Games Results',\n",
       "  '  Facebook metrics',\n",
       "  '  UbiqLog (smartphone lifelogging)',\n",
       "  '  NIPS Conference Papers 1987-2015',\n",
       "  '  HTRU2',\n",
       "  '  Drug consumption (quantified)',\n",
       "  '  Appliances energy prediction',\n",
       "  '  Miskolc IIS Hybrid IPS',\n",
       "  '  KDC-4007 dataset Collection',\n",
       "  '  Geo-Magnetic field and WLAN dataset for indoor localisation from wristband and smartphone',\n",
       "  '  DrivFace',\n",
       "  '  Website Phishing',\n",
       "  '  YouTube Spam Collection',\n",
       "  '  Beijing PM2.5 Data',\n",
       "  '  Cargo 2000 Freight Tracking and Tracing',\n",
       "  '  Cervical cancer (Risk Factors)',\n",
       "  '  Quality Assessment of Digital Colposcopies',\n",
       "  '  KASANDR',\n",
       "  '  FMA: A Dataset For Music Analysis',\n",
       "  '  Air quality',\n",
       "  '  Epileptic Seizure Recognition',\n",
       "  '  Devanagari Handwritten Character Dataset',\n",
       "  '  Stock portfolio performance',\n",
       "  '  MoCap Hand Postures',\n",
       "  '  Early biomarkers of Parkinson�s disease based on natural connected speech',\n",
       "  '  Data for Software Engineering Teamwork Assessment in Education Setting',\n",
       "  '  PM2.5 Data of Five Chinese Cities',\n",
       "  '  Parkinson Disease Spiral Drawings Using Digitized Graphics Tablet',\n",
       "  '  Sales_Transactions_Dataset_Weekly',\n",
       "  '  Las Vegas Strip',\n",
       "  '  Eco-hotel',\n",
       "  '  MEU-Mobile KSD',\n",
       "  '  Crowdsourced Mapping',\n",
       "  '  gene expression cancer RNA-Seq',\n",
       "  '  Hybrid Indoor Positioning Dataset from WiFi RSSI, Bluetooth and magnetometer',\n",
       "  '  chestnut – LARVIC',\n",
       "  '  Burst Header Packet (BHP) flooding attack on Optical Burst Switching (OBS) Network',\n",
       "  '  Motion Capture Hand Postures',\n",
       "  '  Anuran Calls (MFCCs)',\n",
       "  '  TTC-3600: Benchmark dataset for Turkish text categorization',\n",
       "  '  Gastrointestinal Lesions in Regular Colonoscopy',\n",
       "  '  Daily Demand Forecasting Orders',\n",
       "  '  Paper Reviews',\n",
       "  '  extention of Z-Alizadeh sani dataset',\n",
       "  '  Z-Alizadeh Sani',\n",
       "  '  Dynamic Features of VirusShare Executables',\n",
       "  '  IDA2016Challenge',\n",
       "  '  DSRC Vehicle Communications',\n",
       "  '  Mturk User-Perceived Clusters over Images',\n",
       "  '  Character Font Images',\n",
       "  '  DeliciousMIL: A Data Set for Multi-Label Multi-Instance Learning with Instance Labels',\n",
       "  '  Autistic Spectrum Disorder Screening Data for Children',\n",
       "  '  Autistic Spectrum Disorder Screening Data for Adolescent',\n",
       "  '  APS Failure at Scania Trucks',\n",
       "  '  Wireless Indoor Localization',\n",
       "  '  HCC Survival',\n",
       "  '  CSM (Conventional and Social Media Movies) Dataset 2014 and 2015',\n",
       "  '  University of Tehran Question Dataset 2016 (UTQD.2016)',\n",
       "  '  Autism Screening Adult',\n",
       "  '  Activity recognition with healthy older people using a batteryless wearable sensor',\n",
       "  '  Immunotherapy Dataset',\n",
       "  '  Cryotherapy Dataset',\n",
       "  '  OCT data & Color Fundus Images of Left & Right Eyes',\n",
       "  '  Discrete Tone Image Dataset',\n",
       "  '  News Popularity in Multiple Social Media Platforms',\n",
       "  '  Ultrasonic flowmeter diagnostics',\n",
       "  '  ICMLA 2014 Accepted Papers Data Set',\n",
       "  '  BLE RSSI Dataset for Indoor localization and Navigation',\n",
       "  '  Container Crane Controller Data Set',\n",
       "  '  Residential Building Data Set',\n",
       "  '  Health News in Twitter',\n",
       "  '  chipseq',\n",
       "  '  SGEMM GPU kernel performance',\n",
       "  '  Repeat Consumption Matrices',\n",
       "  '  detection_of_IoT_botnet_attacks_N_BaIoT',\n",
       "  '  Absenteeism at work',\n",
       "  '  SCADI',\n",
       "  '  Condition monitoring of hydraulic systems',\n",
       "  '  Carbon Nanotubes',\n",
       "  '  Optical Interconnection Network',\n",
       "  '  Sports articles for objectivity analysis',\n",
       "  '  Breast Cancer Coimbra',\n",
       "  '  GNFUV Unmanned Surface Vehicles Sensor Data',\n",
       "  '  Dishonest Internet users Dataset',\n",
       "  '  Victorian Era Authorship Attribution',\n",
       "  '  Simulated Falls and Daily Living Activities Data Set',\n",
       "  '  Multimodal Damage Identification for Humanitarian Computing',\n",
       "  '  EEG Steady-State Visual Evoked Potential Signals',\n",
       "  '  Roman Urdu Data Set',\n",
       "  '  Avila',\n",
       "  '  PANDOR',\n",
       "  '  Drug Review Dataset (Druglib.com)',\n",
       "  '  Drug Review Dataset (Drugs.com)',\n",
       "  '  Physical Unclonable Functions',\n",
       "  '  Superconductivty Data',\n",
       "  '  WESAD (Wearable Stress and Affect Detection)',\n",
       "  '  GNFUV Unmanned Surface Vehicles Sensor Data Set 2',\n",
       "  '  Student Academics Performance',\n",
       "  '  Online Shoppers Purchasing Intention Dataset',\n",
       "  '  PMU-UD',\n",
       "  \"  Parkinson's Disease Classification\",\n",
       "  '  Electrical Grid Stability Simulated Data',\n",
       "  '  Caesarian Section Classification Dataset',\n",
       "  '  BAUM-1',\n",
       "  '  BAUM-2',\n",
       "  '  Audit Data',\n",
       "  '  BuddyMove Data Set',\n",
       "  '  Real estate valuation data set',\n",
       "  '  Early biomarkers of Parkinson’s disease based on natural connected speech Data Set',\n",
       "  '  Somerville Happiness Survey',\n",
       "  '  2.4 GHZ Indoor Channel Measurements',\n",
       "  '  EMG data for gestures',\n",
       "  '  Parking Birmingham',\n",
       "  '  Behavior of the urban traffic of the city of Sao Paulo in Brazil',\n",
       "  '  Travel Reviews',\n",
       "  '  Tarvel Review Ratings',\n",
       "  '  Rice Leaf Diseases',\n",
       "  '  Gas sensor array temperature modulation',\n",
       "  '  Facebook Live Sellers in Thailand',\n",
       "  '  Parkinson Dataset with replicated acoustic features',\n",
       "  '  Metro Interstate Traffic Volume',\n",
       "  '  Query Analytics Workloads Dataset',\n",
       "  '  Wave Energy Converters',\n",
       "  '  PPG-DaLiA',\n",
       "  '  Alcohol QCM Sensor Dataset',\n",
       "  '  Divorce Predictors data set',\n",
       "  '  Incident management process enriched event log',\n",
       "  '  Opinion Corpus for Lebanese Arabic Reviews (OCLAR)',\n",
       "  '  MEx',\n",
       "  '  Beijing Multi-Site Air-Quality Data',\n",
       "  '  Online Retail II',\n",
       "  '  Hepatitis C Virus (HCV) for Egyptian patients',\n",
       "  '  QSAR fish toxicity',\n",
       "  '  QSAR aquatic toxicity',\n",
       "  '  Human Activity Recognition from Continuous Ambient Sensor Data',\n",
       "  '  WISDM Smartphone and Smartwatch Activity and Biometrics Dataset',\n",
       "  '  QSAR oral toxicity',\n",
       "  '  QSAR androgen receptor',\n",
       "  '  QSAR Bioconcentration classes dataset',\n",
       "  '  QSAR fish bioconcentration factor (BCF)',\n",
       "  '  A study of Asian Religious and Biblical Texts',\n",
       "  '  Real-time Election Results: Portugal 2019',\n",
       "  '  Bias correction of numerical prediction model temperature forecast',\n",
       "  '  Bar Crawl: Detecting Heavy Drinking',\n",
       "  '  Kitsune Network Attack Dataset',\n",
       "  '  Shoulder Implant X-Ray Manufacturer Classification',\n",
       "  '  Speaker Accent Recognition',\n",
       "  '  Heart failure clinical records',\n",
       "  '  Deepfakes: Medical Image Tamper Detection',\n",
       "  '  selfBACK',\n",
       "  '  South German Credit',\n",
       "  '  Exasens',\n",
       "  '  Swarm Behaviour',\n",
       "  '  Crop mapping using fused optical-radar data set',\n",
       "  '  BitcoinHeistRansomwareAddressDataset',\n",
       "  '  Facebook Large Page-Page Network',\n",
       "  '  Amphibians',\n",
       "  '  Early stage diabetes risk prediction dataset.',\n",
       "  '  Turkish Spam V01',\n",
       "  '  Stock keeping units',\n",
       "  '  Demand Forecasting for a store',\n",
       "  '  Detect Malware Types',\n",
       "  '  Wave Energy Converters',\n",
       "  '  Youtube cookery channels viewers comments in Hinglish',\n",
       "  '  Pedestrian in Traffic Dataset',\n",
       "  '  Cervical Cancer Behavior Risk',\n",
       "  '  Sattriya_Dance_Single_Hand_Gestures Dataset',\n",
       "  '  Divorce Predictors data set',\n",
       "  '  3W dataset',\n",
       "  '  Malware static and dynamic features VxHeaven and Virus Total',\n",
       "  '  Internet Firewall Data',\n",
       "  '  User Profiling and Abusive Language Detection Dataset',\n",
       "  '  Estimation of obesity levels based on eating habits and physical condition',\n",
       "  '  Rice (Cammeo and Osmancik)',\n",
       "  '  Vehicle routing and scheduling problems',\n",
       "  '  Algerian Forest Fires Dataset',\n",
       "  '  Breath Metabolomics',\n",
       "  '  Horton General Hospital',\n",
       "  '  UrbanGB, urban road accidents coordinates labelled by the urban center',\n",
       "  '  Gas Turbine CO and NOx Emission Data Set',\n",
       "  '  Activity recognition using wearable physiological measurements',\n",
       "  '  clickstream data for online shopping',\n",
       "  '  CNNpred: CNN-based stock market prediction using a diverse set of variables',\n",
       "  '  Apartment for rent classified',\n",
       "  '  : Simulated Data set of Iraqi tourism places',\n",
       "  '  Nasarian CAD Dataset',\n",
       "  '  Monolithic Columns in Troad and Mysia Region',\n",
       "  '  Bar Crawl: Detecting Heavy Drinking',\n",
       "  '  Seoul Bike Sharing Demand',\n",
       "  '  Person Classification Gait Data',\n",
       "  '  Shill Bidding Dataset',\n",
       "  '  Iranian Churn Dataset',\n",
       "  '  Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       "  '  Bone marrow transplant: children',\n",
       "  '  Exasens',\n",
       "  '  COVID-19 Surveillance',\n",
       "  '  Refractive errors',\n",
       "  '  Shoulder Implant X-Ray Manufacturer Classification',\n",
       "  '  CLINC150',\n",
       "  '  HCV data',\n",
       "  '  Taiwanese Bankruptcy Prediction',\n",
       "  '  South German Credit (UPDATE)',\n",
       "  '  IIWA14-R820-Gazebo-Dataset-10Trajectories',\n",
       "  '  Guitar Chords finger positions',\n",
       "  '  Russian Corpus of Biographical Texts',\n",
       "  '  Codon usage',\n",
       "  '  Intelligent Media Accelerometer and Gyroscope (IM-AccGyro) Dataset',\n",
       "  '  Myocardial infarction complications',\n",
       "  '  Hungarian Chickenpox Cases',\n",
       "  '  Simulated data for survival modelling',\n",
       "  '  Student Performance on an entrance examination',\n",
       "  '  Chemical Composition of Ceramic Samples',\n",
       "  '  Labeled Text Forum Threads Dataset',\n",
       "  '  Stock keeping units',\n",
       "  '  BLE RSSI dataset for Indoor localization',\n",
       "  '  Basketball dataset',\n",
       "  '  GitHub MUSAE',\n",
       "  '  Anticancer peptides',\n",
       "  '  Monolithic Columns in Troad and Mysia Region',\n",
       "  '  Gender by Name',\n",
       "  '  Iranian Churn Dataset',\n",
       "  '  Unmanned Aerial Vehicle (UAV) Intrusion Detection',\n",
       "  '  Shoulder Implant Manufacture Classification',\n",
       "  '  LastFM Asia Social Network',\n",
       "  '  Wheat kernels',\n",
       "  '  Productivity Prediction of Garment Employees',\n",
       "  '  Multi-view Brain Networks',\n",
       "  '  LastFM Asia Social Network',\n",
       "  '  Wisesight Sentiment Corpus',\n",
       "  '  AI4I 2020 Predictive Maintenance Dataset',\n",
       "  '  Dry Bean Dataset',\n",
       "  '  in-vehicle coupon recommendation',\n",
       "  '  Gait Classification',\n",
       "  '  Wikipedia Math Essentials',\n",
       "  '  Wikipedia Math Essentials',\n",
       "  '  Synchronous Machine Data Set'],\n",
       " 'Data_Type': ['Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Univariate, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Data-Generator ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Domain-Theory ',\n",
       "  'Univariate, Time-Series ',\n",
       "  'Multivariate, Spatial ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Data-Generator ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Relational ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Data-Generator ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Domain-Theory ',\n",
       "  'Sequential, Domain-Theory ',\n",
       "  'Sequential ',\n",
       "  'Sequential, Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Domain-Theory ',\n",
       "  'Domain-Theory ',\n",
       "  'Multivariate, Data-Generator ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Data-Generator ',\n",
       "  'Multivariate, Data-Generator ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Relational ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Spatio-temporal ',\n",
       "  'Transactional, Sequential ',\n",
       "  'Image ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Relational ',\n",
       "  'Multivariate, Relational ',\n",
       "  'Sequential ',\n",
       "  'Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Univariate, Time-Series ',\n",
       "  'Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate, Text ',\n",
       "  'Text, Sequential ',\n",
       "  'Image ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Domain-Theory ',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Univariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Text ',\n",
       "  'Domain-Theory ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate, Text, Domain-Theory ',\n",
       "  'Time-Series, Domain-Theory ',\n",
       "  'Multivariate, Text, Domain-Theory ',\n",
       "  'Text ',\n",
       "  'Text ',\n",
       "  'Multivariate, Univariate, Text ',\n",
       "  'Multivariate, Univariate, Text ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Univariate ',\n",
       "  'Multivariate, Text, Domain-Theory ',\n",
       "  'Univariate ',\n",
       "  'Univariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Univariate, Text ',\n",
       "  'Sequential ',\n",
       "  'Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Sequential, Text ',\n",
       "  'Multivariate, Univariate, Time-Series ',\n",
       "  'Time-Series, Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Sequential ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Domain-Theory ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series, Text ',\n",
       "  'Univariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Univariate, Sequential, Time-Series ',\n",
       "  'Univariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Univariate, Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Time-Series ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Univariate, Sequential, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series, Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Time-Series, Domain-Theory ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Text ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Sequential, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  '-',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  '-',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Text ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Sequential, Text ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  '-',\n",
       "  'Sequential ',\n",
       "  'Univariate ',\n",
       "  'Univariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Univariate, Domain-Theory ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Univariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Univariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Univariate ',\n",
       "  'Time-Series ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate, Univariate, Sequential, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Univariate ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Text ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Sequential, Time-Series, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Time-Series, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series, Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Sequential, Time-Series ',\n",
       "  'Multivariate, Univariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Univariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Univariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Sequential ',\n",
       "  'Sequential, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  '-',\n",
       "  'Text ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Sequential, Time-Series ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Sequential ',\n",
       "  'Multivariate ',\n",
       "  'Text ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate, Text ',\n",
       "  'Multivariate, Time-Series ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Multivariate ',\n",
       "  'Time-Series ',\n",
       "  'Time-Series ',\n",
       "  'Multivariate '],\n",
       " 'Task': ['Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Recommender-Systems ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Function-Learning ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Relational-Learning ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Recommender-Systems ',\n",
       "  'Classification ',\n",
       "  'Regression, Description ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Causal-Discovery ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Causal-Discovery ',\n",
       "  'Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Regression ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression, Clustering, Causal-Discovery ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Regression, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Regression, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression, Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression, Clustering, Causa ',\n",
       "  'Classification, Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Regression ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering, Causal-Discovery ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Causal-Discovery ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Regression, Clustering, Causal-Discovery ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Clustering, Causal-Discovery ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Causal-Discovery ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Causal-Discovery ',\n",
       "  'Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification, Clustering, Causal-Discovery ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Causal-Discovery ',\n",
       "  'Classification, Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  '-',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression ',\n",
       "  'Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Recommendation ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Regression, Clustering ',\n",
       "  'Regression ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Regression ',\n",
       "  'Regression ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Clustering, Causal-Discovery ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Causal-Discovery ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Causal-Discovery ',\n",
       "  'Clustering ',\n",
       "  'Regression, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Clustering ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Regression ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression ',\n",
       "  'Classification, Clustering ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification, Regression, Causal-Discovery ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Classification ',\n",
       "  'Regression ',\n",
       "  'Regression ',\n",
       "  'Regression '],\n",
       " 'Attribute_Type': ['Categorical, Integer, Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Real ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  '-',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer ',\n",
       "  '-',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical, Real, Integer ',\n",
       "  'Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Integer ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Categorical ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Categorical ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Categorical ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Categorical ',\n",
       "  'Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Real ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Categorical, Integer ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Categorical, Real ',\n",
       "  'Real ',\n",
       "  'Categorical ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Categorical ',\n",
       "  'Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Categorical ',\n",
       "  '-',\n",
       "  'Categorical, Real ',\n",
       "  '-',\n",
       "  'Categorical ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Categorical ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Categorical ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Categorical, Integer ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Categorical ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Categorical, Integer ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Categorical, Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Categorical ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Categorical ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  'Integer ',\n",
       "  'Real ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  'Integer ',\n",
       "  '-',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Integer, Real ',\n",
       "  '-',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real ',\n",
       "  'Real '],\n",
       " 'No_of_Instances': ['4177 ',\n",
       "  '48842 ',\n",
       "  '798 ',\n",
       "  '37711 ',\n",
       "  '452 ',\n",
       "  '6000 ',\n",
       "  '226 ',\n",
       "  '226 ',\n",
       "  '398 ',\n",
       "  '205 ',\n",
       "  '294 ',\n",
       "  '625 ',\n",
       "  '16 ',\n",
       "  '286 ',\n",
       "  '699 ',\n",
       "  '198 ',\n",
       "  '569 ',\n",
       "  '108 ',\n",
       "  '1728 ',\n",
       "  '48842 ',\n",
       "  '-',\n",
       "  '3196 ',\n",
       "  '28056 ',\n",
       "  '-',\n",
       "  '100 ',\n",
       "  '67557 ',\n",
       "  '690 ',\n",
       "  '125 ',\n",
       "  '209 ',\n",
       "  '1473 ',\n",
       "  '581012 ',\n",
       "  '512 ',\n",
       "  '366 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '132 ',\n",
       "  '336 ',\n",
       "  '194 ',\n",
       "  '352 ',\n",
       "  '214 ',\n",
       "  '306 ',\n",
       "  '160 ',\n",
       "  '303 ',\n",
       "  '155 ',\n",
       "  '368 ',\n",
       "  '-',\n",
       "  '2310 ',\n",
       "  '3279 ',\n",
       "  '351 ',\n",
       "  '150 ',\n",
       "  '7797 ',\n",
       "  '104 ',\n",
       "  '57 ',\n",
       "  '-',\n",
       "  '24 ',\n",
       "  '20000 ',\n",
       "  '345 ',\n",
       "  '-',\n",
       "  '32 ',\n",
       "  '148 ',\n",
       "  '209 ',\n",
       "  '528 ',\n",
       "  '-',\n",
       "  '106 ',\n",
       "  '128 ',\n",
       "  '3190 ',\n",
       "  '432 ',\n",
       "  '202 ',\n",
       "  '2000 ',\n",
       "  '8124 ',\n",
       "  '476 ',\n",
       "  '6598 ',\n",
       "  '12960 ',\n",
       "  '-',\n",
       "  '5473 ',\n",
       "  '5620 ',\n",
       "  '10992 ',\n",
       "  '90 ',\n",
       "  '339 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '167 ',\n",
       "  '15 ',\n",
       "  '1389 ',\n",
       "  '307 ',\n",
       "  '47 ',\n",
       "  '23 ',\n",
       "  '531 ',\n",
       "  '4601 ',\n",
       "  '267 ',\n",
       "  '267 ',\n",
       "  '76 ',\n",
       "  '-',\n",
       "  '1000 ',\n",
       "  '151 ',\n",
       "  '958 ',\n",
       "  '7200 ',\n",
       "  '10 ',\n",
       "  '285 ',\n",
       "  '435 ',\n",
       "  '527 ',\n",
       "  '5000 ',\n",
       "  '5000 ',\n",
       "  '178 ',\n",
       "  '1484 ',\n",
       "  '101 ',\n",
       "  '-',\n",
       "  '20000 ',\n",
       "  '6650 ',\n",
       "  '2565 ',\n",
       "  '2458285 ',\n",
       "  '299285 ',\n",
       "  '340 ',\n",
       "  '68040 ',\n",
       "  '-',\n",
       "  '122 ',\n",
       "  '178080 ',\n",
       "  '50672 ',\n",
       "  '640 ',\n",
       "  '9000 ',\n",
       "  '10104 ',\n",
       "  '256932 ',\n",
       "  '640 ',\n",
       "  '191779 ',\n",
       "  '4000000 ',\n",
       "  '-',\n",
       "  '10000 ',\n",
       "  '989818 ',\n",
       "  '129000 ',\n",
       "  '-',\n",
       "  '100000 ',\n",
       "  '21578 ',\n",
       "  '463 ',\n",
       "  '600 ',\n",
       "  '332 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '690 ',\n",
       "  '1000 ',\n",
       "  '270 ',\n",
       "  '6435 ',\n",
       "  '2310 ',\n",
       "  '58000 ',\n",
       "  '946 ',\n",
       "  '20008 ',\n",
       "  '208 ',\n",
       "  '528 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '1024 ',\n",
       "  '10080 ',\n",
       "  '50400 ',\n",
       "  '1025010 ',\n",
       "  '19020 ',\n",
       "  '1364 ',\n",
       "  '961 ',\n",
       "  '517 ',\n",
       "  '200 ',\n",
       "  '8000000 ',\n",
       "  '1030 ',\n",
       "  '606 ',\n",
       "  '900 ',\n",
       "  '2600 ',\n",
       "  '1950 ',\n",
       "  '13500 ',\n",
       "  '4400 ',\n",
       "  '2536 ',\n",
       "  '300 ',\n",
       "  '197 ',\n",
       "  '2858 ',\n",
       "  '748 ',\n",
       "  '11640 ',\n",
       "  '1593 ',\n",
       "  '1567 ',\n",
       "  '22632 ',\n",
       "  '360 ',\n",
       "  '103 ',\n",
       "  '1994 ',\n",
       "  '120 ',\n",
       "  '4898 ',\n",
       "  '2396130 ',\n",
       "  '16772 ',\n",
       "  '5875 ',\n",
       "  '503 ',\n",
       "  '51 ',\n",
       "  '106 ',\n",
       "  '2126 ',\n",
       "  '5456 ',\n",
       "  '8800 ',\n",
       "  '164860 ',\n",
       "  '-',\n",
       "  '1941 ',\n",
       "  '130065 ',\n",
       "  '515345 ',\n",
       "  '440 ',\n",
       "  '-',\n",
       "  '53500 ',\n",
       "  '8235 ',\n",
       "  '-',\n",
       "  '5749132 ',\n",
       "  '2215 ',\n",
       "  '310 ',\n",
       "  '10000 ',\n",
       "  '3000 ',\n",
       "  '1500 ',\n",
       "  '30000 ',\n",
       "  '2500 ',\n",
       "  '4143 ',\n",
       "  '64 ',\n",
       "  '53414 ',\n",
       "  '65554 ',\n",
       "  '45211 ',\n",
       "  '1138562 ',\n",
       "  '13910 ',\n",
       "  '583 ',\n",
       "  '2551 ',\n",
       "  '34465 ',\n",
       "  '5574 ',\n",
       "  '245057 ',\n",
       "  '182 ',\n",
       "  '3850505 ',\n",
       "  '138 ',\n",
       "  '1080 ',\n",
       "  '2075259 ',\n",
       "  '210 ',\n",
       "  '115 ',\n",
       "  '3960456 ',\n",
       "  '-',\n",
       "  '10299 ',\n",
       "  '1600 ',\n",
       "  '768 ',\n",
       "  '308 ',\n",
       "  '100 ',\n",
       "  '237 ',\n",
       "  '434874 ',\n",
       "  '536 ',\n",
       "  '140000 ',\n",
       "  '6118 ',\n",
       "  '165632 ',\n",
       "  '18000 ',\n",
       "  '540 ',\n",
       "  '931 ',\n",
       "  '1055 ',\n",
       "  '100 ',\n",
       "  '9120 ',\n",
       "  '403 ',\n",
       "  '111740 ',\n",
       "  '10421 ',\n",
       "  '5820 ',\n",
       "  '403 ',\n",
       "  '14980 ',\n",
       "  '45730 ',\n",
       "  '2584 ',\n",
       "  '1372 ',\n",
       "  '306 ',\n",
       "  '120000 ',\n",
       "  '13910 ',\n",
       "  '2747 ',\n",
       "  '3395 ',\n",
       "  '39242 ',\n",
       "  '4137 ',\n",
       "  '17389 ',\n",
       "  '51 ',\n",
       "  '470 ',\n",
       "  '132 ',\n",
       "  '5000000 ',\n",
       "  '11000000 ',\n",
       "  '250 ',\n",
       "  '126 ',\n",
       "  '-',\n",
       "  '4889 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '340 ',\n",
       "  '501 ',\n",
       "  '45781 ',\n",
       "  '1503 ',\n",
       "  '440 ',\n",
       "  '2000 ',\n",
       "  '9568 ',\n",
       "  '168 ',\n",
       "  '100000 ',\n",
       "  '5665 ',\n",
       "  '79 ',\n",
       "  '127 ',\n",
       "  '1040 ',\n",
       "  '9900 ',\n",
       "  '560 ',\n",
       "  '60021 ',\n",
       "  '1419 ',\n",
       "  '101 ',\n",
       "  '399 ',\n",
       "  '58 ',\n",
       "  '180 ',\n",
       "  '21048 ',\n",
       "  '-',\n",
       "  '750 ',\n",
       "  '3000 ',\n",
       "  '150 ',\n",
       "  '1059 ',\n",
       "  '11934 ',\n",
       "  '27965 ',\n",
       "  '216 ',\n",
       "  '120 ',\n",
       "  '649 ',\n",
       "  '370 ',\n",
       "  '4178504 ',\n",
       "  '221579 ',\n",
       "  '10800 ',\n",
       "  '58509 ',\n",
       "  '129685 ',\n",
       "  '2456 ',\n",
       "  '2921 ',\n",
       "  '1151 ',\n",
       "  '6590 ',\n",
       "  '3000 ',\n",
       "  '39797 ',\n",
       "  '326 ',\n",
       "  '913 ',\n",
       "  '168286 ',\n",
       "  '400 ',\n",
       "  '314080 ',\n",
       "  '637 ',\n",
       "  '1710671 ',\n",
       "  '12000 ',\n",
       "  '10929 ',\n",
       "  '1080 ',\n",
       "  '40000 ',\n",
       "  '43930257 ',\n",
       "  '230318 ',\n",
       "  '10500000 ',\n",
       "  '13197 ',\n",
       "  '-',\n",
       "  '30000 ',\n",
       "  '324 ',\n",
       "  '541909 ',\n",
       "  '11164866 ',\n",
       "  '163 ',\n",
       "  '373 ',\n",
       "  '20560 ',\n",
       "  '40 ',\n",
       "  '422937 ',\n",
       "  '9358 ',\n",
       "  '640 ',\n",
       "  '919438 ',\n",
       "  '40949 ',\n",
       "  '5744 ',\n",
       "  '10503 ',\n",
       "  '42240 ',\n",
       "  '102944 ',\n",
       "  '500 ',\n",
       "  '9782222 ',\n",
       "  '11463 ',\n",
       "  '17898 ',\n",
       "  '1885 ',\n",
       "  '19735 ',\n",
       "  '1540 ',\n",
       "  '4007 ',\n",
       "  '153540 ',\n",
       "  '606 ',\n",
       "  '1353 ',\n",
       "  '1956 ',\n",
       "  '43824 ',\n",
       "  '3942 ',\n",
       "  '858 ',\n",
       "  '287 ',\n",
       "  '17764280 ',\n",
       "  '106574 ',\n",
       "  '9358 ',\n",
       "  '11500 ',\n",
       "  '92000 ',\n",
       "  '315 ',\n",
       "  '78095 ',\n",
       "  '130 ',\n",
       "  '74 ',\n",
       "  '52854 ',\n",
       "  '77 ',\n",
       "  '811 ',\n",
       "  '504 ',\n",
       "  '401 ',\n",
       "  '2856 ',\n",
       "  '10546 ',\n",
       "  '801 ',\n",
       "  '1540 ',\n",
       "  '1451 ',\n",
       "  '1075 ',\n",
       "  '78095 ',\n",
       "  '7195 ',\n",
       "  '3600 ',\n",
       "  '76 ',\n",
       "  '60 ',\n",
       "  '405 ',\n",
       "  '303 ',\n",
       "  '303 ',\n",
       "  '107888 ',\n",
       "  '76000 ',\n",
       "  '10000 ',\n",
       "  '180 ',\n",
       "  '745000 ',\n",
       "  '12234 ',\n",
       "  '292 ',\n",
       "  '104 ',\n",
       "  '60000 ',\n",
       "  '2000 ',\n",
       "  '165 ',\n",
       "  '217 ',\n",
       "  '1175 ',\n",
       "  '704 ',\n",
       "  '75128 ',\n",
       "  '90 ',\n",
       "  '90 ',\n",
       "  '50 ',\n",
       "  '71 ',\n",
       "  '93239 ',\n",
       "  '540 ',\n",
       "  '105 ',\n",
       "  '6611 ',\n",
       "  '15 ',\n",
       "  '372 ',\n",
       "  '58000 ',\n",
       "  '4960 ',\n",
       "  '241600 ',\n",
       "  '130000 ',\n",
       "  '7062606 ',\n",
       "  '740 ',\n",
       "  '70 ',\n",
       "  '2205 ',\n",
       "  '10721 ',\n",
       "  '640 ',\n",
       "  '1000 ',\n",
       "  '116 ',\n",
       "  '1672 ',\n",
       "  '322 ',\n",
       "  '93600 ',\n",
       "  '3060 ',\n",
       "  '5879 ',\n",
       "  '9200 ',\n",
       "  '20000 ',\n",
       "  '20867 ',\n",
       "  '-',\n",
       "  '4143 ',\n",
       "  '215063 ',\n",
       "  '6000000 ',\n",
       "  '21263 ',\n",
       "  '63000000 ',\n",
       "  '10190 ',\n",
       "  '300 ',\n",
       "  '12330 ',\n",
       "  '5180 ',\n",
       "  '756 ',\n",
       "  '10000 ',\n",
       "  '80 ',\n",
       "  '1184 ',\n",
       "  '1047 ',\n",
       "  '777 ',\n",
       "  '249 ',\n",
       "  '414 ',\n",
       "  '-',\n",
       "  '143 ',\n",
       "  '7840 ',\n",
       "  '30000 ',\n",
       "  '35717 ',\n",
       "  '135 ',\n",
       "  '980 ',\n",
       "  '5456 ',\n",
       "  '120 ',\n",
       "  '4095000 ',\n",
       "  '7051 ',\n",
       "  '240 ',\n",
       "  '48204 ',\n",
       "  '260000 ',\n",
       "  '288000 ',\n",
       "  '8300000 ',\n",
       "  '125 ',\n",
       "  '170 ',\n",
       "  '141712 ',\n",
       "  '3916 ',\n",
       "  '6262 ',\n",
       "  '420768 ',\n",
       "  '1067371 ',\n",
       "  '1385 ',\n",
       "  '908 ',\n",
       "  '546 ',\n",
       "  '13956534 ',\n",
       "  '15630426 ',\n",
       "  '8992 ',\n",
       "  '1687 ',\n",
       "  '779 ',\n",
       "  '1056 ',\n",
       "  '590 ',\n",
       "  '21643 ',\n",
       "  '7750 ',\n",
       "  '14057567 ',\n",
       "  '27170754 ',\n",
       "  '597 ',\n",
       "  '329 ',\n",
       "  '299 ',\n",
       "  '20000 ',\n",
       "  '26136 ',\n",
       "  '1000 ',\n",
       "  '399 ',\n",
       "  '24017 ',\n",
       "  '325834 ',\n",
       "  '2916697 ',\n",
       "  '22470 ',\n",
       "  '189 ',\n",
       "  '520 ',\n",
       "  '826 ',\n",
       "  '2279 ',\n",
       "  '28764 ',\n",
       "  '7107 ',\n",
       "  '288000 ',\n",
       "  '9800 ',\n",
       "  '4760 ',\n",
       "  '72 ',\n",
       "  '1450 ',\n",
       "  '170 ',\n",
       "  '1984 ',\n",
       "  '2955 ',\n",
       "  '65532 ',\n",
       "  '65919 ',\n",
       "  '2111 ',\n",
       "  '3810 ',\n",
       "  '18 ',\n",
       "  '244 ',\n",
       "  '104 ',\n",
       "  '139 ',\n",
       "  '360177 ',\n",
       "  '36733 ',\n",
       "  '4480 ',\n",
       "  '165474 ',\n",
       "  '1985 ',\n",
       "  '10000 ',\n",
       "  '232 ',\n",
       "  '150 ',\n",
       "  '11 ',\n",
       "  '14057567 ',\n",
       "  '8760 ',\n",
       "  '48 ',\n",
       "  '6321 ',\n",
       "  '3150 ',\n",
       "  '17256 ',\n",
       "  '187 ',\n",
       "  '399 ',\n",
       "  '14 ',\n",
       "  '467 ',\n",
       "  '597 ',\n",
       "  '23700 ',\n",
       "  '615 ',\n",
       "  '6819 ',\n",
       "  '1000 ',\n",
       "  '-',\n",
       "  '2633 ',\n",
       "  '200 ',\n",
       "  '13028 ',\n",
       "  '800 ',\n",
       "  '1700 ',\n",
       "  '521 ',\n",
       "  '120000 ',\n",
       "  '666 ',\n",
       "  '88 ',\n",
       "  '200 ',\n",
       "  '2279 ',\n",
       "  '23570 ',\n",
       "  '10000 ',\n",
       "  '37700 ',\n",
       "  '1850 ',\n",
       "  '11 ',\n",
       "  '147270 ',\n",
       "  '3150 ',\n",
       "  '17256 ',\n",
       "  '597 ',\n",
       "  '7624 ',\n",
       "  '314 ',\n",
       "  '1197 ',\n",
       "  '70 ',\n",
       "  '7624 ',\n",
       "  '26737 ',\n",
       "  '10000 ',\n",
       "  '13611 ',\n",
       "  '12684 ',\n",
       "  '48 ',\n",
       "  '731 ',\n",
       "  '731 ',\n",
       "  '557 '],\n",
       " 'No_of_Attributes': ['8 ',\n",
       "  '14 ',\n",
       "  '38 ',\n",
       "  '294 ',\n",
       "  '279 ',\n",
       "  '7 ',\n",
       "  '-',\n",
       "  '69 ',\n",
       "  '8 ',\n",
       "  '26 ',\n",
       "  '1 ',\n",
       "  '4 ',\n",
       "  '4 ',\n",
       "  '9 ',\n",
       "  '10 ',\n",
       "  '34 ',\n",
       "  '32 ',\n",
       "  '13 ',\n",
       "  '6 ',\n",
       "  '14 ',\n",
       "  '22 ',\n",
       "  '36 ',\n",
       "  '6 ',\n",
       "  '-',\n",
       "  '6 ',\n",
       "  '42 ',\n",
       "  '15 ',\n",
       "  '-',\n",
       "  '9 ',\n",
       "  '9 ',\n",
       "  '54 ',\n",
       "  '39 ',\n",
       "  '33 ',\n",
       "  '20 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '12 ',\n",
       "  '8 ',\n",
       "  '30 ',\n",
       "  '-',\n",
       "  '10 ',\n",
       "  '3 ',\n",
       "  '5 ',\n",
       "  '75 ',\n",
       "  '19 ',\n",
       "  '27 ',\n",
       "  '-',\n",
       "  '19 ',\n",
       "  '1558 ',\n",
       "  '34 ',\n",
       "  '4 ',\n",
       "  '617 ',\n",
       "  '12 ',\n",
       "  '16 ',\n",
       "  '7 ',\n",
       "  '4 ',\n",
       "  '16 ',\n",
       "  '7 ',\n",
       "  '-',\n",
       "  '56 ',\n",
       "  '18 ',\n",
       "  '8 ',\n",
       "  '22 ',\n",
       "  '-',\n",
       "  '58 ',\n",
       "  '-',\n",
       "  '61 ',\n",
       "  '7 ',\n",
       "  '-',\n",
       "  '649 ',\n",
       "  '22 ',\n",
       "  '168 ',\n",
       "  '168 ',\n",
       "  '8 ',\n",
       "  '-',\n",
       "  '10 ',\n",
       "  '64 ',\n",
       "  '16 ',\n",
       "  '8 ',\n",
       "  '17 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '72 ',\n",
       "  '4 ',\n",
       "  '6 ',\n",
       "  '10 ',\n",
       "  '35 ',\n",
       "  '35 ',\n",
       "  '4 ',\n",
       "  '102 ',\n",
       "  '57 ',\n",
       "  '22 ',\n",
       "  '44 ',\n",
       "  '45 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '5 ',\n",
       "  '9 ',\n",
       "  '21 ',\n",
       "  '32 ',\n",
       "  '17 ',\n",
       "  '16 ',\n",
       "  '38 ',\n",
       "  '21 ',\n",
       "  '40 ',\n",
       "  '13 ',\n",
       "  '8 ',\n",
       "  '17 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '15 ',\n",
       "  '22 ',\n",
       "  '68 ',\n",
       "  '40 ',\n",
       "  '17 ',\n",
       "  '89 ',\n",
       "  '-',\n",
       "  '4 ',\n",
       "  '12 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '86 ',\n",
       "  '72 ',\n",
       "  '61 ',\n",
       "  '12 ',\n",
       "  '481 ',\n",
       "  '42 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '5 ',\n",
       "  '90 ',\n",
       "  '-',\n",
       "  '5 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '14 ',\n",
       "  '20 ',\n",
       "  '13 ',\n",
       "  '36 ',\n",
       "  '19 ',\n",
       "  '9 ',\n",
       "  '18 ',\n",
       "  '4 ',\n",
       "  '60 ',\n",
       "  '10 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '10 ',\n",
       "  '4 ',\n",
       "  '3 ',\n",
       "  '11 ',\n",
       "  '11 ',\n",
       "  '-',\n",
       "  '6 ',\n",
       "  '13 ',\n",
       "  '-',\n",
       "  '100000 ',\n",
       "  '9 ',\n",
       "  '101 ',\n",
       "  '10000 ',\n",
       "  '20000 ',\n",
       "  '100000 ',\n",
       "  '5000 ',\n",
       "  '500 ',\n",
       "  '73 ',\n",
       "  '43 ',\n",
       "  '23 ',\n",
       "  '3 ',\n",
       "  '5 ',\n",
       "  '-',\n",
       "  '256 ',\n",
       "  '591 ',\n",
       "  '70 ',\n",
       "  '91 ',\n",
       "  '10 ',\n",
       "  '128 ',\n",
       "  '6 ',\n",
       "  '12 ',\n",
       "  '3231961 ',\n",
       "  '5409 ',\n",
       "  '26 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '10 ',\n",
       "  '23 ',\n",
       "  '24 ',\n",
       "  '13 ',\n",
       "  '8 ',\n",
       "  '-',\n",
       "  '27 ',\n",
       "  '50 ',\n",
       "  '90 ',\n",
       "  '138672 ',\n",
       "  '-',\n",
       "  '386 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '12 ',\n",
       "  '147 ',\n",
       "  '6 ',\n",
       "  '8 ',\n",
       "  '27 ',\n",
       "  '10000 ',\n",
       "  '20000 ',\n",
       "  '10000 ',\n",
       "  '54877 ',\n",
       "  '4702 ',\n",
       "  '24 ',\n",
       "  '29 ',\n",
       "  '17 ',\n",
       "  '3 ',\n",
       "  '128 ',\n",
       "  '10 ',\n",
       "  '242 ',\n",
       "  '120 ',\n",
       "  '-',\n",
       "  '4 ',\n",
       "  '13 ',\n",
       "  '52 ',\n",
       "  '47 ',\n",
       "  '857 ',\n",
       "  '9 ',\n",
       "  '7 ',\n",
       "  '200 ',\n",
       "  '4 ',\n",
       "  '-',\n",
       "  '561 ',\n",
       "  '64 ',\n",
       "  '8 ',\n",
       "  '7 ',\n",
       "  '10 ',\n",
       "  '9 ',\n",
       "  '4 ',\n",
       "  '8 ',\n",
       "  '77 ',\n",
       "  '51 ',\n",
       "  '18 ',\n",
       "  '1950000 ',\n",
       "  '18 ',\n",
       "  '1300 ',\n",
       "  '41 ',\n",
       "  '6 ',\n",
       "  '5625 ',\n",
       "  '5 ',\n",
       "  '-',\n",
       "  '7 ',\n",
       "  '33 ',\n",
       "  '5 ',\n",
       "  '15 ',\n",
       "  '9 ',\n",
       "  '19 ',\n",
       "  '5 ',\n",
       "  '5 ',\n",
       "  '1000000 ',\n",
       "  '129 ',\n",
       "  '-',\n",
       "  '20 ',\n",
       "  '152 ',\n",
       "  '24 ',\n",
       "  '16 ',\n",
       "  '35 ',\n",
       "  '17 ',\n",
       "  '5 ',\n",
       "  '18 ',\n",
       "  '28 ',\n",
       "  '7 ',\n",
       "  '309 ',\n",
       "  '3 ',\n",
       "  '6 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '16 ',\n",
       "  '13 ',\n",
       "  '5 ',\n",
       "  '6 ',\n",
       "  '8 ',\n",
       "  '2 ',\n",
       "  '4 ',\n",
       "  '148 ',\n",
       "  '55 ',\n",
       "  '17 ',\n",
       "  '8 ',\n",
       "  '42 ',\n",
       "  '26 ',\n",
       "  '50 ',\n",
       "  '2 ',\n",
       "  '281 ',\n",
       "  '120 ',\n",
       "  '-',\n",
       "  '6 ',\n",
       "  '120432 ',\n",
       "  '150000 ',\n",
       "  '529 ',\n",
       "  '-',\n",
       "  '16 ',\n",
       "  '2500 ',\n",
       "  '5 ',\n",
       "  '68 ',\n",
       "  '16 ',\n",
       "  '100 ',\n",
       "  '216 ',\n",
       "  '23 ',\n",
       "  '33 ',\n",
       "  '140256 ',\n",
       "  '19 ',\n",
       "  '20 ',\n",
       "  '20 ',\n",
       "  '49 ',\n",
       "  '12 ',\n",
       "  '30 ',\n",
       "  '5232 ',\n",
       "  '20 ',\n",
       "  '1 ',\n",
       "  '-',\n",
       "  '61 ',\n",
       "  '27 ',\n",
       "  '53 ',\n",
       "  '11 ',\n",
       "  '25 ',\n",
       "  '0 ',\n",
       "  '20 ',\n",
       "  '9 ',\n",
       "  '3 ',\n",
       "  '561 ',\n",
       "  '82 ',\n",
       "  '13 ',\n",
       "  '16 ',\n",
       "  '13 ',\n",
       "  '28 ',\n",
       "  '4 ',\n",
       "  '-',\n",
       "  '24 ',\n",
       "  '34 ',\n",
       "  '8 ',\n",
       "  '128 ',\n",
       "  '15 ',\n",
       "  '513 ',\n",
       "  '7 ',\n",
       "  '7 ',\n",
       "  '5 ',\n",
       "  '15 ',\n",
       "  '480000 ',\n",
       "  '11 ',\n",
       "  '54 ',\n",
       "  '561 ',\n",
       "  '64 ',\n",
       "  '6 ',\n",
       "  '116 ',\n",
       "  '19 ',\n",
       "  '-',\n",
       "  '5812 ',\n",
       "  '9 ',\n",
       "  '32 ',\n",
       "  '29 ',\n",
       "  '67 ',\n",
       "  '-',\n",
       "  '25 ',\n",
       "  '6400 ',\n",
       "  '10 ',\n",
       "  '5 ',\n",
       "  '13 ',\n",
       "  '98 ',\n",
       "  '36 ',\n",
       "  '69 ',\n",
       "  '2158859 ',\n",
       "  '518 ',\n",
       "  '15 ',\n",
       "  '179 ',\n",
       "  '-',\n",
       "  '12 ',\n",
       "  '38 ',\n",
       "  '65 ',\n",
       "  '102 ',\n",
       "  '86 ',\n",
       "  '7 ',\n",
       "  '53 ',\n",
       "  '20 ',\n",
       "  '1 ',\n",
       "  '71 ',\n",
       "  '29 ',\n",
       "  '20531 ',\n",
       "  '65 ',\n",
       "  '3 ',\n",
       "  '22 ',\n",
       "  '38 ',\n",
       "  '22 ',\n",
       "  '4814 ',\n",
       "  '698 ',\n",
       "  '13 ',\n",
       "  '10 ',\n",
       "  '59 ',\n",
       "  '56 ',\n",
       "  '482 ',\n",
       "  '171 ',\n",
       "  '5 ',\n",
       "  '500 ',\n",
       "  '411 ',\n",
       "  '8519 ',\n",
       "  '21 ',\n",
       "  '21 ',\n",
       "  '171 ',\n",
       "  '7 ',\n",
       "  '49 ',\n",
       "  '12 ',\n",
       "  '3 ',\n",
       "  '21 ',\n",
       "  '9 ',\n",
       "  '8 ',\n",
       "  '7 ',\n",
       "  '2 ',\n",
       "  '11 ',\n",
       "  '11 ',\n",
       "  '173 ',\n",
       "  '5 ',\n",
       "  '15 ',\n",
       "  '3 ',\n",
       "  '105 ',\n",
       "  '25000 ',\n",
       "  '-',\n",
       "  '18 ',\n",
       "  '21000 ',\n",
       "  '115 ',\n",
       "  '21 ',\n",
       "  '206 ',\n",
       "  '43680 ',\n",
       "  '8 ',\n",
       "  '10 ',\n",
       "  '59 ',\n",
       "  '10 ',\n",
       "  '5 ',\n",
       "  '5 ',\n",
       "  '1000 ',\n",
       "  '138 ',\n",
       "  '-',\n",
       "  '16 ',\n",
       "  '2 ',\n",
       "  '10 ',\n",
       "  '-',\n",
       "  '8 ',\n",
       "  '6 ',\n",
       "  '129 ',\n",
       "  '81 ',\n",
       "  '12 ',\n",
       "  '6 ',\n",
       "  '22 ',\n",
       "  '18 ',\n",
       "  '9 ',\n",
       "  '754 ',\n",
       "  '14 ',\n",
       "  '5 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '18 ',\n",
       "  '7 ',\n",
       "  '7 ',\n",
       "  '-',\n",
       "  '7 ',\n",
       "  '5 ',\n",
       "  '6 ',\n",
       "  '4 ',\n",
       "  '18 ',\n",
       "  '11 ',\n",
       "  '25 ',\n",
       "  '-',\n",
       "  '20 ',\n",
       "  '12 ',\n",
       "  '46 ',\n",
       "  '9 ',\n",
       "  '8 ',\n",
       "  '49 ',\n",
       "  '11 ',\n",
       "  '8 ',\n",
       "  '54 ',\n",
       "  '36 ',\n",
       "  '3916 ',\n",
       "  '710 ',\n",
       "  '18 ',\n",
       "  '8 ',\n",
       "  '29 ',\n",
       "  '7 ',\n",
       "  '9 ',\n",
       "  '37 ',\n",
       "  '6 ',\n",
       "  '1024 ',\n",
       "  '1024 ',\n",
       "  '14 ',\n",
       "  '7 ',\n",
       "  '8265 ',\n",
       "  '29 ',\n",
       "  '25 ',\n",
       "  '3 ',\n",
       "  '115 ',\n",
       "  '1 ',\n",
       "  '12 ',\n",
       "  '13 ',\n",
       "  '200000 ',\n",
       "  '6 ',\n",
       "  '21 ',\n",
       "  '4 ',\n",
       "  '2400 ',\n",
       "  '175 ',\n",
       "  '10 ',\n",
       "  '4714 ',\n",
       "  '23 ',\n",
       "  '17 ',\n",
       "  '2 ',\n",
       "  '9 ',\n",
       "  '8 ',\n",
       "  '280 ',\n",
       "  '49 ',\n",
       "  '3 ',\n",
       "  '14 ',\n",
       "  '19 ',\n",
       "  '-',\n",
       "  '54 ',\n",
       "  '8 ',\n",
       "  '1087 ',\n",
       "  '12 ',\n",
       "  '3 ',\n",
       "  '17 ',\n",
       "  '8 ',\n",
       "  '9 ',\n",
       "  '12 ',\n",
       "  '1656 ',\n",
       "  '6 ',\n",
       "  '2 ',\n",
       "  '11 ',\n",
       "  '533 ',\n",
       "  '14 ',\n",
       "  '84 ',\n",
       "  '22 ',\n",
       "  '16 ',\n",
       "  '52 ',\n",
       "  '19 ',\n",
       "  '3 ',\n",
       "  '14 ',\n",
       "  '321 ',\n",
       "  '13 ',\n",
       "  '13 ',\n",
       "  '55 ',\n",
       "  '39 ',\n",
       "  '4 ',\n",
       "  '7 ',\n",
       "  '79 ',\n",
       "  '1 ',\n",
       "  '-',\n",
       "  '14 ',\n",
       "  '96 ',\n",
       "  '21 ',\n",
       "  '-',\n",
       "  '5 ',\n",
       "  '2 ',\n",
       "  '69 ',\n",
       "  '9 ',\n",
       "  '124 ',\n",
       "  '20 ',\n",
       "  '25 ',\n",
       "  '11 ',\n",
       "  '19 ',\n",
       "  '9 ',\n",
       "  '9 ',\n",
       "  '5 ',\n",
       "  '7 ',\n",
       "  '4006 ',\n",
       "  '2 ',\n",
       "  '19 ',\n",
       "  '4 ',\n",
       "  '13 ',\n",
       "  '55 ',\n",
       "  '1 ',\n",
       "  '7842 ',\n",
       "  '15 ',\n",
       "  '15 ',\n",
       "  '70 ',\n",
       "  '7842 ',\n",
       "  '4 ',\n",
       "  '14 ',\n",
       "  '17 ',\n",
       "  '23 ',\n",
       "  '321 ',\n",
       "  '1068 ',\n",
       "  '1068 ',\n",
       "  '5 '],\n",
       " 'Year': ['1995 ',\n",
       "  '1996 ',\n",
       "  '-',\n",
       "  '1998 ',\n",
       "  '1998 ',\n",
       "  '1992 ',\n",
       "  '1987 ',\n",
       "  '1992 ',\n",
       "  '1993 ',\n",
       "  '1987 ',\n",
       "  '1994 ',\n",
       "  '1994 ',\n",
       "  '-',\n",
       "  '1988 ',\n",
       "  '1992 ',\n",
       "  '1995 ',\n",
       "  '1995 ',\n",
       "  '1990 ',\n",
       "  '1997 ',\n",
       "  '1996 ',\n",
       "  '1988 ',\n",
       "  '1989 ',\n",
       "  '1994 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '1995 ',\n",
       "  '-',\n",
       "  '1992 ',\n",
       "  '1987 ',\n",
       "  '1997 ',\n",
       "  '1998 ',\n",
       "  '1995 ',\n",
       "  '1998 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '1994 ',\n",
       "  '-',\n",
       "  '1989 ',\n",
       "  '1996 ',\n",
       "  '1990 ',\n",
       "  '1990 ',\n",
       "  '1987 ',\n",
       "  '1999 ',\n",
       "  '1989 ',\n",
       "  '1988 ',\n",
       "  '1988 ',\n",
       "  '1989 ',\n",
       "  '-',\n",
       "  '1990 ',\n",
       "  '1998 ',\n",
       "  '1989 ',\n",
       "  '1988 ',\n",
       "  '1994 ',\n",
       "  '1990 ',\n",
       "  '1988 ',\n",
       "  '1988 ',\n",
       "  '1990 ',\n",
       "  '1991 ',\n",
       "  '1990 ',\n",
       "  '-',\n",
       "  '1992 ',\n",
       "  '1988 ',\n",
       "  '1990 ',\n",
       "  '1996 ',\n",
       "  '1995 ',\n",
       "  '1990 ',\n",
       "  '-',\n",
       "  '1992 ',\n",
       "  '1992 ',\n",
       "  '1994 ',\n",
       "  '-',\n",
       "  '1987 ',\n",
       "  '1994 ',\n",
       "  '1994 ',\n",
       "  '1997 ',\n",
       "  '1991 ',\n",
       "  '1995 ',\n",
       "  '1998 ',\n",
       "  '1998 ',\n",
       "  '1993 ',\n",
       "  '1988 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '1992 ',\n",
       "  '1993 ',\n",
       "  '1988 ',\n",
       "  '1989 ',\n",
       "  '1988 ',\n",
       "  '1987 ',\n",
       "  '1993 ',\n",
       "  '1988 ',\n",
       "  '1999 ',\n",
       "  '2001 ',\n",
       "  '2001 ',\n",
       "  '-',\n",
       "  '1992 ',\n",
       "  '1993 ',\n",
       "  '1997 ',\n",
       "  '1991 ',\n",
       "  '1987 ',\n",
       "  '1994 ',\n",
       "  '1988 ',\n",
       "  '1987 ',\n",
       "  '1993 ',\n",
       "  '1988 ',\n",
       "  '1988 ',\n",
       "  '1991 ',\n",
       "  '1996 ',\n",
       "  '1990 ',\n",
       "  '-',\n",
       "  '1999 ',\n",
       "  '1999 ',\n",
       "  '2002 ',\n",
       "  '-',\n",
       "  '2000 ',\n",
       "  '1999 ',\n",
       "  '1999 ',\n",
       "  '2001 ',\n",
       "  '1999 ',\n",
       "  '1999 ',\n",
       "  '2000 ',\n",
       "  '1999 ',\n",
       "  '2000 ',\n",
       "  '1999 ',\n",
       "  '1999 ',\n",
       "  '-',\n",
       "  '1998 ',\n",
       "  '1999 ',\n",
       "  '2001 ',\n",
       "  '1999 ',\n",
       "  '-',\n",
       "  '2003 ',\n",
       "  '1999 ',\n",
       "  '1999 ',\n",
       "  '1997 ',\n",
       "  '1999 ',\n",
       "  '1999 ',\n",
       "  '1998 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '1994 ',\n",
       "  '-',\n",
       "  '1993 ',\n",
       "  '1990 ',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '-',\n",
       "  '1989 ',\n",
       "  '2006 ',\n",
       "  '2006 ',\n",
       "  '2007 ',\n",
       "  '2007 ',\n",
       "  '2007 ',\n",
       "  '2007 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2007 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2009 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2008 ',\n",
       "  '2009 ',\n",
       "  '2009 ',\n",
       "  '2009 ',\n",
       "  '2009 ',\n",
       "  '2009 ',\n",
       "  '2009 ',\n",
       "  '2010 ',\n",
       "  '2009 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2010 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2011 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2012 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2014 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2013 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2013 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2015 ',\n",
       "  '2014 ',\n",
       "  '2014 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2014 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2015 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2015 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2015 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2016 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2017 ',\n",
       "  '2016 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2016 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2019 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2019 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2021 ',\n",
       "  '2018 ',\n",
       "  '2018 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2019 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2020 ',\n",
       "  '2021 ',\n",
       "  '2021 ',\n",
       "  '2021 ']}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the 'Dataset_Name', 'Data_Type', 'Task', 'Attribute_Type', 'No_of_Instances', 'No_of_Attributes', 'Year' details\n",
    "str_ = \"//table[@border='1']/tbody/tr[\"\n",
    "keys = list(d.keys())\n",
    "for i in range(1,len(rows)):\n",
    "    path = str_+str(i+1)+\"]/td\"\n",
    "    l = driver.find_elements_by_xpath(path)\n",
    "    for j in range(7):\n",
    "        if(l[j].text)==' ':\n",
    "            d[keys[j]].append(\"-\")\n",
    "        else:\n",
    "            d[keys[j]].append(l[j].text)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>-</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset_Name      Data_Type                  Task  \\\n",
       "0                               Abalone  Multivariate        Classification    \n",
       "1                                 Adult  Multivariate        Classification    \n",
       "2                             Annealing  Multivariate        Classification    \n",
       "3          Anonymous Microsoft Web Data              -  Recommender-Systems    \n",
       "4                            Arrhythmia  Multivariate        Classification    \n",
       "..                                  ...            ...                   ...   \n",
       "583    in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "584                 Gait Classification  Multivariate        Classification    \n",
       "585           Wikipedia Math Essentials   Time-Series            Regression    \n",
       "586           Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587        Synchronous Machine Data Set  Multivariate            Regression    \n",
       "\n",
       "                  Attribute_Type No_of_Instances No_of_Attributes   Year  \n",
       "0    Categorical, Integer, Real            4177                8   1995   \n",
       "1          Categorical, Integer           48842               14   1996   \n",
       "2    Categorical, Integer, Real             798               38       -  \n",
       "3                   Categorical           37711              294   1998   \n",
       "4    Categorical, Integer, Real             452              279   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "583                            -          12684               23   2020   \n",
       "584                        Real              48              321   2020   \n",
       "585                        Real             731             1068   2021   \n",
       "586                        Real             731             1068   2021   \n",
       "587                        Real             557                5   2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
